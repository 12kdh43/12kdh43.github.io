<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
	
	<!-- On Post front-matter YAML, set "use_math: true" to use LaTex -->
	

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Search Result</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />

    <!-- syntax.css -->
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
	
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="" />
    <link rel="shortcut icon" href="http://0.0.0.0:4000/assets/built/images/favicon.jpg" type="image/png" />
    <link rel="canonical" href="http://0.0.0.0:4000/search" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Darron's Devlog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Search Result" />
    <meta property="og:description" content="" />
    <meta property="og:url" content="http://0.0.0.0:4000/search" />
    <meta property="og:image" content="http://0.0.0.0:4000/assets/built/images/blog-cover1.png" />
    <meta property="article:publisher" content="https://www.facebook.com/" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Search Result" />
    <meta name="twitter:description" content="" />
    <meta name="twitter:url" content="http://0.0.0.0:4000/" />
    <meta name="twitter:image" content="http://0.0.0.0:4000/assets/built/images/blog-cover1.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Darron's Devlog" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="666" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Darron's Devlog",
        "logo": "http://0.0.0.0:4000/"
    },
    "url": "http://0.0.0.0:4000/search",
    "image": {
        "@type": "ImageObject",
        "url": "http://0.0.0.0:4000/assets/built/images/blog-cover1.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://0.0.0.0:4000/search"
    },
    "description": ""
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Search Result" href="/feed.xml" />


</head>
<body class="page-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- < default -->
<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<!-- The big featured header, it uses blog cover image as a BG if available -->
<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="/">Darron's Devlog</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-projects" role="menuitem"><a href="/tag/projects/">Projects</a></li>
    <li class="nav-studies" role="menuitem"><a href="/tag/studies/">Studies</a></li>
	<li class="nav-blog" role="menuitem"><a href="/tag/blog/">Blog</a></li>
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
</ul>
        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  post page no-image">

            <header class="post-full-header">
                <h1 class="post-full-title">Search Result</h1>
            </header>

            

            <section class="post-full-content">
                <form action="/search" method="get" hidden="hidden">
    <label for="search-box"></label>
    <input type="text" id="search-box" name="query">
</form>

<ul class="mylist" id="search-results"></ul>

<script>
    window.store = {
    
    "cs224n-lec2": {
        "title": "cs224n - Lecture 2. Neural Classifiers",
        "author": "Darron Kwon",
        "category": "",
        "content": "Review: Main idea of word2vec  Start with random word vectors  Iterate through each word in the whole corpus  Try to predict surrounding words using word vectors: $P(o\\mid c) = \\frac{\\exp(u_o^T v_c)}{\\sum_{w \\in V}\\exp(u_w^T v_c)}$  Learning: Update vectors so they can predict actual surrounding words better  Doing no more than this, this algorithm learns word vectors that capture well word similarity and meaningful directions in a wordspace.  A “bag of words” model; doesn’t actually pay any attention to word order or position. The model makes the same predictions at each position; the probability estimate would be the same if it is next to the center word or a bit further away.      We want a model that gives a reasonably high probability estimate to all words that occur in the context(at all often)    Word2vec maximizes objective function by putting similar words nearby in high dimensional vector spaceOptimization: Gradient Descent  To learn good word vectors: minimize a cost function $J(\\theta)$  Gradient Descent is an algorithm to minimize $J(\\theta)$ by changing $\\theta$  idea: from current value of $\\theta$, calculate gradient of $J(\\theta)$, then take small step in the direction of negative gradient. Repreat.  Algorithm:    while True:  theta_grad = evaluate_gradient(J, corpus, theta)  theta = theta - alpha * theta_grad      Stochastic Gradient Descent  Problem: $J(\\theta)$ is a function of all windows in the corpus (often, billions!); so $\\nabla_\\theta J(\\theta)$ is very expensive to compute  Solution: Stochastic gradient descent(SGD)          Repeatedly sample windows, and update after each one, or each small batch        Algorithm:    while True:  window = sample_window(corpus)  theta_grad = evaluate_gradient(J, window, theta)  theta = theta - alpha * theta_grad        Stochastic gradients with word vectors (Aside)          iteratively take gradients at each such window for SGD      But in each window, we only have at most 2m + 1 words,  so $\\nabla_\\theta J(\\theta)$ is very sparse:  \\(\\nabla_\\theta J_t(\\theta) = \\begin{bmatrix} 0  \\\\ \\vdots \\\\ \\nabla_{v_{\\text{like}}} \\\\ \\vdots 0 \\\\ \\nabla_{u_I} \\\\ \\vdots \\\\ \\nabla_{u_{\\text{learning}}} \\\\ \\vdots \\end{bmatrix} \\in \\mathbb{R}^{2dV}\\)      We might only update the word vectors that actually appear.      Solution: either you need sparse matrix update operations to only update certain rows(in most DL packages) of full embedding matrices U and V, or you need to keep around a hash for word vectors.        If you have millions of word vectors and do distributed computing, it is important to not have to send gigantic updates around.      2b. Word2vec algorithm family: More details  Why two vectors? $\\rightarrow$ Easier optimization. Average both at the end          But can implement the algorithm with just one vector per word, and it works slightly better, but it makes the algorithm much more complicated.        Two model variants:          Skip-grams(SG) Predict context(“outside”) words (position independent) given center word      Continuous Bag of Words(CBOW) Predict center word from (bag of) context words  We presented: Skip-gram model        Additional efficiency in training:          Negative sampling  So far: Focus on naive softmax(simpler, but expensive training method)      The skip-gram model with negative sampling(SGNS)  The normalization term is computationally expensive, especially on the denominator of $P(o\\mid c)$.  Main idea: train binary logistic regressions for a true pair (center word and a word in its context window) versus several noise pairs (the center word paired with a random word)  From paper: “Distributed Representations of Words and Phrases and their Compositionality” (Mikolov et al. 2013)  Overall objective function(to maximize):  \\(J(\\theta) = \\frac{1}{T}\\sum_{t=1}^T J_t(\\theta)\\)  \\(J_t(\\theta) = \\log\\sigma(u_o^T u_c) + \\sum_{i=1}^k \\mathbb{E}_{j~P(w)}\\left[ \\log\\sigma(-u_j^T v_c) \\right]\\)  where the logistic/sigmoid function: $\\sigma(x) = \\frac{1}{1+ e^{-x}}$  We maximize the probability of two words co-occuring in first log and minimize probability of noise words:  $J_{\\text{neg-sample}}(u_o, v_c, U) = -\\log \\sigma(u_o^T v_c) - \\sum_{k\\in { \\text{K sampled indicies} }} \\log \\sigma(-u_k^T v_c)$  We take k negative samples (using word probabilities)  Maximize probability that real outside word appears, minimize probability that random words appear around center word  Another trick: sample with $P(w) = U(w)^{3/4} / Z$, the unigram distribution $U(w)$ raised to the $3/4$ power (We provide this function in the starter code)  The power makes less frequent words be sampled more oftenWhy not capture co-occurrence counts directly?  Building a co-occurrence matrix X          2 options: windows vs. full document      Window: Similar to word2vec, use window around each word and captures some syntactic and semantic information        Word-document co-occurrence matrix will give general topics (all sports terms will have similar entries) learning to “Latent Semantic Analysis”; in tasks like information retrieval      Co-occurrence vectors  Simple count co-occurrence vectors          Vectors increase in size with vocabulary      Very high dimensional: require a lot of storage (though sparse)      Subsequent classification models have sparsity issues $\\rightarrow$ Models are less robust        Low-dimensional vectors          idea: store “most” of the important information in a fixed, small number of directions: a dense vector      Usually 25-1000 directions, similar to word2vec      How to reduce the dimensionality?      Classic Method: Dimensionality Reduction on X  Singular Value Decomposition of co-occurrence matrix X  Factorizes X into $U\\Sigma V^T$, where U and V are orthonormal    Corresponding to the columns without singular values in $\\Sigma$, bottom rows in $V^T$ are ignored. The singular values inside the diagonal matrix $\\Sigma$ are ordered from largest down to smallest. Retaining only k singular values, in order to generalize, the lower dimensional representation $\\hat{X}$ is the best rank k approximation to X, in terms of least squares.Hacks to X (several used in Rohde et al. 2005 in COALS)      Running an SVD on a raw count co-occurrence matrix works poorly; In the mathematical assumptions of SVD, we are expecting to have normally distributed errors. But there are exceedingly common words like “a”, “the”, and “and”, and there is a very large number of rare words.    Scaling the counts in the cells can help a lot          Problem: function words(the, he, has) are too frequent $\\rightarrow$ syntax has too much impact. Some fixes:                  log the frequencies          $min(X,t)$, with $t\\approx 100$          ignore the function words                      Ramped windows that count closer words more than further away words  Use Pearson correlations instead of counts, then set negative values to 0  Etc.  Result:  Interesting semantic patterns emerge in the scaled vectors; something like a word vector analogies.  Towards GloVe: Count based vs. direct predictionEncoding meaning components in vector differences  Pennington, Socher, and Manning, EMNLP 2014  What properties needed to make vector analogies work?      Crucial insight: Ratios of co-occurrence probabilities can encode meaning components    Q: How can we capture ratios of co-occurrence probabilities as linear meaning components in a word vector space?  A: Log-bilinear model: the dot product between two word vectors attempts to approximate the log of the probability of co-occurrence; \\(w_i \\cdot w_j = \\log P(i|j)\\)  $\\rightarrow$ with vector differences \\(w_x \\cdot (w_a - w_b) = \\log \\frac{P(x\\mid a)}{P(x \\mid b)}\\)Combining the best of both worlds: GloVe  Pennington, Socher, and Manning, EMNLP 2014  With \\(w_i \\cdot w_j = \\log P(i|j)\\),  explicit loss function \\(J = \\sum_{i,j=1}^V f(X_{ij})(w_i^T \\tilde{w}_j + b_i + \\tilde{b}_j - \\log X_{ij})^2\\)  to make the dot product to be similar to the log of the co-occurrence. To not have very common words dominate, capped the effect of high word counts using $f$ function. Optimize J directly on the co-occurrence count matrix.          Fast training      Scalable to hugh corpora      Good performance even with small corpus and small vectors      How to evaluate word vectors?  Related to general evaluation in NLP: intrinsic vs. extrinsic  Intrinsic:          Evaluation on a specific/intermediate subtask      Fast to compute      Helps to understand that system      Not clear if really helpful unless correlation to real task is established        Extrinsic:          Evaluation on a real task      Can take a long time to compute accuracy      Unclear if the subsystem is the problem or its interaction or other subsystems      If replacing exactly one subsystem with another improves accuracy $\\rightarrow$ Winning!      Intrinsic word vector evaluation  Word Vector Analogies  |a:b :: c:?| $\\rightarrow$ $d = \\text{argmax}_i \\frac{(x_b -x_a +x_c)^T x_i}{\\lVert x_b -x_a +x_c\\rVert}$  (e.g. man:woman :: king:?)  Evalute word vectors by how well their cosine distance after addition captures intuitive semantic and syntactic analogy questions  Discarding the input words from the search!  Problem: What if the information is there but not linear?GloVe VisualizationsAnalogy evaluation and hyperparametersAnother intrinsic word vector evaluation  Word vector distances and their correlation with human judgements  Example dataset: WordSim353 http://www.cs.technion.ac.il/~gabr/resources/data/wordsim353/  Some ideas from Glove paper have been shown to improve skip-gram(SG) model also (e.g., average both vectors)Extrinsic word vector evaluation  All subsequent NLP tasks  One example where good word vectors should help directly: named entity recognition: identifying references to a person, organization or locationWord senses  Most words have lots of meanings          Especially common words      Especially words that have existed for a long time        Does one vector caputre all these meanings or do we have a mess?“Linear Algebric Structure of Word Senses, with Applications to Polysemy”, Arora, …, Ma, …, TACL 2018  Different senses of a word reside in a linear superposition(weighted sum) in standard word embeddings like word2vec  \\(v_{\\text{pike}} = \\alpha_1 v_{\\text{pike}_2} + \\alpha_2 v_{\\text{pike}_2} + \\alpha_3 v_{\\text{pike}_3}\\)  where $\\alpha_1 = \\frac{f_1}{f_1+f_2+f_3}$, etc., for frequency f  Surprising result:  Commonly, it is impossible to reconstruct the original components from their sum, but, because of ideas from sparse coding you can actually separate out the senses(providing they are relatively common)!",
        "url": "/cs224n_lec2"
    }
    ,
    
    "cs224n-lec1": {
        "title": "cs224n - Lecture 1. Word Vectors",
        "author": "Darron Kwon",
        "category": "",
        "content": "Objectives  The foundations of the effective modern methods for deep learning applied to NLP; from basics to key methods used in NLP: RNN, Attention, Transformers, etc.)  A big picture understanding of human languages and the difficulties in understanding and producing them  An understanding of and ability to build systems (in PyTorch) for some of the major problems in NLP: Word meaning, dependency parsing, machine translation, question answering  NLP tasks:  Easy: Spell Checking, Keyword Search, Finding Synonyms  Medium: Parsing information from websites, documents, etc.  Hard: Machine Translation, Semantic Analysis, Coreference, QAWord meaning      Commonest linguistic way of thinking of meaning:  signifier (symbol) $\\Leftrightarrow$ signified (idea or thing)  $=$ denotational semantics        Common NLP solution: Use, e.g., WordNet, a thesaurus containing lists of synonym sets and hypernyms(“is a” relationships).        Problems with resources like WordNet          Great as a resource but missing nuance      Missing new meanings of words; impossible to keep up-to-date      Subjective      Requires human labor to create and adapt      Can’t compute accurate word similarity      Representing words as discrete symbols  In traditional NLP, we regard words as discrete symbols - a localist representation.  $\\rightarrow$ in a statistical machine learning systems, such symbols for words are separately represented by one-hot vectors. Thus we need to have huge vector dimension corresponding to the number of words in vocabulary.          But with discrete symbols, two vectors are orthogonal and there is no natural notion of similarity for one-hot vectors.        Solution:          Could try  to rely on WordNet’s list of synonyms to get similarity?  But it is well-known to fail badly; incompleteness, etc.      Instead: learn to encode similarity in the vecotr themselves.      Representing words by their context  Distributional semantics: A word’s meaning is given by the words that frequently appear close-by          “You shall know a word by the company it keeps” (J. R. Firth 1957:11)      One of the most successful ideas of modern statistical NLP        When a word w appears in a text, its context is the set of words that appear nearby(within a fixed-size window).  Use the many contexts of w to build up a representation of wWord vectors      A dense vector for each word, chosen so that it is similar to vectors of words that appear in similar contexts        Note: as a distributed representation, word vectors are also called word embeddings or (neural) words representations  Word2vecWord2vec: overview  Word2vec(Mikolov et al. 2013) is a framework for learning word vectors  idea:          We have a large corpus(“body”) of text      Every word in a fixed vocabulary is representated by a vector      Go through each position t in the text, which has a center word c and context(“outside”) words o      Use the similarity of the word vectors for c and o to calculate the probability of o given c(or vice versa)      Keep adjusting the word vectors to maximize this probability      We can learn these word vectors from just a big pile of text by doing this distributional similarity task of being able to predict what words occur in the context of other words.  Example windows and process for computing $P(w_{t+j}|w_t)$Word2vec: objective functionFor each position $t = 1, \\ldots, T$, predict context words within a window of fixed size m, given center word $w_j$. Data likelihood:\\(\\begin{align*}L(\\theta) = \\prod_{t=1}^T \\prod_{\\substack{-m\\leqq j\\leqq m \\\\ j\\ne 0}} P(w_{t+j}|w_t;\\theta)\\end{align*}\\)where $\\theta$ is all variables to be optimized.The objective function $J(\\theta)$ is the (average) negative log likelihood:\\(\\begin{align*}J(\\theta) = -\\frac{1}{T}\\log L(\\theta) = -\\frac{1}{T}\\sum_{t=1}^T \\sum_{\\substack{-m\\leqq j\\leqq m \\\\ j\\ne 0}}\\log P(w_{t+j}|w_t;\\theta)\\end{align*}\\)Minimizing objective function $\\Leftrightarrow$ Maximizing predictive accuracy  Question: How to calculate $P(w_{t+j}\\vert w_t;\\theta)$?  Answer: We will use two vectors per word w:          $v_w$ when w is a center word      $u_w$ when w is a context word        Then for a centor word c and a context word o:  \\(P(o|c) = \\frac{\\exp(u_o^T v_c)}{\\sum_{w \\in V}\\exp(u_w^T v_c)}\\)Word2vec: prediction function\\(P(o|c) = \\frac{\\exp(u_o^T v_c)}{\\sum_{w \\in V}\\exp(u_w^T v_c)}\\)  $u_w^T v_c$: Dot product compares similarity of o and c. $u^T v = u\\ .v = \\sum_{i=1}^n u_i v_i$ Larger dot product = larger probability  $\\exp$: Exponentiation makes anything positive  $\\sum_{w \\in V}\\exp(u_w^T v_c)$: Normalize over entire vocabulary to give probability distribution.      This is an example of the softmax function $\\mathbb{R}^n \\rightarrow (0,1)^n$(Open region) that maps arbitary values $x_i$ to a probability distribution $p_i$  \\(\\mbox{softmax}(x_i) = \\frac{\\exp(x_i)}{\\sum_{j=1}^n\\exp(x_j)} = p_i\\)        To train the model: Optimize value of parameters to minimize loss          Recall: $\\theta$ represents all the model parameters, in one long vector      In our case, with d-dimensional vectors and V-many words, we have: $\\theta \\in \\mathbb{R}^{2dV}$      Remember: every word has two vectors      We optimize these parameters by walking down the gradient(gradient descent)      We compute all vector gradients      Word2vec derivations of gradient\\(\\begin{align*}J(\\theta) = -\\frac{1}{T}\\log L(\\theta) = -\\frac{1}{T}\\sum_{t=1}^T \\sum_{\\substack{-m\\leqq j\\leqq m \\\\ j\\ne 0}}\\log P(w_{t+j}|w_t;\\theta)\\end{align*}\\)\\(P(o|c) = \\frac{\\exp(u_o^T v_c)}{\\sum_{w \\in V}\\exp(u_w^T v_c)}\\)\\(\\frac{\\partial}{\\partial v_c} \\log \\frac{\\exp(u_o^T v_c)}{\\sum_{w \\in V}\\exp(u_w^T v_c)} = \\underbrace{\\frac{\\partial}{\\partial v_c} \\log \\exp(u_o^T v_c)}_{(1)} - \\underbrace{\\frac{\\partial}{\\partial v_c} \\log \\sum_{w=1}^V \\exp(u_w^T v_c)}_{(2)}\\)\\(\\begin{align*}\\cdots (1) &amp;= \\frac{\\partial}{\\partial v_c} u_o^T v_c \\\\\t\t\t\t\t\t\t&amp;= u_o \\end{align*}\\)\\(\\begin{align*}\\cdots (2) &amp;= \\frac{1}{\\sum_{w=1}^V \\exp(u_w^T v_c)} \\cdot \\sum_{x=1}^V \\frac{\\partial}{\\partial v_c} \\exp(u_x^T v_c) \\\\\t\t\t\t\t\t\t&amp;= \\frac{1}{\\sum_{w=1}^V \\exp(u_w^T v_c)} \\cdot \\sum_{x=1}^V \\exp(u_x^T v_c) \\cdot \\frac{\\partial}{\\partial v_c} u_x^T v_c \\\\\t\t\t\t\t\t\t&amp;= \\frac{1}{\\sum_{w=1}^V \\exp(u_w^T v_c)} \\cdot \\sum_{x=1}^V \\exp(u_x^T v_c) \\cdot u_x \\\\\t\t\t\t\t\t\t\\end{align*} \\\\\\)\\(\\begin{align*}\\frac{\\partial}{\\partial v_c} \\log P(o|c) &amp;= u_o - \\frac{\\sum_{x=1}^V \\exp(u_x^T v_c)u_x}{\\sum_{w=1}^V \\exp(u_w^T v_c)} \\\\\t&amp; = u_o - \\sum_{x=1}^V \\underbrace{\\frac{\\exp(u_x^T v_c)}{\\sum_{w=1}^V \\exp(u_w^T v_c)}}_{\\mbox{softmax formula}} u_x \\\\\t&amp; = u_o - \\underbrace{\\sum_{x=1}^V P(x|c) u_x}_{\\mbox{Expectation}} \\\\\t&amp; = \\mbox{observed} - \\mbox{expected} \\end{align*}\\)",
        "url": "/cs224n_lec1"
    }
    ,
    
    "devenv-setup": {
        "title": "DevEnv Setup",
        "author": "Darron Kwon",
        "category": "",
        "content": "  For purpose of setting local development environment on a new SSD storage, followed instructions below. Post for later use.  Document Enable NVIDIA CUDA on WSL          Install stable version of Windows 11      Enable WSL, install Ubuntu(20.04.3 LTS)  On Windows Settings app, select Check for updates in the Windows Update section and get the latest kernel(5.10.43.3 or higher)  To check the version, run wsl cat /proc/version command in Powershell.      Install the GPU driver  Download and install the NVIDIA CUDA enabled driver for WSL  (Studio version: 511.65-desktop-win10-win11-64bit-international-nsd-dch-whql)        Install Docker Desktop app on Windows          Run:  docker run --rm -it --gpus=all nvcr.io/nvidia/k8s/cuda-sample:nbody nbody -gpu -benchmark      Result:          &gt; Windowed mode  &gt; Simulation data stored in video memory  &gt; Single precision floating point simulation  &gt; 1 Devices used for simulation  GPU Device 0: \"Ampere\" with compute capability 8.6  &gt; Compute 8.6 CUDA device: [NVIDIA GeForce RTX 3070]  47104 bodies, total time for 10 iterations: 40.275 ms  = 550.910 billion interactions per second  = 11018.199 single-precision GFLOP/s at 20 flops per interaction                      Setting Docker image for TensorFlow-GPU          Pull the latest TensorFlow-GPU image  docker run -it --gpus all tensorflow/tensorflow:latest-gpu      Install Anaconda on user:root(ref: blog)          # update and install prerequisites  apt-get update  apt-get install wget  # get proper version of anaconda3  wget https://repo.anaconda.com/archive/Anaconda3-2021.11-Linux-x86_64.sh   sh Anaconda3-2021.11-Linux-x86_64.sh  exec bash  # create anaconda environment and install libraries(for stability)  conda create -n !env_name pip python=3.7  conda activate !env_name  pip install tensorflow-gpu  pip install ipykernel  python -m ipykernel install --user --name !env_name --display-name !dispaly_name  pip install jupyter  # escape with Ctrl + p, Ctrl + q  docker commit -m \"!message\" !container_id !image_name:tag                    (Optional) Install TensorFlow Object Detection API          apt-get install git  git clone --depth 1 https://github.com/tensorflow/models  cd models/research/  apt install -y protobuf-compiler  # found a symlink err, fixed with running:  # ln -s /usr/lib/x86_64-linux-gnu/libcuda.so.1 /usr/local/cuda/lib64/libcuda.so  # and rerun: apt install -y protobuf-compiler  protoc object_detection/protos/*.proto --python_out=.  cd models/research/  # install Object Detection API  cp object_detection/packages/tf2/setup.py .  python -m pip install --use-feature=2020-resolver .  # run test  python object_detection/builders/model_builder_tf2_test.py  # rm -rf models (if desired)                    (Optional) Install JupyterLab Extensions and enable TensorBoard within Jupyterlab-Docker container  Stable versions worked on my local environment          curl -sL https://deb.nodesource.com/setup_12.x | bash -  apt-get install -y nodejs  node --version # check: v12.22.10  npm --version # check: 6.14.16  pip install jupyterlab==2.3.2   pip install git+https://github.com/cliffwoolley/jupyter_tensorboard.git   pip install tensorboard==2.2  jupyter labextension install jupyterlab_tensorboard                Commit and run container with any open port for JupyterLab  e.g.          docker run --rm -it --gpus all -p 4000:4000 !image_name:tag  conda activate !env_name  jupyter lab --ip='0.0.0.0' --port=4000 --no-browser --allow-root                On your Windows, open localhost:4000 with browser              Setting Docker image for Jekyll blog          Get latest Ubuntu image and install packages          docker run --rm -it -p 4000:4000 ubuntu  apt-get update  apt-get install git  apt-get install vim ruby-full build-essential zlib1g-dev -y  echo '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.bashrc  echo 'export GEM_HOME=\"$HOME/gems\"' &gt;&gt; ~/.bashrc  echo 'export PATH=\"$HOME/gems/bin:$PATH\"' &gt;&gt; ~/.bashrc  source ~/.bashrc  gem install jekyll bundler\t\t  jekyll -v # 4.2.1  mkdir -p /root/blog_home  echo 'export BLOG_HOME=\"/root/blog_home\"' &gt;&gt; ~/.bashrc  echo '# Start jekyll' &gt;&gt; ~/.bashrc  source ~/.bashrc  cd $BLOG_HOME # Get any jekyll blog template here  rm Gemfile.lock # if needed  bundle install  bundle exec jekyll serve --host 0.0.0.0 -p 4000                    ",
        "url": "/DevEnv_Setup"
    }
    ,
    
    "mask-r-cnn": {
        "title": "Mask R-CNN",
        "author": "Darron Kwon",
        "category": "",
        "content": "Mask R-CNNKaiming He, Georgia Gkioxari, Piotr Dollár, Ross Girshick, ICCV 2017https://github.com/facebookresearch/DetectronWhat’s different?      Models so far  R-CNN: 2-stage model for Object detection  Fast R-CNN: RoI on feature map  Faster R-CNN: RPN network    Instance Segmentation  Combining to tasks:          Object detection(Fast/Faster R-CNN): classify individual objects and localize each using a bounding box.      Semantic segmentation(FCN; Fully Convolutional Network): classify each pixel into a fixed set of categories without differentiating object instances.        Mask R-CNN:  1) Model for instance segmentation: Mask prediction branch  2) FPN(feature pyramid network) before RPN  3) RoI alignMask prediction      Mask loss  In the second stage, in parallel to predicting the class and box offset, Mask R-CNN also outputs a binary mask(ones to the object and zeros elsewhere) for each RoI. Defined multi-task loss on each sampled RoI: $L = L_{cls} + L_{box} + L_{mask}$  The mask branch has a $Km^2$-dimensional output for each RoI, which encodes K binary masks of resolution m\\times m, one for each of the K classes. To this we apply a per-pixel sigmoid, and define $L_{mask}$ as the average binary cross-entropy loss.  For an RoI associated with ground-truth class k, $L_{mask}$ is only defined on the k-th mask(other mask outputs do not contribute to the loss).        Decouples mask and class prediction  This definition of mask loss allows the network to generate masks for each class without competition among classes; we rely on the dedicated classification branch to predict the class label used to select the output mask.  With a per-pixel sigmoid and a binary loss, masks do not compete across classes; in contrast to FCNs for semantic segmentation using a per-pixel softmax and a multinomial cross-entropy loss.        Mask Representation  Unlike class labels or box offsets, extracting the spatial structure of masks can be addressed naturally by the pixel-to-pixel correspondence provided by convolutions.  Predicting an $m\\times m$ mask from each RoI using an FCN, allows each layer in the mask branch to have $m\\times m$ object spatial layout without collapsing it into a vector representation that lacks spatial dimensions.  This pixel-to-pixel behavior requires RoI features, small cropped feature maps, to be well aligned to faithfully preserve the explicit per-pixel spatial correspondence; RoIAlign.  RoIAlign  RoIPool(or RoI Pooling)  Quantizes a floating-number RoI to the discrete granularity(integerize by rounding) of the feature map, its result is then subdivided into spatial bins, and finally feature values covered by each bin are aggregated(usually by max pooling).          Problem: Quantizations introduce misalignments between the RoI and the extracted features. This may not impact classification, which is robust to small translations, but it has a large negative effect on predicting pixel-accurate masks.            RoIAlign layer  Instead of any quantization of the RoI boundaries or bins, use bilinear interpolation(Spatial transformer networks) to compute the exact values of the input features at four regularly sampled locations in each RoI bin, and aggregate the result(using max or average).  e.g.      (from CS231n lecture)  Feature $f_{xy}$ for point $(x, y)$ is a linear combination of features at its four neighboring grid cells:  $f_{xy} = \\sum_{i,j=1}^2 f_{i,j} \\text{max}(0, 1 - \\left\\vert x - x_i \\right\\vert) \\text{max}(0, 1 - \\left\\vert y - y_i \\right\\vert)$    RoIAlign improves mask accuracy by relative 10% to 50%, showing bigger gains under stricter localization metrics.Network Architecture  backbone:  Faster R-CNN with an FPN(ResNet-FPN)          FPN, Feature pyramid network(Lin et al.):  Uses a top-down architecture with lateral connections to build an in-network feature pyramid from a single-scale input.      RPN:  RoI align on each FPN feature maps        head:    Add a fully convolutional mask prediction branch, extending the Faster R-CNN box heads from the ResNet and FPN papers. Train with additional mask loss.Experiments  Comparison to the sota methods in instance segmentation  Ablations          Architecture        Multinomial vs. Independent Masks        Class-Specific vs. Class-Agnostic Masks  Interestingly, Mask R-CNN with classagnostic masks(predicting a single m×m output regardless of class)) is nearly as effective as class-specific masks(default; m×m mask per class).      RoIAlign  ResNet50-C4 backbone of stride 16    ResNet-50-C5 backbone of stride 32    Note that with RoIAlign, using stride-32 C5 features is more accurate than using stride-16 C4 features. Used with FPN, which has finer multi-level strides, RoIAlign shows better result.      Mask branch          Bounding Box Detection Results  Our approach largely closes the gap between object detection and the more \tchallenging instance segmentation task.Mask R-CNN for Human Pose Estimation      By modeling a keypoint’s location as a one-hot mask, and adopt Mask R-CNN to predict K masks, one for each of K keypoint types, this framework can easily be extended to human pose estimation.        Main Results and Ablations:        $\\therefore$ We have a unified model that can simultaneously predict boxes, segments, and keypoints while running at 5 fps.",
        "url": "/Mask_R-CNN"
    }
    ,
    
    "starfish-detection": {
        "title": "Starfish detection w/ TF Object Detection API",
        "author": "Darron Kwon",
        "category": "",
        "content": "TensorFlow - Help Protect the Great Barrier Reef      Worked in Feb. 2022. to study object detection model        Task:  Underwater + Small object detection        Score(IoU=0.50:0.95):  mAP@100: 0.364686 / AR@100: 0.491768 / Expected F2: 0.459727        Direct link: kaggle notebook  ",
        "url": "/starfish_detection"
    }
    ,
    
    "cs231n-lec15": {
        "title": "cs231n - Lecture 15. Detection and Segmentation",
        "author": "Darron Kwon",
        "category": "",
        "content": "Computer Vision Tasks  Image Classification: No spatial extent  Semantic Segmentation: No objects, just pixels  Object Detection/ Instance Segmentation: Multiple objectsSemantic Segmentation  Paired training data:  For each training image, each pixel is labeled with a semantic category.  At test time, classify each pixel of a new image.  Problem:  Classifying with only single pixel does not include context information.  Idea:          Sliding Window  Extract patch from full image, classify center pixel with CNN.  $\\color{red}{(-)}$ Very inefficient, not reusing shared features between overlapping patches.      Convolution  Encode the entire image with conv net, and do semantic segmentation on top.  $\\color{red}{(-)}$ CNN architectures often change the spatial sizes, but semantic segmentation requires the output size to be same as input size.      Fully Convolutional  Design a network with only convolutional layers without downsampling operators    $\\color{red}{(-)}$ convolutions at original image resolution is very expensive  $\\rightarrow$ Design convolutional network with downsampling and upsampling          Downsampling: Pooling, strided convolution      In-Network Upsampling: Unpooling, strided transpose convolution        Unpooling:  Nearest Neighbor: copy-paste to extended region  “Bed of Nails”: no positional argument, pad with zeros        Max Unpooling: use positions from poolying layer ahead, pad with zeros        Learnable Downsampling: Strided convolution  Output is a dot product between filter and input  Stride gives ratio between movement in input and output        Learnable Upsampling: Transposed convolution  Input gives weight for filter  Output contains copies of the filter weighted by the input, summing at where at overlaps in the output      Summary  Label each pixel in the image with a category label  Don’t differentiate instances, only care about pixelsObject Detection  Multiple Objects:  Each image needs a different number of outputs;  $\\rightarrow$ Apply a CNN to many different crops of the image, CNN classifies each crop as object or background.  $\\color{red}{(-)}$ Need to apply CNN to huge number of locations, scales, and aspect ratios, very computationally expensive.R-CNN      Girshick et al, “Rich feature hierarchies for accurate object detection andsemantic segmentation”, CVPR 2014    2-stage Detector: Region Proposal + Region Classification          Image as input      Crop bounding boxes with Selective Search Warp into same size pixels for CNN model      Input Warped images into CNN      Run classification on each        Algorithm:          Region Proposals: Selective Search Find “blobby” image regions that are likely to contain objects. Relatively fast to run; e.g. Selective Search gives 2000 region proposals in a few seconds on CPU.      CNN: For a pre-trained CNN architecture, change the number of classes on the last classification layer(detection classes N + background 1), fine-tune with dataset for Object Detection. From the region proposal input, outputs a fixed-length feature vector.      SVM: Category-Specific Linear SVMs Positive: ground-truth boxes Negative: IoU under 0.3 Scores each feature vector for classes, classifies whether each one is positive/negative(is_object).      Non-Maximum Suppression: with concept of IoU Intersection over Union; area of intersection divided by area of union If there are two boxes with IoU over 0.5, consider them proposed on the same object, leave one with the highest score.      Bounding Box Regression: adjust boxes from Selective Search                  Algorithm: Assume a bounding box $P^i = (P_x^i, P_y^i, P_w^i, P_h^i)$, Ground-truth box $G = (G_x, G_y, G_w, G_h)$. Define a function $d$, mapping $P$ close to $G$; \\(\\hat{G}_x = P_w d_x(P) + P_x\\) \\(\\hat{G}_y = P_h d_y(P) + P_y\\) \\(\\hat{G}_w = P_w \\mbox{exp}(d_w(P))\\) \\(\\hat{G}_h = P_h \\mbox{exp}(d_h(P))\\) where $d_{\\star}(P) = w_{\\star}^T \\phi_5(P)$, is modeled as a linear function(learnable weight vector w) of the POOL5 features of proposal P($\\phi_5(P)$). We learn $w_{\\star}$ by optimizing the regularized least squares objective(Ridge regression)  Learnable parameters on: 2, 3, 5                      Summary:  Score: 53.7% on Pascal VOC 2010  Problem:      1. Low Performance; Warping images into 224x224 size for AlexNet      2. Slow; Using all candidates from Selective Search      3. Not GPU-optimized; Using Selective Search and SVM      4. No Back Propagation; Not sharing computationsFast R-CNN      Girshick, “Fast R-CNN”, ICCV 2015        idea:  Pass the image through convnet before cropping. Crop the conv feature instead.    Algorithm:          Pass the full image through pre-trained CNN and extract feature maps.      Get RoIs from a proposal method(Selective Search) and crop by RoI Pooling, get fixed size feature vectors.      With RoI feature vectors, pass some fully connected layers and split into two branches.      1) pass softmax and classify the class of RoI. no SVM used. 2) Run bounding box regression.        Cropping Features: RoI Pool           Project RoI proposals(on input image) onto CNN image features.      Divide into subregions.      Run pooling(Max-pool) within each subregion.  $\\rightarrow$ Region features always be the same size regardless of input region size      Faster R-CNN      Ren et al, “Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks”, NIPS 2015        idea:  Fast R-CNN is not GPU-optimized; runtime dominated by region proposals.  By inserting Region Proposal Network(RPN), implemented end-to-end architecture.    Algorithm:          Pass the full image through pre-trained CNN and extract feature maps.      RPN: For K different anchor boxes of different size and scale at each point in the feature map, predict whether it contains an object(binary classification), and also predict a corrections from the anchor to the ground-truth box(regress 4 numbers per pixel).       Jointly train with 4 losses: 1) RPN classify object / not object 2) RPN regress box coordinates 3) Final classification score (object classes) 4) Final box coordinates        Glossing over many details:          Ignore overlapping proposals with non-max suppression      How are anchors determined?      How do we sample positive / negative samples for training the RPN?      How to parameterize bounding box regression?        Two-stage object detector:          First stage: Run once per image                  Backbone network          Region proposal network(RPN)                    Second stage: Run once per region                  Crop features: RoI pool/ align          Predict object class          Prediction bbox offset                    Single-Stage Object Detectors: YOLO / SSD / RetinaNet  Algorithm:          Divide input imgae into grid      Image a set of base boxes centered at each grid cell      Within each grid cell:                  Regress from each of the B base boxes to a final box with 5 numbers(dx, dy, dh, dw, confidence)          Predict scores for each of C classes(including background as a class)          Looks a lot like RPN, but category-specific                    Instance Segmentation: Mask R-CNN  He et al, “Mask R-CNN”, ICCV 2017Open Source FrameworksTensorFlow Detection APIDetectron2(Pytorch)Beyond 2D Object DetectionObject Detection + Captioning: Dense CaptioningDense Video Captioning: timestep “T”Objects + Relationships: Scene Graphs3D Object Detection      2D bounding box: (x, y, w, h)  $\\rightarrow$ 3D oriented bounding box: (x, y, z, w, h, l, r, p, y)  $\\rightarrow$ Simplified bbox: no roll &amp; pitch        Simple Camera Model:    A point on the image plane corresponds to a ray in the 3D space  A 2D bounding box on an image is a frustrum in the 3D space  Localize an object in 3D: The object can be anywhere in the camera viewing frustrum    Monocular Camera:            Same idea as Faster RCNN, but proposals are in 3D      3D bounding box proposal, regress 3D box parameters + class score        3D Shape Prediction: Mesh R-CNN",
        "url": "/cs231n_lec15"
    }
    ,
    
    "cs231n-lec14": {
        "title": "cs231n - Lecture 14. Visualizing and Understanding",
        "author": "Darron Kwon",
        "category": "",
        "content": "What’s going on inside ConvNets?Visualizing what models have learned  First layer: Visualize Filters  At the first layer, we can visualize the raw weights and see gabor-like features. While the higher layers are about the weights to the activations from the layer before, it is not very interpretable.  Last layer: Visualize Representations(feature vector)          Nearest neighbors in feature space      Dimensionality reduction: clustering with similarity; using simple algorithm(PCA) or more complex one(t-SNE)        Visualizing Activations:  Yosinski et al, “Understanding Neural Networks Through Deep Visualization”, ICML DL Workshop 2014.Understanding input pixels  Maximally Activating Patches  Run many images, record values of chosen channel(layer or neuron) and visualize image patches that correspond to maximal activations.  Saliency via Occlusion: Zeiler and Fergus, “Visualizing and Understanding Convolutional Networks”, ECCV 2014.  Mask part of the image before feeding to CNN, slide the occluder and check how much predicted probabilities change. Found that when there are multiple objects, the classification performance improved as the false class object masked.  Which pixels matter: Saliency via Backprop          Visualize the data gradient                  foward an image          set activations in layer of interest to all zero, except for a 1.0 for a neuron of interest          backprop to image input          squish the channels of gradients to get 1-dimensional activation map(or we can run segmentation using grabcut on this heatmap).                    Can also find biases; to see what false classifier actually see        Intermediate Features via (guided) backprop          Deconvolution-based approach:                  Feed image into net          Pick a layer, set the gradient there to be all zero except for one 1 for some neuron of interest          Backprop to image(use guided backprop to pass the positive influence; activation with positive values, using modified relu or deconvnet)                      Visualizing CNN features: Gradient Ascent  (Guided) backprop: Find the part of an image that a neuron responds to.  Gradient ascent: Generate a synthetic image that maximally activates a neuron.  \\(I^{\\ast} = \\mbox{argmax}_I f(I) + R(I)\\); (neuron value + regularizer)          Optimization-based approach: freeze/fix the weights and run “image update” to find images that maximize the score of chosen class.  Karen Simonyan, Andrea Vedaldi, Andrew Zisserman, “Deep Inside Convolutional Networks: Visualizing Image Classification Models and Saliency Maps”, Workshop at ICLR, 2014.      Find images that maximize some class score: \\(\\mbox{argmax}_I S_c(I) - \\lambda {\\lVert I \\rVert}^2_2\\)                  initialize image to zeros          forward image to compute current scores          set the gradient of the scores vector to be I, then backprop to image          make a small update to the image                    Instead of using L2 norm, we can use better regularizer(Gaussian blur image, Clip pixels with small values/gradients to 0, …)        Optimize in FC6 latent space instead of pixel space:Adversarial perturbations  Fooling Images / Adversarial Examples          Start from an arbitrary image      Pick an arbitrary class      Modify the image to maximize the class      Repeat until network is fooled        Ian Goodfellow, “Explaining and Harnessing Adversarial Examples”, 2014  Classifier is vulnerable to adversarical perturbation because of its linear nature. Check Ian Goodfellow’s lecture from 2017  Moosavi-Dezfooli, Seyed-Mohsen, et al. “Universal adversarial perturbations”, IEEE, 2017.Style Transfer  DeepDream: Amplify existing features  Rather than synthesizing an image to maximize a specific neuron, instead try to amplify the neuron activations at some layer in the network.  Choose an image and a layer in a CNN; repeat:          Forward: compute activations at chosen layer      Set gradient of chosen layer equal to its activation      Backward: Compute gradient on image      Update image        Feature Inversion  Mahendran and Vedaldi, “Understanding Deep Image Representations by Inverting Them”, CVPR 2015  Given a CNN feature vector for an image, find a new image that:          Matches the given feature vector      “looks natural” (image prior regularization)  \\(\\begin{align*}  x^{\\ast} &amp;= \\underset{x\\in\\mathbb{R}^{H \\times W \\times C}}{\\mbox{argmin}} l(\\Phi(x), \\Phi_0) + \\lambda \\mathcal{R}(x) \\\\      &amp; \\mbox{where loss } l = {\\lVert \\Phi(x) - \\Phi_0 \\rVert}^2  \\end{align*}\\)            Texture Synthesis: Nearest Neighbor  Given a sample patch of some texture, generate a bigger image of the same texture  Generate pixels one at a time in scanline order; form neighborhood of already generated pixels and copy nearest neighbor from input    Neural Texture Synthesis: Gram Matrix  a pair-wise statistics; interpret given CxHxW features as HxW grid of C-dimensional vectors. By computing outer product and sum up for all spacial locations($G=V^T V$), it gives CxC matrix measuring co-occurrence.          Pretrain a CNN on ImageNet (VGG-19)      Run input texture forward through CNN, record activations on every layer      At each layer compute the Gram matrix      Initialize generated image from random noise      Pass generated image through CNN, compute Gram matrix on each layer      Compute loss: weighted sum of L2 distance between Gram matrices      Backprop to get gradient on image      Make gradient step on image      GOTO 5        Neural Style Transfer: Feature + Gram Reconstruction          Extract content targets (ConvNet activations of all layers for the given image)      Extract style targets (Gram matrices of ConvNet activations of all layers)      Optimize over image to have:                  The content of the content image(activations match content)          The style of the stlye image(Gram matrices of activations match style)            Problem: requires many forward, backward passes; VGG is very slow          Solution: Train another neural network; Fast Style Transfer                      Fast Style Transfer  ",
        "url": "/cs231n_lec14"
    }
    ,
    
    "rotation": {
        "title": "Unsupervised Representation Learning by Predicting Image Rotations",
        "author": "Darron Kwon",
        "category": "",
        "content": "Unsupervised Representation Learning by Predicting Image RotationsGidaris et al. 2018https://github.com/gidariss/FeatureLearningRotNet  ConvNet:  (+) Unparalleled capacity to learn high level semantic image features  (-) Require massive amounts of manually labeled data, expensive and impractical to scale  $\\rightarrow$ Unsupervised Learning  Unsupervised semantic feature learning:  Learn image features by training ConvNets to recognize the 2d rotated images as input. With apparently simple task, provides a very powerful supervisory signal for semantic feature learning(Conv). Evaluated in various unsupervised feature learning benchmarks, exceeds SotA performance.FeatureLearningRotNet  How To:  First define a small set of discrete geometric transformations, then each of those transformations are applied to each image on the dataset and produced transformed images are fed to ConvNet model that is trained to recognize the transformation of each image.          Set of geometric transformations define the classification pretext task that the ConvNet has to learn; to achieve unsupervised semantic feature learning, it is important to properly choose those geometric transformations.            Purpose: to define the geometric transformations as rotations of 4 different degrees, ConvNet trained on the 4-way image classification task of recognizing one of the four Maximizing prob. $F^y(x^{y^{*}})$, probability of transformation y predicted by F, when given X is transformed by the transformation $y^{*}$.    With idea: In order a ConvNet model to be able recognize the rotation transformations, it will require to understand the concept of the objects depicted in the image\tsuch as their location, type, and pose.Overview  define a set of K discrete geometric transformations \\(G = \\{g(\\cdot\\vert y)\\}_{y=1}^K\\), where $g(.\\vert y)$ applies to input X, transformed image $X^y = g(X\\vert y)$  ConvNet model F(.) gets as input an image $X^{y^{\\ast}}$, to recognize unknown $y^{\\ast}$ yields as output a probability distribution over all possible transformations\t\\(F(X^{y^{\\ast}}\\vert\\theta) = \\{ F^y(X^{y^{\\ast}}\\vert\\theta) \\}_{y=1}^K\\), output F returns probs for all classes $y$.  Therefore, N training images \\(D = \\{ X_i \\}_{i=0}^N\\), the self-supervised training objective that ConvNet must learn to solve is: \\(\\mbox{min}_{\\theta}\\frac{1}{N}\\sum_{i=1}^N \\mbox{loss}(X_i,\\theta)\\), where the loss function is defined as: \\(\\mbox{loss}(X_i,\\theta) = -\\frac{1}{K}\\sum_{y=1}^K \\log(F^y(g(X_i|y)|\\theta))\\) (negative sum of log probs F for all classes y)  2d image rotations:  $Rot(X, \\phi)$, operator that rotates image X by $\\phi$ degrees  In this case 0, 90, 180, 270; K=4 for G, where $g(X|y)=Rot(X,(y-1)90)$Forcing the learning of semantic featuresFact that it is essentially impossible for a ConvNet model to effectively perform the above rotation recognition task, unless it has first learnt to recognize and detect classes of objects as well as their semantic parts in images.$\\rightarrow$ ATTENTION MAPS  By comparing the attention maps from two models trained on supervised and unsupervised way, we observe that both models seem to focus on roughly the same image regions.  Also, trained on the proposed rotation recognition task, visualized layer filters learnt appear to have a big variety of edge filters on multiple orientations and multiple frequencies, then the filters learnt by the supervised task.          Absence of low-level visual artifacts:  An additional important advantage of using image rotations over other geometric transformations, is that they do not leave e any easily detectable low-level visual artifacts that will lead the ConvNet to learn trivial features with no practical value for the vision perception tasks.      Well-posedness:  Human captured images tend to depict objects in an “up-standing” position. When defining the rotation recognition task, there is usually no ambiguity of what is the rotation transformation.      Implementing image rotations:  Flip and transpose.        $*$ Activation-based Attention Maps from “Paying More Attention to Attention”, Zagoruyko et al., 2017 - https://arxiv.org/abs/1612.03928  Activation tensor of a conv. layer: $A\\in R^{C\\times H\\times W}$ consists of C feautre planes with spatial dimensions HxW  Activation-based mapping function F w.r.t that layer: $\\mathcal{F}: R^{C\\times H\\times W} \\rightarrow R^{H\\times W}$  With implicit assumption: Absolute value of a hidden neuron activation(that results when the network is evaluated on given input) can be used as an indication about the importance of that neuron w.r.t. the specific input.  By considering, therefore, the absolute values of the elements of tensor A,\twe construct a spatial attention map by computing statistics of these values\tacross the channel dimension(C)          sum of abs: $F_{sum}(A)=\\sum_{i=1}^C\\vert A_i\\vert$      sum of abs, raised to the power of p(&gt;1): $F_{sum}^p(A) = \\sum_{i=1}^C\\vert A_i\\vert^p$      max of abs, raised to the pwoer of p(&gt;1): $F_{max}^p(A) = \\mbox{max}_{i=1,C}\\vert A_i\\vert^p$      Transfer LearningWith a model trained on proposed rotation recognition task with unlabeled data, freeze its early conv. layers and attach the layers from a supervised model, evaluate on a supervised task with a subset of labeled data.Experimental ResultsCIFAR-10 Experiments      RotNet implementation details:  Network-In-Network (NIN) architectures (Lin et al., 2013)  Pretask train: optimizer = SGD, batch_size = 128, momentum = 0.9, weight_decay = 5e−4, lr = 0.1, lr_decay = 0.2 (after 30, 60, 80 epochs), num_epochs = 100    Evaluation of the learned feature hierarchies:  Using the CIFAR-10 training images, train three RotNet models which have 3, 4, and 5 conv. blocks respectively. Afterwards, on top of the feature maps generated by each conv. block of each RotNet model, add classifiers trained in a supervised way on the object recognition task of CIFAR-10; consists of 3 FC layers. The accuracy results of CIFAR-10 test set:            In all cases the feature maps generated by the 2nd conv. block achieve the highest accuracy, i.e., between 88.26% and 89.06%. Then the accuracy gradually degrades, which we assume is because they start becoming more and more specific on the self-supervised task of rotation prediction.      Observe that increasing the total depth of the RotNet models leads to increased object recognition performance by the feature maps generated by earlier layers. We assume that this is because increasing the depth of the model and thus the complexity of its head (i.e., top ConvNet layers) allows the features of earlier layers to be less specific to the rotation prediction task.        Exploring the quality of the learned features w.r.t. the number of recognized rotations:            Observed that 4 discrete rotations as proposed achieved better performance over other cases.        Comparison against supervised and other unsupervised methods:              Model using the feature maps generated by the 2nd conv. block of a RotNet model with 4 conv. blocks in total.  (a) RotNet + non-linear: a non-linear classifier with 3 fully connected layers  (b) RotNet +conv.: three conv. layers + a linear prediction layer      Achieved best result among the unsupervised approaches      Very close to the fully supervised NIN model      Observed that fine-tuning the unsupervised learned features further improves the classification performance        Correlation between object classification task and rotation prediction task:            As the ability of the RotNet features for solving the rotation prediction task improves(as the rotation prediction accuracy increases), their ability to help solving the object recognition task improves as well(the object recognition accuracy also increases).      Object recognition accuracy converges fast w.r.t. the number of training epochs used for solving the pretext task of rotation prediction.        Semi-supervised setting:    Train a 4 block RotNet model on the rotation prediction task using the entire image dataset of CIFAR-10, then train on top of its feature maps object classifiers using only a subset of the available images and their corresponding labels. As feature maps we use those from 2nd conv. block of the RotNet model. As a classifier we use a set of convolutional layers of the same e architecture as the 3rd conv. block of a NIN model plus a linear classifier, all randomly initialized.  For training the object classifier we use for each category 20, 100, 400, 1000, or 5000 image examples. Comapred with a supervised model that is trained only on the available examples each time:          Observed that our unsupervised trained model exceeds in this semi-supervised setting the supervised model when the number of examples per category drops below 1000; can be useful when there are only small subset of labeled data.      Evaluation of self-supervised features trained in ImageNet      Train a RotNet model on the training images of the ImageNet dataset and evaluate the performance of the self-self-supervised features on the image classification tasks of ImageNet, Places, and PASCAL VOC datasets and on the object detection and object segmentation tasks of PASCAL VOC.        Implementation details:  Based on an AlexNet architecture, without local response normalization units, dropout units, or groups in the colvolutional layers, while it includes batch normalization units after each linear layer (either convolutional or fully connected).  Train with SGD, batch_size=192, momentum=0.9, weight_decay=5e-4, lr=0.01, lr_decay=0.1(after 10, 20 epochs), num_epochs=30    ImageNet classification task:            Observed that our approach surpasses all the other methods by a significant margin        Transfer learning evaluation on PASCAL VOC:    Places classification task:  ",
        "url": "/Rotation"
    }
    ,
    
    "cs231n-lec13": {
        "title": "cs231n - Lecture 13. Self-Supervised Learning",
        "author": "Darron Kwon",
        "category": "",
        "content": "Self-Supervised LearningGenerative vs. Self-supervised Learning  Both aim to learn from data without manual label annotation  Generative learning aims to model data distribution $p_{data}(x)$,  e.g., generating realistic images.  Self-supervised learning methods solve “pretext” tasks that produce good features for downstream tasks.          Learn with supervised learning objectives, e.g., classification, regression.      Labels of these pretext tasks are generated automatically.      Self-supervised pretext tasks  Example: learn to predict image transformations / complete corrupted images;  e.g. image completion, rotation prediction, “jigsaw puzzle”, coloriztaion.  Solving the pretext tasks allow the model to learn good features.  We can automatically generate labels for the pretext tasks.  Learning to generate pixel-level details is often unnecessary; learn high-level semantic features with pretext tasks instead(only encode high-level features sufficient enough to distinguish different objects, Contrastive Methods): Epstein, 2016How to evaluate a self-supervised learning method?  Self-supervised learning: With lots of unlabeled data, learn good feature extractors from self-supervised pretext tasks, e.g., predicting image rotations.  Supervised Learning: With small amount of labeled data on the target task, attach a shallow network on the feature extractor; train the shallow network and evaluate on the target task, e.g., classification, detection.Pretext tasks from image transformations  Predict Rotations  Gidaris et al., 2018 - (Paper Review)     Predict Relative Patch Locations  Doersch et al., 2015    Solving “jigsaw puzzles”; shuffled patches   Noroozi &amp; Favaro, 2016    Predict Missing Pixels(Inpainting); encoder-decoder  Pathak et al., 2016    Image Coloring; Split-brain Autoencoder  Richard Zhang/ Phillip Isola    Video Coloring; from t=0 reference frame to the later frames  Summary: Pretext tasks  Pretext tasks focus on “visual common sense”; by image transformations, can learn without supervision(big labeled data).  The models are forced learn good features about natural images, e.g., semantic representation of an object category, in order to solve the pretext tasks.  We don’t care about the performance of these pretext tasks, but rather how useful the learned features are for downstream tasks.  $\\color{red}{Problems}$: 1) coming up with individual pretext tasks is tedious, and 2) the learned representations may not be general; tied to a specific pretext task.Contrastive Representation LearningFor a more general pretext task,A formulation of contrastive learning      What we want:  $\\mbox{score}(f(x), f(x^+)) » score(f(x), f(x^-))$  x: reference sample, x+: positive sample, x-: negative sample  Given a chosen score function, we aim to learn an encoder function f that yields high score for positive pairs and low scores for negative pairs.        Loss function given 1 positive sample and N-1 negative samples:    seems familiar with Cross entropy loss for a N-way softmax classifier!  i.e., learn to find the positive sample from the N samples          Commonly known as the InfoNCE loss(van den Oord et al., 2018)  A lower bound on the mutual information between $f(x)$ and $f(x^+)$  \\(\\rightarrow MI[f(x), f(x^+)] - \\log(N) \\ge -L\\)  The larger the negative sample size(N), the tighter the bound      SimCLR: A Simple Framework for Contrastive Learning  Chen et al., 2020  Cosine similarity as the score function:  \\(s(u, v) = \\frac{u^T v}{\\lVert u \\rVert \\lVert v \\rVert}\\)  Use a projection network h(.) to project features to a space where contrastive learning is applied.      Generate positive samples through data augmentation:  random cropping, random color distortion, and random blur.    Evaluate: Freeze feature encoder, train(finetune) on a supervised downstream taskSimCLR design choices: Projection head($z=g(.)$)Linear / non-linear projection heads improve representation learning.  A possible explanation:          contrastive learning objective may discard useful information for downstream tasks.      representation space z is trained to be invariant to data transformation.      by leveraging the projection head g(.), more information can be preserved in the h representation space      SimCLR design choices: Large batch sizeLarge training batch size is crucial for SimCLR, but it causes large memory footprint during backpropagation; requires distributed training on TPUs.Momentum Contrastive Learning (MoCo)  He et al., 2020  Key differences to SimCLR:          Keep a running queue of keys (negative samples).      Compute gradients and update the encoder only through the queries.      Decouple min-batch size with the number of keys: can support a large number of negative samples.      MoCo V2  Chen et al., 2020  A hybrid of ideas from SimCLR and MoCo:  From SimCLR: non-linear projection head and strong data augmentation.  From MoCo: momentum-updated queues that allow training on a large number of negative samples (no TPU required).  Key takeaways(vs. SimCLR, MoCo V1):          Non-linear projection head and strong data augmentation are crucial for contrastive learning.      Decoupling mini-batch size with negative sample size allows MoCo-V2 to outperform SimCLR with smaller batch size (256 vs. 8192).      Achieved with much smaller memory footprint.      Instance vs. Sequence Contrastive Learning  Instance-level contrastive learning:  Based on positive &amp; negative instances.  E.g., SimCLR, MoCo  Sequence-level contrastive learning:  Based on sequential / temporal orders.  E.g., Contrastive Predictive Coding (CPC)Contrastive Predictive Coding (CPC)  van den Oord et al., 2018  Contrastive: contrast between “right” and “wrong” sequences using contrastive learning.  Predictive: the model has to predict future patterns given the current context.  Coding: the model learns useful feature vectors, or “code”, for downstream tasks, similar to other context self-supervised methods.  Encode all samples in a sequence into vectors $z_t = g_{\\mbox{enc}}(x_t)$  Summarize context (e.g., half of a sequence) into a context code $c_t$ using an auto-regressive model ($g_{\\mbox{ar}}$). The original paper uses GRU-RNN here.  Compute InfoNCE loss between the context $c_t$ and future code $z_{t+k}$ using the following time-dependent score funtion: $s_k(z_{t+k}, c_t) = z_{t+k}^T W_k c_t$, where $W_k$ is a trainable matrix.  Summary(CPC):  Contrast “right” sequence with “wrong” sequence.  InfoNCE loss with a time-dependent score function.  Can be applied to a variety of learning problems, but not as effective in learning image representations compared to instance-level methods.Other examples",
        "url": "/cs231n_lec13"
    }
    ,
    
    "cs231n-lec12": {
        "title": "cs231n - Lecture 12. Generative Models",
        "author": "Darron Kwon",
        "category": "",
        "content": "Supervised vs. Unsupervised      Supervised Learning:  Data: $(x,y)$; y is label  Goal: Learn a function to map $x\\rightarrow y$        Unsupervised Learning:  Data: x; no labels  Goal: Learn some underlying hidden structure of the data  Generative ModelingGiven training data, generate new samples from same distribution  Objectives:          Learn $p_{\\scriptstyle\\text{model}}(x)$ that approximates $p_{\\scriptstyle\\text{data}}(x)$      Sampling new x from $p_{\\scriptstyle\\text{model}}(x)$        Formulate as density estimation problems:          Explicit density estimation: explicitly define and solve for $p_{\\scriptstyle\\text{model}}(x)$.      Implicit density estimation: learn model that can sample from $p_{\\scriptstyle\\text{model}}(x)$ without explicitly defining it.        Why Generative Models?  Realistic samples for artwork, super-resolution, colorization, etc.  Learn useful features for downstream tasks such as classification.  Getting insights from high-dimensional data (physics, medical imaging, etc.)  Modeling physical world for simulation and planning (robotics and reinforcement learning applications)  …PixelRNN and PixelCNN; a brief overview  Fully visible belief network (FVBN)  is an explicit density model, defines tractable density function using chain rule to decompose the likelihood of an image x into product of 1-d distributions:    Then maximize likelihood of training data. It is a complex distribution over pixel values, express using a neural network.PixelRNN, van der Oord et al., 2016  Generate image pixels starting from corner, dependency on previous pixels modeled using an RNN(LSTM).     Drawback: sequential generation is slow in both training and inferencePixelCNN, van der Oord et al., 2016      Generate image pixels starting from corner, ependency on previous pixels modeled using a CNN over context region(masked convolution)    Training is faster than PixelRNN: it can parallelize convolutions since context region values known from training images.  Generation is still slow: for a 32x32 image, we need to do forward passes of the network 1024 times for a single image.        Improving PixelCNN performance  Gated convolutional layers, Short-cut connections, Discretized logistic loss, Multi-scale, Training tricks, etc.  See also PixelCNN++, Salimans et al., 2017  Summary  Pros:  Can explicitly compute likelihood p(x)  Easy to optimize  Good samples  Cons:  Sequential generation is slowVariational Autoencoder(VAE)  VAE is an explicit density model, defines intractable(approximate) density function with latent z:  $p_\\theta(x) = \\int p_\\theta(z)p_\\theta(x|z)\\, dz$  No dependencies among pixels, can generate all pixels at the same time. But cannot optimize directly, derive and optimize lower bound on likelihood insteadBackground: Autoencoders  Unsupervised approach for learning a lower-dimensional feature representation from unlabeled training data            z usually smaller than x: with dimensionality reduction to capture meaningful factors of variation in data. Train such that features can be used to reconstruct original data($\\hat{x}$)      “Autoencoding”; encoding input itself(L2 loss)      After training, throw away decoder and adjust to the final task            Encoder can be used to initialize a supervised model;  Transfer from large, unlabeled dataset(Autoencoder) to small, labeled dataset and fine-tune; train for final task.      But we can’t generate new images from an autoencoder because we don’t know the space of z. $\\rightarrow$ Variational Autoencoders for a generative model.Variational Autoencoders: Probabilistic spin on autoencoders  Assume training data \\(\\left\\{ x^{(i)}\\right\\} _{i=1}^N\\) is generated from the distribution of unobserved (latent) representation z  Intuition from autoencoders: x is an image, z is latent factors used to generate x: attributes, orientation, etc.  We want to estimate the true parameters $\\theta^*$ of this generative model given training data x.  Model representation:          p(z): Choose prior to be simple, e.g. Gaussian.      z: Reasonable for latent attributes, e.g. pose, how much smile.      p(x|z): Generating images, conditional probability is complex  $\\rightarrow$ represent with neural network      $p_\\theta(x)$: Learn model parameters to maximize likelihood of training data      Variational Autoencoders: Intractability  Data likelihood:  $p_\\theta(x) = \\int p_\\theta(z)p_\\theta(x|z)\\, dz$  where $p_\\theta(z)$ is a Simple Gaussian prior and $p_\\theta(x|z)$ is a decoder neural network, it is intractable to compute p(x|z) for every z.  while Monte Carlo estimation-$\\log p(x) \\approx \\log\\frac{1}{k}\\sum_{i=1}^k p(x|z^{(i)})$, where $z^{(i)}\\sim p(z)$- is too high variance.  divided by intractable $p_\\theta(x)$, Posterior density also intractable:  $p_\\theta(z|x) = p_\\theta(x|z)p_\\theta(z)/p_\\theta(x)$  Solution:  In addition to modeling $p_\\theta(x|z)$, learn $q_\\phi(z|x)$ that approximates the true posterior $p_\\theta(z|x)$. $q_\\phi$, approximate posterior allows us to derive a lower bound on the data likelihood that is tractable, which can be optimized.  Variational inference is to approximate the unknown posterior distribution from only the observed data x\\[\\begin{align*}\\log p_\\theta(x^{(i)})&amp;= \\mathbf{E}_{z~q_\\phi(z|x^{(i)})}\\left[ \\log p_\\theta(x^{(i)}) \\right] \\quad \\textit(p_\\theta(x^{(i)})\\ does\\ not\\ depend\\ on\\ z) \\\\&amp;= \\mathbf{E}_z \\left[\t\\log\\frac{p_\\theta(x^{(i)}|z)p_\\theta(z)}{p_\\theta(z|x^{(i)})} \\right] \\quad \\textit(Bayes'\\ Rule) \\\\&amp;= \\mathbf{E}_z \\left[ \t\\log\\frac{p_\\theta(x^{(i)}|z)p_\\theta(z)}{p_\\theta(z|x^{(i)})}\t\t\\frac{q_\\phi(z|x^{(i)})}{q_\\phi(z|x^{(i)})} \\right] \\quad \\textit(Multiply\\ by\\ constant)\\\\&amp;= \\mathbf{E}_z \\left[\\log p_\\theta(x^{(i)}|z) \\right]\t- \\mathbf{E}_z \\left[ \\log\\frac{q_\\phi(z|x^{(i)})}{p_\\theta(z)}\\right]\t+ \\mathbf{E}_z \\left[ \\log\\frac{q_\\phi(z|x^{(i)})}{p_\\theta(z|x^{(i)})}\\right] \\quad \\textit(Logarithms) \\\\&amp;= \\mathbf{E}_z \\left[\\log p_\\theta(x^{(i)}|z) \\right]\t- D_{KL}(q_\\phi(z|x^{(i)})|p_\\theta(z)) + D_{KL}(q_\\phi(z|x^{(i)})|p_\\theta(z|x^{(i)}))\\end{align*}\\]  With taking expectation with respect to z(using encoder network) let us write nice KL terms;          \\(\\mathbf{E}_z \\left[\\log p_\\theta(x^{(i)}\\vert z) \\right]\\): Decoder network gives $p_\\theta(x\\vert z)$, can compute estimate of this term through sampling(need some trick to differentiate through sampling). It reconstruct the input data.      \\(D_{KL}(q_\\phi(z\\vert x^{(i)})\\vert p_\\theta(z))\\): KL term between Gaussian for encoder and z prior has nice closed-form solution. Encoder makes approximate posterior distribution close to prior.      \\(D_{KL}(q_\\phi(z\\vert x^{(i)})\\vert p_\\theta(z\\vert x^{(i)}))\\): is intractable, we can’t compute this term; but we know KL divergence always greater than 0.            To maximize the data likelihood, we can rewrite\\(\\begin{align*}\\log p_\\theta (x^{(i)}) &amp;= \\mathbf{E}_z \\left[ \\log p _\\theta (x^{(i)}\\vert z) \\right]                      - D_{KL}(q_\\phi (z\\vert x^{(i)})\\vert p_\\theta (z)) + D_{KL}(q_\\phi (z\\vert x^{(i)})\\vert p_\\theta (z\\vert x^{(i)})) \\\\                      &amp;= \\mathcal{L}(x^{(i)},\\theta ,\\phi ) + (C\\ge 0)\\end{align*}\\)    \\(\\mathcal{L}(x^{(i)},\\theta,\\phi)\\): Decoder - Encoder  Tractable lower bound which we can take gradient of and optimize. Maximizing this evidence lower bound(ELBO), we can maximize $\\log p_\\theta(x)$. Later, we take minus on this term for the loss function of a neural network.  Encoder part; \\(D_{KL}(q_\\phi(z\\vert x^{(i)})\\vert p_\\theta(z))\\)  We choose q(z) as a Gaussian distribution, $q(z\\vert x) = N(\\mu_{z\\vert x}, \\Sigma_{z\\vert x})$. Computing the KL divergence, \\(D_{KL}(N(\\mu_{z\\vert x}, \\Sigma_{z\\vert x}))\\vert N(0,I))\\), having analytical solution.  Reparameterization trick z:  to make sampling differentiable, input sample $\\epsilon\\sim N(0,I)$ to the graph $z = \\mu_{z\\vert x} + \\epsilon\\sigma_{z\\vert x}$; where $\\mu, \\sigma$ are the part of computation graph.  Decoder part;  Maximize likelihood of original input being reconstructed, $\\hat{x}-x$.  For every minibatch of input data, compute $\\mathcal{L}$ graph forward pass and backprop.Variational Autoencoders: Generating Data  Diagonal prior on z for independent latent variables  Different dimensions of z encode interpretable factors of variation;  Also good feature representation taht can be computed using $q_\\phi(z\\vert x)$.Summary  Probabilistic spin to traditional autoencoders, allows generating data      Defines an intractable density; derive and optimize a (variational) lower bound    Pros:  Principled approach to generative models  Interpretable latent space  Allows inference of $q(z\\vert x)$, can be useful feature representation for other tasks  - Cons:  Maximizes lower bound of likelihood: not as good evaluation as tractable model  Samples mean; blurrier and lower quality compared to state-of-the-art (GANs)Generative Adversarial Networks(GANs)idea: Use a discriminator network to tell whether the generate image is within data distribution (“real”) or notTraining GANs: Two-player gameDiscriminator network: try to distinguish between real and fake imagesGenerator network: try to fool discriminator by generating real-looking images  Train jointly in minimax game;  Minimax objective function:  \\(\\mbox{min}_{\\theta_g} \\mbox{max}_{\\theta_d}\\left[\\mathbb{E}_{x\\sim {p_{data}}}\\log D_{\\theta_d}(x) + \\mathbb{E}_{z\\sim p(z)}\\log(1-D_{\\theta_d}(G_{\\theta_g}(z))) \\right]\\)  where $\\theta_g$ is an objective for the generator objective and $\\theta_d$ for the discriminator          $D_{\\theta_d}(x)$: Discriminator outputs likelihood in (0,1) of real image      $D_{\\theta_d}(G_{\\theta_g}(z))$: Discriminator output for generated fake data G(z)        Discriminator($\\theta_d$) wants to maximize objective such that D(x) is close to 1(real) and D(G(z)) is close to 0(fake)  Generator($\\theta_g$) wants to minimize objective such that D(G(z)) is close to 1(to fool discriminator)We alternate the minimax objection function with:  Gradient ascent on discriminator \\(\\mbox{max}_{\\theta_d}\\left[\\mathbb{E}_{x\\sim p_{data}}\\log D_{\\theta_d}(x) + \\mathbb{E}_{z\\sim p(z)}\\log(1-D_{\\theta_d}(G_{\\theta_g}(z))) \\right]\\)  1) Gradient descent on generator \\(\\mbox{min}_{\\theta_g}\\mathbb{E}_{z\\sim p(z)}\\log(1-D_{\\theta_d}(G_{\\theta_g}(z)))\\)          In practice, optimizing this generator objective does not work well;  When sample is likely fake, want to learn from it to improve generator (move to the right on X axis), but gradient near 0 in X axis is relatively flat; Gradient signal is dominated by region where sample is already good(near 1).          2) Instead: Gradient ascent on generator, different objective \\(\\mbox{max}_{\\theta_d}\\mathbb{E}_{z\\sim p(z)}\\log(D_{\\theta_d}(G_{\\theta_g}(z)))\\)          Rather than minimizing likelihood of discriminator being correct, maximize likelihood of discriminator being wrong. Same objective of fooling discriminator, but now higher gradient signal for bad samples.              GAN training Algorithm          After training, use generator network to generate new images  GAN: Convolutional Architectures      Generator is an upsampling network with fractionally-strided convolutions  Discriminator is a convolutional network        Architecture guidelines for stable Deep Conv GANs          Replace any pooling layers with strided convolutions(discriminator) and fractional-strided convolutions(generator).      Use batchnorm in both network.      Remove fully connected hidden layers for deeper architecture.      Use ReLU activation in generator for all layers except for the output, which uses Tanh.      Use LeakyReLU activation in the discriminator for all layers.      GAN: Interpretable Vector Math  works similar to a language model2017: Explosion of GANs  “The GAN Zoo”, https://github.com/hindupuravinash/the-gan-zoo  check https://github.com/soumith/ganhacks for tips and tricks for training GANsScene graphs to GANs  Specifying exactly what kind of image you want to generate. The explicit structure in scene graphs provides better image generation for complex scenes.Summary: GANs  Don’t work with an explicit density function      Take game-theoretic approach: learn to generate from training distribution through 2-player game    Pros:          Beautiful, state-of-the-art samples        Cons:          Trickier / more unstable to train      Can’t solve inference queries such as $p(x)$, $p(z\\vert x)$        Active areas of research:          Better loss functions, more stable training (Wasserstein GAN, LSGAN, many others)      Conditional GANs, GANs for all kinds of applications        Useful Resources on Generative Models  CS236: Deep Generative Models (Stanford)  CS 294-158 Deep Unsupervised Learning (Berkeley)",
        "url": "/cs231n_lec12"
    }
    ,
    
    "cs231n-lec11": {
        "title": "cs231n - Lecture 11. Attention and Transformers",
        "author": "Darron Kwon",
        "category": "",
        "content": "Attention with RNNsImage Captioning using spatial featuresInput: Image IOutput: Sequence y $= y_1, y_2, \\ldots, y_T$Encoder: $h_0 = f_W(z)$, where z is spatial CNN features, $f_W(\\cdot)$ is an MLPDecoder: $y_t = g_v(y_{t-1}, h_{t-1}, c)$, where context vector c is often $c=h_0$Problem: Input is “bottlenecked” through c; especially in a long descriptions.  Model needs to encode everything it wants to say within cAttention idea: New context vector c_t at every time stepEach context vector will attend to different image regions  Alignment scores(scalars): $H \\times W$ matrix e  $e_{t,i,j} = f_{\\mbox{att}}(h_{t-1}, z_{i,j})$  where $f_{\\mbox{att}}(\\cdot)$ is an MLP  Normalize to get attention weights:  $a_{t,:,:} = \\mbox{softmax}(e_{t,:,:})$,  $0&lt;a_{t,i,j}&lt;1$, attention values sum to 1  Compute context vector c: multiply CNN features and Attention weights  $c_t = \\sum_{i,j} a_{t,i,j} z_{t,i,j}$  Decoder: $y_t = g_v(y_{t-1}, h_{t-1}, \\color{red}{c_t})$Each timestep of decode uses a different context vector that looks(attend) at different parts of the input image. This entire process is differentiable; model chooses its own attention weights. No attention supervision is required.Similar tasks in NLP - Language translation exampleVanilla Encoder-Decoder setting:  Input: sequence x $= x_1, x_2, \\ldots, x_T$  Output: sequence y $= y_1, y_2, \\ldots, y_T$  Encoder: $h_0 = f_W(z)$, where $z_t = \\mbox{RNN}(x_t, u_{t-1})$, $f_W(\\cdot)$ is MLP, u is the hidden RNN state  Decoder: $y_t = g_v(y_{t-1}, h_{t-1}, c)$, where context vector c is often $c=h_0$Attention in NLP  Alignment scores(scalars):  $e_{t,i} = f_{\\mbox{att}}(h_{t-1}, z_t)$, where $f_{\\mbox{att}}(\\cdot)$ is an MLP  Normalize to get attention weights:  $a_{t,:} = \\mbox{softmax}(e_{t,:})$,  $0&lt;a_{t,i}&lt;1$, attention values sum to 1  Compute context vector c:  $c_t = \\sum_i a_{t,i} z_{t,i}$  Decoder: $y_t = g_v(y_{t-1}, h_{t-1}, \\color{red}c_t)$Heatmap: visualization of attention weights; without any attention supervision, model learns different word orderings for different languagesGeneral Attention LayerAttention in image captioning beforeSingle query settingInputs  input vectors: x(shape: $N\\times D$)  Attention operation is permutation invariant; produces the same output regardless of the order of elements(features) in the input vector. Stretch $H\\times W = N$ into N vectors, transform $H\\times W\\times D$ features into $N\\times D$ input vectors x(similar to attention in NLP).  Query: h(shape: D)Operations  Alignment          Change $f_{\\mbox{att}}(\\cdot)$ to a simple dot product:  $e_i = h\\cdot x_i$; only works well with key &amp; value transformation trick      Change $f_{\\mbox{att}}(\\cdot)$ to a scaled dot product:  $e_i = h\\cdot x_i / \\sqrt{D}$;  Larger dimensions means more terms in the dot product sum. So, the variance of the logits is higher. Large magnitude(length) vectors will produce much higher logits. Then, the post-softmax distribution(e) has lower-entropy(high uncertainty) assuming logits are I.I.D. Ultimately, these large magnitude vectors will cause softmax to peak and assign very little weight to all others. To reduce this effect, divide by $sqrt{D}$.        Attention: $\\mathbf{a} = \\mbox{softmax}(\\mathbf{e})$  Output: $\\mathbf{c} = \\sum_i a_i x_i$Outputs\t- context vector: c(shape: D)Multiple query settingInputs  input vectors: x(shape: $N\\times D$)  Queries: q(shape: $M\\times D$); multiple query vectorsOperations  Alignment: $e_{i,j} = q_j\\cdot x_i / \\sqrt{D}$  Attention: $\\mathbf{a} = \\mbox{softmax}(\\mathbf{e})$  Output: $y_j = \\sum_i a_{i,j} x_i$Outputs  context vectors: y(shape: D);  each query creates a new output context vectorWeight layers addedNotice that the input vectors x are used for both the alignment(e) and attention calculations(y); We can add more expressivity to the layer by adding a different FC layer before each of the two steps. The input and output dimensions can now change depending on the key and value FC layers.Inputs  input vectors: x(shape: $N\\times D$)  Queries: q(shape: $M\\times D_k$)Operations  Key vectors: $\\mathbf{k} = \\mathbf{x}W_k$  Value vectors: $\\mathbf{v} = \\mathbf{x}W_v$  Alignment: $e_{i,j} = q_j\\cdot k_i / \\sqrt{D}$  Attention: $\\mathbf{a} = \\mbox{softmax}(\\mathbf{e})$  Output: $y_j = \\sum_i a_{i,j} v_i$Outputs  context vectors: y(shape: $D_v$);Self attention layerRecall that the query vector was a function of the input vectors; Encoder $h_0=f_W(z)$, where z is spatial CNN features, $f_W(\\cdot)$ is an MLP. We can calculate the query vectors from the input vectors, defining a “self-attention” layer. No input query vectors anymore, instead query vectors are calculated using a FC layer.Inputs  input vectors: x(shape: $N\\times D$)Operations  Key vectors: $\\mathbf{k} = \\mathbf{x}W_k$  Value vectors: $\\mathbf{v} = \\mathbf{x}W_v$  Query vectors: $\\mathbf{q} = \\mathbf{x}W_q$  Alignment: $e_{i,j} = q_j\\cdot k_i / \\sqrt{D}$  Attention: $\\mathbf{a} = \\mbox{softmax}(\\mathbf{e})$  Output: $y_j = \\sum_i a_{i,j} v_i$Outputs  context vectors: y(shape: $D_v$)Positional encodingSelf attention attends over sets of inputs; is permutation invariant. To encode the ordered sequences(e.g. language, image), concatenate special positional encoding $p_j$ to each input vector $x_j$.$\\mathit{pos}: N\\rightarrow R^d$ to process the position j of the vector into a d-dimensional vector; $p_j = \\mathit{pos}(j)$Desiderata of $\\mathit{pos}(\\cdot)$:  Should output a unique encoding for each time-step(word’s position in a sentence).  Distance between any two time-steps should be consistent across sentences with different lengths(variable inputs).  Model should generalize to longer sentences without any efforts. Its values should be bounded.  Must be deterministic.Options for $\\mathit{pos}(\\cdot)$:  Learn a lookup table:          Learn parameters to use for $\\mathit{pos}(t)$ for $t \\in [0,T)$      Lookup table contains $T\\times d$ parameters        Design a fixed function with the desiderataMasked self-attention layerManually set alignment scores to $-\\infty$, prevent vectors from looking at future vectors.Multi-head self attention layerMultiple self-attention heads in parallel; similar to ensembleComparing RNNs to TransformersRNNs(+) LSTMs work reasonably well for long sequences.(-) Expects an ordered sequences of inputs(-) Sequential computation: subsequent hidden states can only be computed after the previous ones are done.Transformers(+) Good at long sequences. Each attention calculation looks at all inputs.(+) Can operate over unordered sets or ordered sequences with positional encodings.(+) Parallel computation: All alignment and attention scores for all inputs can be done in parallel.(-) Requires a lot of memory: N x M alignment and attention scalers need to be calculated and stored for a single self-attention head.TransformersImage Captioning using transformers  No recurrence at allInput: Image IOutput: Sequence y $= y_1, y_2, \\ldots, y_T$Encoder: $c = T_W(z)$, where z is spatial CNN features, $T_W(\\cdot)$ is the transformer encoderDecoder: $y_t = T_D(y_{0:t-1}, c)$, where $T_D(\\cdot)$ is the transformer decoderThe Transformer encoder blockInputs: Set of vectors xOutputs: Set of vectors ySelf-attention is the only interaction between vectors; Layer norm and MLP operate independently per vector. Highly scalable, highly parallelizable, but high memory usage.The Transformer Decoder blockInputs: Set of vectors x and Set of context vector cOutputs: Set of vectors yMasked Self-attention only interacts with past inputs(x, or previous output $y_{t-1}$). Multi-head attention block is NOT self-attention; it attends over the transformer encoder outputs. In this phase, we inject image features into the decoder. Highly scalable, highly parallelizable, but high memory usage.Image Captioning using ONLY transformers      Transformers from pixels to language  Dosovitskiy et al, “An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”, ArXiv 2020  colab notebook link        Note: in Google Colab - TPU runtime setting  import tensorflow as tfimport os# TPU initializationresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])tf.config.experimental_connect_to_cluster(resolver)tf.tpu.experimental.initialize_tpu_system(resolver)strategy = tf.distribute.TPUStrategy(resolver)# compile in strategy.scopedef create_model():  return tf.keras.Sequential(      [tf.keras.layers.Conv2D(256, 3, activation='relu', input_shape=(28, 28, 1)),       tf.keras.layers.Conv2D(256, 3, activation='relu'),       tf.keras.layers.Flatten(),       tf.keras.layers.Dense(256, activation='relu'),       tf.keras.layers.Dense(128, activation='relu'),       tf.keras.layers.Dense(10)])with strategy.scope():  model = create_model()  model.compile(optimizer='adam',                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),                metrics=['sparse_categorical_accuracy'])Summary  Adding attention to RNNs allows them to “attend” to different parts of the input at every time step  The general attention layer is a new type of layer that can be used to design new neural network architectures  Transformers are a type of layer that uses self-attention and layer norm.          It is highly scalable and highly parallelizable      Faster training, larger models, better performance across vision and language tasks      They are quickly replacing RNNs, LSTMs, and may even replace convolutions.      ",
        "url": "/cs231n_lec11"
    }
    ,
    
    "cs231n-lec10": {
        "title": "cs231n - Lecture 10. Recurrent Neural Networks",
        "author": "Darron Kwon",
        "category": "",
        "content": "RNN: Process Sequences  one to one; vanilla neural networks  one to many; e.g. Image Captioning(image to sequence of words)  many to one; e.g. Action Prediction(video sequence to action class)  many to many(1); e.g. Video Captioning(video sequence to caption)      many to many(2); e.g. Video Classification on frame level    Why existing convnets are insufficient?:  Variable sequence length inputs and outputs      Key idea: RNNs have an “internal state” that is updated as a sequence is processed.    RNN hidden state update:  \\(h_t = f_W(h_{t-1}, x_t)\\)  The same function and the same set of parameters are used at every time step.      RNN output generation: \\(y_t = f_{W_hy}(h_t)\\)    Simple(Vanilla) RNN: The state consists of a single hidden vector h  $h_t = \\mbox{tanh}(W_hh h_{t-1} + W_{xh}x_t)$  $y_t = W_{hy}h_t$Sequence to Sequence(Seq2Seq): Many-to-One + One-to-Many      Many-to-One: Encode input sequence in a single vector  One-to-Many: Produce output sequence from single input vector  Encoder produces the last hidden state $h_T$ and decoder uses it as a default $h_0$. Weights($W_1, W_2$) are re-used for each procedure.        Example: Character-level Language Model Sampling  Backpropagation  Backpropagation through time: Computationally Expensive  Forward through entire sequence to compute loss, then backward through entire sequence to compute gradient.  Truncated Backpropagation through time:  Run forward and backward through chunks of the sequence instead of whole sequence. Carry hidden states forward in time forever, but only backpropagate for some smaller number of steps.RNN tradeoffs  RNN Advantages:          Can process any length input      Computation for step t can (in theory) use information from many steps back      Model size doesn’t increase for longer input      Same weights applied on every timestep, so there is symmetry in how inputs are processed.        RNN Disadvantages:          Recurrent computation is slow      In practice, difficult to access information from many steps back      Image Captioning: CNN + RNN  Instead of the final FC layer and the classifier in CNN, use FC output v(say 4096 length vector) to formulate the default hidden state $h_0$ in RNN.          before: $h = \\mbox{tanh}(W_{xh}\\ast x+W_{hh}\\ast h)$      now: $h=\\mbox{tanh}(W_{xh}\\ast x + W_{hh}\\ast h + W_{ih}\\ast v)$        RNN for Image Captioning  Re-sample the previous output $y_{t-1}$ as the next input $x_t$, iterate untill $y_t$ sample takes &lt;END&gt; token.Visual Question Answering: RNNs with AttentionOther tasks  Visual Dialog: Conversations about images  Visual Language Navigation: Go to the living room  Agent encodes instructions in language and uses an RNN to generate a series of movements as the visual input changes after each move.  Visual Question Answering: Dataset Bias  With different types(Image + Question + Answer) of data used, model performances are better.Long Short Term Memory (LSTM)  Vanilla RNN  \\(h_t = \\mbox{tanh}(W_{hh}h_{t-1} + W_{xh}x_t) \\\\      = \\mbox{tanh}\\left(          (W_{hh} \\ W_{hx}) {\\begin{pmatrix} h_{t-1} \\\\ x_t \\end{pmatrix}}                  \\right) \\\\      = \\mbox{tanh}\\left(          W {\\begin{pmatrix} h_{t-1} \\\\ x_t \\end{pmatrix}}                  \\right)\\)      \\(\\frac{\\partial h_t}{\\partial h_{t-1}} = \\mbox{tanh}' (W_{hh}h_{t-1} + W_{xh}x_t)W_{hh}\\)  $\\frac{\\partial L}{\\partial W} = \\sum_{t=1}^T \\frac{\\partial L_t}{\\partial W}$\\[\\begin{align*}  \\frac{\\partial L_T}{\\partial W} &amp;= \\frac{\\partial L_T}{\\partial h_T}                                      \\frac{\\partial h_t}{\\partial h_{t-1}}\\cdots                                      \\frac{\\partial h_1}{\\partial W} \\\\                                   &amp;= \\frac{\\partial L_T}{\\partial h_T}(\\prod_{t=2}^T \\frac{\\partial h_t}{\\partial h_{t-1}})\\frac{\\partial h_1}{\\partial W} \\\\                                  &amp;= \\frac{\\partial L_T}{\\partial h_T}(\\prod_{t=2}^T \\mbox{tanh}'(W_{hh}h_{t-1} + W_{xh}x_t))W_{hh}^{T-1} \\frac{\\partial h_1}{\\partial W}  \\end{align*}\\]    Problem  As the output of tanh function are in range of [-1,1] and almost smaller than 1, vanilla RNN has vanishing gradients. If we assume no non-linearity, the gradient will be \\(\\frac{\\partial L_T}{\\partial W} = \\frac{\\partial L_T}{\\partial h_T}W_{hh}^{T-1}\\frac{\\partial h_1}{\\partial W}\\). In this case, when the largest singular value is greater than 1, we have exploding gradients, while the value is smaller than 1, we have vanishing gradients.H = 5\t# dimensionality of hidden stateT = 50\t# number of time stepsWhh = np.random.randn(H, H)# forward pass of an RNN (ignoring inputs x)hs = {}ss = {}hs[-1] = np.random.randn(H)for t in xrange(T):    ss[t] = np.dot(Whh, hs[t-1])    hs[t] = np.maximum(0, ss[t])\t# backward pass of the RNNdhs = {}dss = {}dhs[T-1] = np.random.randn(H) #start off the chain with random gradientfor t in reversed(xrange(T)):    dss[t] = (hs[t] &gt; 0) * dhs[t]\t# backprop through the nonlinearity\tdhs[t-1] = np.dot(Whh.T, dss[t])\t# backprop into previous hidden state\t\t# \"Whh.T\" multiplied by \"T\" times!      For exploding gradients: control with gradient clipping.  For vanishing gradients: change the architecture, LSTM introduced.        LSTM:  \\(\\begin{pmatrix} i \\\\ f \\\\ o \\\\ g \\end{pmatrix} =  \\begin{pmatrix} \\sigma \\\\ \\sigma \\\\ \\sigma \\\\ \\mbox{tanh}\\end{pmatrix} W \\begin{pmatrix} h_{t-1} \\\\ x_t \\end{pmatrix}\\)  \\(c_t = f \\odot c_{t-1} + i \\odot g\\), memory cell update  \\(h_t = o \\odot \\mbox{tanh}(c_t)\\), hidden state update  where W is a stack of $W_h$ and $W_x$  i: Input gate, whether to write to cellf: Forget gate, Whether to erase cello: Output gate, How much to reveal cellg: Gate gate, How much to write to cell      Backpropagation from $c_t$ to $c_{t-1}$ only elementwise multiplication by f, no matrix multiply by W. Notice that the gradient contains the f gate’s vector of activations; it allows better control of gradients values, using suitable parameter updates of the forget gate. Also notice that are added through the f, i, g, and o gates, we can have better balancing of gradient values.        Recall: “PlainNets” vs. ResNets  ResNet is to PlainNet what LSTM is to RNN, kind of.  Additive skip connections        Do LSTMs solve the vanishing gradient problem?:  The LSTM architecture makes it easier for the RNN to preserve information over many timesteps. e.g. If $f=1$ and $i=0$, then the information of that cell is preserved indefinitely. By contrast, it’s harder for vanilla RNN to learn a recurrent weight matrix $W_h$ that preserves information in hidden state.  LSTM doesn’t guarantee that there is no vanishing/exploding gradient, but it does provide an easier way for the model to learn long-distance dependencies.        in between: Highway Networks, Srivastava et al, 2015, [arXiv:1505.00387v2]  A new architecture designed to ease gradient-based training of very deep networks. To regulate the flow of information and enlarge the possibility of studying extremely deep and efficient architectures.  $g = T(x, W_T)$, $y = g \\odot H(x, W_H) + (1-g)\\odot x$  Other RNN Variants  Neural Architecture Search(NAS) with Reinforcement Learning, Zoph et Le, 2017          RNN to design model; idea that we can represent the model architecture with a variable-length string.      Apply reinforcement learning on a neural network to maximize the accuracy(as a reward) on validation set, find a good architecture.        GRU; smaller LSTM, “Learning phrase representations using rnn encoder-decoder for statistical machine translation”, Cho et al., 2014  “An Empirical Exploration of Recurrent Network Architectures”, Jozefowicz et al., 2015  LSTM: A Search Space Odyssey, Greff et al., 2015Recurrence for Vision  LSTM wer a good default choice until this year  Use variants like GRU if you want faster compute and less parameters  Use transformers (next lecture) as they are dominating NLP models  almost everyday there is a new vision transformer modelSummary  RNNs allow a lot of flexibility in architecture design  Vanilla RNNs are simple but don’t work very well  Common to use LSTM or GRU: their additive interactions improve gradient flow  Backward flow of gradients in RNN can explode or vanish. Exploding is controlled with gradient clipping. Vanishing is controlled with additive interactions (LSTM)  Better/simpler architectures are a hot topic of current research, as well as new paradigms for reasoning over sequences  Better understanding (both theoretical and empirical) is needed.",
        "url": "/cs231n_lec10"
    }
    ,
    
    "cs231n-lec9": {
        "title": "cs231n - Lecture 9. CNN Architectures",
        "author": "Darron Kwon",
        "category": "",
        "content": "Review      LeCun et al., 1998  $5\\times 5$ Conv filters applied at stride 1  $2\\times 2$ Subsampling (Pooling) layers applied at stride 2  i.e. architecture is [CONV-POOL-CONV-POOL-FC-FC]        Stride: Downsample output activations  Padding: Preserve input spatial dimensions in output activations  Filter: Each conv filter outputs a “slice” in the activation  Case StudiesAlexNet: First CNN-based winner  Architecture: [CONV1-MAXPOOL1-NORM1-CONV2-MAXPOOL2-NORM2-CONV3-CONV4-CONV5-MaxPOOL3-FC6-FC7-FC8]          Input: $227\\times 227\\times 3$ images      First layer(CONV1):  96 $11\\times 11$ filters applied at stride 4, pad 0  Output volume: $W’ = (W-F+2P)/S + 1 \\rightarrow$ $55\\times 55\\times 96$  Parameters: $(11* 11* 3 +1)* 96 =$ 36K      Second layer(POOL1):  $3\\times 3\\times$ filters applied at stride 2  Output volume: $27\\times 27\\times 96$  Parameters: 0  $\\vdots$      CONV2($27\\times 27\\times 256$):  256 $5\\times 5$ filters applied at stride 1, pad 2      MAX POOL2($13\\times 13\\times 256):  $3\\times 3\\times$ filters applied at stride 2      CONV3($13\\times 13\\times 384$):  384 $3\\times 3$ filters applied at stride 1, pad 1      CONV4($13\\times 13\\times 384$):  384 $3\\times 3$ filters applied at stride 1, pad 1      CONV5($13\\times 13\\times 256$):  256 $3\\times 3$ filters applied at stride 1, pad 1      MAX POOL3($6\\times 6\\times 256$):  $3\\times 3\\times$ filters applied at stride 2      FC6(4096): 4096 neurons      FC7(4096): 4096 neurons      FC8(1000): 1000 neurons (class scores)        Historical note:          Network spread across 2 GPUs, half the neurons (feature maps) on each GPU.      CONV1, CONV2, CONV4, CONV5: Connections only with feature maps on same GPU      CONV3, FC6, FC7, FC8: Connections with all feature maps in preceding layer, communication across GPUs        Details/Retrospectives:          Krizhevsky et al. 2012      first use of ReLU      used Norm layers (not common anymore)      heavy data augmentation      dropout 0.5      batch size 128      SGD Momentum 0.9      Learning rate 1e-2, reduced by 10 manually when val accuracy plateaus      L2 weight decay 5e-4      7 CNN ensemble: 18.2% $\\rightarrow$ 15.4%      ZFNet: Improved hyperparameters over AlexNet  AlexNet but:          CONV1: change from ($11\\times 11$ stride 4) to ($7\\times 7$ stride 2)      CONV3,4,5: instead of 384, 384, 256 filters use 512, 1024, 512      ImageNet top 5 error: 16.4% -&gt; 11.7%      Zeiler and Fergus, 2013      VGGNet: Deeper Networks  Small filters, Deeper networks          8 layers (AlexNet) $\\rightarrow$ 16 - 19 layers (VGG16Net)      Only $3\\times 3$ CONV stride 1, pad 1 and $2\\times 2$ MAX POOL with stride 2      11.7% top 5 error(ZFNet) $\\rightarrow$ 7.3% top 5 error in ILSVRC’14            Why use smaller filters?  :Stack of three $3\\times 3$ conv (stride 1) layers has same effective receptive field as one $7\\times 7$ conv layer, but with deeper, more non-linearities and fewer parameters          TOTAL memory: 24M * 4 bytes ~= 96MB / image (for a forward pass)  TOTAL params: 138M parameters  Most memory is in early CONV, Most params are in late FC    Details:          Simonyan and Zisserman, 2014      ILSVRC’14 2nd in classification, 1st in localization      Similar training procedure as Krizhevsky 2012      No Local Response Normalisation (LRN)      Use VGG16 or VGG19 (VGG19 only slightly better, more memory)      Use ensembles for best results      FC7 features generalize well to other\ttasks      GoogLeNet  Inception module:          design a good local network topology(network within a network) and then stack these modules on top of each other      Apply parallel filter operations on the input from previous layer: Multiple receptive field sizes for convolution(1x1, 3x3, 5x5), Pooling(3x3)      Concatenate all filter outputs together channel-wise        “Bottlenect” layers to reduce computational complexity of inception:          use 1x1 conv to reduce feature channel size; alternatively, interpret it as applying the same FC layer on each input pixel      preserves spatial dimensions, reduces depth        Full GoogLeNet Architecture:          Stem Network: [Conv-POOL-2x CONV-POOL]      Stack Inception modules: with dimension reduction on top of each other      Classifier output: [(H*W*c)-Avg POOL-(1*1*c)-FC-Softmax]  Global average pooling layer before final FC layer, avoids expensive FC layers      Auxiliary classification layers: [AvgPool-1x1 Conv-FC-FC-Softmax]  to inject additional gradient at lower layers        Details:          Deeper networks, with computational efficiency      ILSVRC’14 classification winner (6.7% top 5 error)      22 layers      Only 5 million parameters(12x less than AlexNet, 27x less than VGG-16)      Efficient “Inception” module      No FC layers      ResNet      From 2015, “Revolution of Depth”; more than 100 layers    Stacking deeper layers on a “plain” convolutional neural network results in lower both test and training error. The deeper model performs worse, but it’s not caused by overfitting.          Fact: Deep models have more representation power (more parameters) than shallower models.      Hypothesis: the problem is an optimization problem, deeper models are harder to optimize      Solution: copying the learned layers from the shallower model and setting additional layers to identity mapping.        “Residual block”:          Use network layers to fit a residual mapping instead of directly trying to fit a desired underlying mapping        Full ResNet Architecture:          Stack residual blocks      Every residual block has two $3\\times 3$ conv layers      Periodically, double number of filters and downsample spatially using stride 2 (/2 in each dimension). Reduce the activation volume by half.      Additional conv layer at the beginning (7x7 conv in stem)      No FC layers at the end (only FC 1000 to output classes)      (In theory, you can train a ResNet with input image of variable sizes)            For deeper networks(ResNet-50+):  use bottleneck layer to improve efficiency (similar to GoogLeNet)  e.g. [(28x28x256 INPUT)-(1x1 CONV, 64)-(3x3 CONV, 64)-(1x1 CONV, 256)-(28x28x256 OUTPUT)]    Training ResNet in practice:          Batch Normalization after every CONV layer      Xavier initialization from He et al.      SGD + Momentum (0.9)      Learning rate: 0.1, divided by 10 when validation error plateaus      Mini-batch size 256      Weight decay of 1e-5      No dropout used        Experimental Results:          He et al., 2015      Able to train very deep networks without degrading (152 layers on ImageNet, 1202 on Cifar)      Deeper networks now achieve lower training error as expected      Swept 1st place in all ILSVRC and COCO 2015 competitions      ILSVRC 2015 classification winner (3.6% top 5 error); better than human performance!        Details:          Very deep networks using residual connections      152-layer model for ImageNet      ILSVRC’15 classification winner(3.57% top 5 error)      Swept all classification and detection competitions in ILSVRC’15 and COCO’15      ",
        "url": "/cs231n_lec9"
    }
    ,
    
    "cs231n-lec8": {
        "title": "cs231n - Lecture 8. Training Neural Networks II",
        "author": "Darron Kwon",
        "category": "",
        "content": "OptimizationProblems with SGD      What if loss changes quickly in one direction and slowly in another? What does gradient descent do? Very slow progress along shallow dimension, jitter along steep direction        What if the loss function has a local minima or saddle point? Zero gradient, gradient descent gets stuck(more common in high dimension)        Gradients come from minibatches can be noisy  SGD + Momentum  To avoid local minima, combine gradient at current point with velocity to get step used to update weights; continue moving in the general direction as the previous iterations  \\(v_{t+1}=\\rho v_t + \\nabla f(x_t)\\)  \\(x_{t+1}=x_t - \\alpha v_{t+1}\\)  with rho giving “friction”; typically 0.9 or 0.99vx = 0while True:\tdx = compute_gradient(x)\tvx = rho * vx + dx\tx -= learning_rate * vxNesterov Momentum  “Look ahead” to the point where updating using velocity would take us; compute gradient there and mix it with velocity to get actual update direction  \\(v_{t+1}=\\rho v_t - \\alpha\\nabla f(x_t + \\rho v_t)\\)  \\(x_{t+1}=x_t + v_{t+1}\\)  rearrange with \\(\\tilde{x}_t = x_t + \\rho v_t\\),  \\(v_{t+1}=\\rho v_t - \\alpha\\nabla f(\\tilde{x}_t)\\)  \\(\\begin{align*}  \\tilde{x}_{t+1} &amp;= \\tilde{x}_t - \\rho v_t + (1+\\rho)v_{t+1}                  &amp;= \\tilde{x}_t + v_{t+1} + \\rho(v_{t+1}-v_t)  \\end{align*}\\)AdaGradgrad_squared = 0while True:\tdx = compute_gradient(x)\tgrad_squared += dx * dx\tx -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)  Added element-wise scaling of the gradient based on the historical sum of squares in each dimension  “Per-parameter learning rates” or “adaptive learning rates”  Progress along “steep” directions is damped and “flat” directions is accelerated  Step size decays to zero over timeRMSProp: “Leaky AdaGrad”grad_squared = 0while True:\tdx = compute_gradient(x)\tgrad_squared = decay_rate * grad_squared + (1 - decay_rate) * dx * dx\tx -= learning_rate * dx / (np.sqrt(grad_squared) + 1e-7)Adamfirst_moment = 0second_moment = 0for t in range(1, num_iterations):\tdx = compute_gradient(x)\tfirst_moment = beta1 * first_moment + (1 - beta1) * dx\t\t# Momentum\tsecond_moment = beta2 * second_moment + (1 - beta2) * dx * dx\tfirst_unbias = first_moment / (1 - beta1 ** t)\t\t\t# Bias correction\tsecond_unbias = second_moment / (1 - beta2 ** t)\tx -= learning_rate * first_unbias / (np.sqrt(second_unbias) + 1e-7)\t# AdaGrad/ RMSProp  Sort of like RMSProp with momentum  Bias correction for the fact that first and second moment estimates start at zero  Adam with beta1 = 0.9, beta2 = 0.999, and learning_rate = 1e-3 or 5e-4 is a great starting pointLearning rate schedulesLearning rate decays over time  Reduce learning rate by a certain value at a few fixed points(after some epochs)Learning Rate Decay      Reduce learning rate gradually, e.g.  Cosine:  $\\alpha_t = \\frac{1}{2}\\alpha_0(1+\\mbox{cos}(t\\pi / T))$  Linear: $\\alpha_t = \\alpha_0(1-t/T)$  Inverse sqrt: $\\alpha_t = \\alpha_0 / \\sqrt{t}$  while $\\alpha_0$ is the initial learning rate, $\\alpha_t$ is one at epoch t, and T is the total number of epochs        Linear Warmup  High initial learning rates can make loss explode; linearly increasing learning rate from 0 over the first ~5000 iterations can prevent this  Empirical rule of thumb: If you increase the batch size by N, also scale the initial learning rate by N  First-Order Optimization  Use gradient from linear approximation  Step to minimize the approximationSecond-Order Optimization  Use gradient and Hessian to form quadratic approximation  Step to the minima of the (quadratic) approximation  But Hessian has O(N^2) elements and inverting takes O(N^3), N is extremely large          Quasi-Newton methods (BGFS most popular):  instead of inverting the Hessian, approximate inverse Hessian with rank 1 updates over time      L-BFGS (Limited memory BFGS):  Does not form/store the full inverse Hessian. Usually works very well in full batch, deterministic mode, but does not transfer very well to mini-batch setting. Large-scale, stochastic setting is an active area of research.      Summary  Adam is a good default choice in many cases; even with constant learning rate  SGD+Momentum can outperform Adam but may equire more tuning of LR and schedule. Cosine schedule preferred, since it has very few hyperparameters.  L-BFGS is good if you can afford to do full batch updates.Improve test error  Better optimization algorithms help reduce training loss, but what we really care is about error on new data - how to reduce the gap?Early Stopping: Always do this  Stop training the model when accuracy on the validation set decreases. Or train for a long time, but always keep track of the model snapshot that worked best on val.Model Ensembles  Train multiple independent models  At test time average their results (Take average of predicted probability distributions, then choose argmax)Regularization      To improve single-model performance, add terms to loss  e.g. L1, L2, Elastic net.        or, use Dropout:  In each forward pass, randomly set some neurons to zero. Probability of dropping is a hyperparameter; 0.5 is common.  It forces the network to have a redundant representation; Prevents co-adaptation of features. Dropout can be interpreted as training a large ensemble of models (that share parameters).  p = 0.5 # dropout ratedef train_step(X):\t\t# drop in train time\tH1 = np.maximum(0, np.dot(W1, X) + b1)\tU1 = np.random.rand(*H1.shape) &lt; p\tH1 *= U1\tH2 = np.maximum(0, np.dot(W2, H1) + b2)\tU2 = np.random.rand(*H2.shape) &lt; p\tH2 *= U2\tout = np.dot(W3, H2) + b3\t# backward pass: compute gradients...\t# perform parameter update...def predict(X):\t\t\t# scale at test time\tH1 = np.maximum(0, np.dot(W1, X) + b1) * p\tH2 = np.maximum(0, np.dot(W2, H1) + b2) * p\tout = np.dot(W3, H2) + b3      more common: “Inverted dropout”  U1 = (np.random.rand(*H1.shape) &lt; p) / p in train time and no scaling in test time        A common pattern of regularization  Training: Add some kind of randomness  $y = fw(x,z)$  Testing: Average out randomness (sometimes approximate)  \\(y = f(x) = E_z[f(x,z)] = \\int p(z)f(x,z)\\, dz\\)        Data Augmentation:  Addes transformed data to train model  e.g. translation, rotation, stretching, shearing, lens distortions.        DropConnect:  Training: Drop connections between neurons (set weights to 0)  Testing: Use all the connections        Fractional Pooling:  Training: Use randomized pooling regions  Testing: Average predictions from several regions        Stochastic Depth:  Training: Skip some layers in the network  Testing: Use all the layer        Cutout:  Training: Set random image regions to zero  Testing: Use full image        Mixup:  Training: Train on random blends of images  Testing: Use original images  e.g. Randomly blend the pixels of pairs of training images, say 40% cat and 60% dog, and set the target label as cat:0.4 and dog:0.6.        Summary  Consider dropout for large fully-connected layers  Batch normalization and data augmentation almost always a good idea  Try cutout and mixup especially for small classification datasets  Choosing Hyperparameters      Step 1: Check initial loss  Turn off weight decay, sanity check loss at initialization  e.g. log(C) for softmax with C classes        Step 2: Overfit a small sample  Try to train to 100% training accuracy on a small sample of training data (~5-10 minibatches); fiddle with architecture, learning rate, weight initialization  If loss is not going down, LR too low or bad initialization. If loss explodes, then LR is too high or bad initialization.        Step 3: Find LR that makes loss go down  Use the architecture from the previous step, use all training data, turn on small weight decay, find a learning rate that makes the loss drop significantly within ~100 iterations.        Step 4: Coarse grid, train for ~1-5 epochs  Choose a few values of learning rate and weight decay around what worked from Step 3, train a few models for ~1-5 epochs.        Step 5: Refine grid, train longer  Pick best models from Step 4, train them for longer (~10-20 epochs) without learning rate decay        Step 6: Look at loss and accuracy curves  If accuracy still going up, you need to train longer. If it goes down, huge train / val gap means overfitting. You need to increase regularization or get more data. If there’s no gap between train / val, it means underfitting. Train longer or use a bigger model.        Look at learning curves  Losses may be noisy, use a scatter plot and also plot moving average to see trends better. Cross-validation is useful too.        Step 7: GO TO Step 5        Hyperparameters to play with:  network architecture,  learning rate, its decay schedule, update type,  regularization (L2/Dropout strength)        for Hyper-Parameter Optimization, consider both Random Search and Grid Search  Summary  Improve your training error:          Optimizers      Learning rate schedules        Improve your test error:          Regularization      Choosing Hyperparameters      ",
        "url": "/cs231n_lec8"
    }
    ,
    
    "cs231n-lec7": {
        "title": "cs231n - Lecture 7. Training Neural Networks I",
        "author": "Darron Kwon",
        "category": "",
        "content": "Activation FunctionsSigmoid  $\\sigma(x)=1/(1+e^{-x})$          Squashes numbers to range [0,1]      Historically popular since they have nice interpretation as a saturating “firing rate” of a neuron.        Problem:          Gradient Vanishing: Saturated neurons “kill” the gradients; If all the gradients flowing back will be zero and weights will never change.      Sigmoid outputs are not zero-centered and always positive, so the gradients will be always all positive or all negative. Then the gradient update would follow a zig-zag path, resulting in bad efficiency.      exp() is a bit compute expensive.      tanh(x)  Squashes numbers to range [-1,1]  zero centered  but still kills gradients when saturatedReLU(Rectified Linear Unit)  \\(f(x) = \\mbox{max}(0,x)\\)  Does not saturate (in + region)  Very computationally efficient  Converges much faster than sigmoid/tanh  but has not zero-centered output and weights will never be updated for negative xLeaky ReLU  \\(f(x) = \\mbox{max}(0.01x,x)\\)  (or parametric, PReLU: \\(f(x) = \\mbox{max}(\\alpha x, x)\\))  Not saturate  Computationally efficient  Converges much faster  will not “die”ELU(Exponential Linear Units)  \\(f(n)= \\begin{cases} x &amp; \\mbox{if }x&gt;0 \\\\                      \\alpha(\\mbox{exp}(x)-1) &amp; \\mbox{if }x\\le 0\\end{cases}\\)  ($\\scriptstyle{\\alpha = 1}$)  All benefits of ReLU  Closer to zero mean outputs  Negative saturation regime compared with Leaky ReLU adds some robustness to noise  Computation requires exp()SELU (Scaled Exponential Linear Units)  \\(f(n)= \\begin{cases} \\lambda x &amp; \\mbox{if }x&gt;0 \\\\                      \\lambda\\alpha(e^x -1) &amp; \\mbox{otherwise}\\end{cases}\\)  ($\\scriptstyle{\\alpha=1.6733, \\lambda=1.0507}$)  Scaled versionof ELU that works better for deep networks  “Self-normalizing” property;  Can train deep SELU networks without BatchNormMaxout “Neuron”  \\(\\mbox{max}(w_1^T x + b_1, w_2^T x + b_2)\\)  Nonlinearity; does not have the basic form of dot product  Generalizes ReLU and Leaky ReLU  Linear Regime; does not saturate or die  Complexity; Doubles the number of parameters/neuronSwish  \\(f(x)=x\\sigma(\\beta x)\\)  train a neural network to generate and test out different non-linearities  outperformed all other options for CIFAR-10 accuracySummary  Use ReLU and be careful with learning rates  Try out Leaky ReLU / Maxout / ELU / SELU to squeeze out some marginal gains  Don’t use sigmoid or tanhData Preprocessing  We may have zero-centered, normalized, decorrelated(PCA) or whitened data  After normalization, it will be less sensitive to small changes in weights and easier to optimize  In practice for images, centering only used.Weight Initialization  First idea: Small random numbers  (gaussian with zero mean and 1e-2 standard deviation)W = 0.01 * np.random.randn(D_in, D_out)  It works okay for small networks, but problems with deeper networks  All activations and gradients tend to zero and no learning proceeded.“Xavier” Initialization  std = 1/sqrt(D_in)  For conv layers, $\\mbox{D_in}$ is $\\mbox{filter_size}^2\\times \\mbox{input_channels}$W = np.random.randn(D_in, D_out) / np.sqrt(D_in)  x = np.tanh(x.dot(W))  Activations are nicely scaled for deeper layers  works well especially in non-linear activation functions like sigmoid, tanh  but cannot used in ReLU activation function; activations collapse to zero and no learningKaiming / MSRA Initialization  ReLU correction: std = sqrt(2/D_in)W = np.random.randn(D_in, D_out) * np.sqrt(2/D_in)  x = np.maximum(0, x.dot(W))Batch Normalization      To make each dimension zero-mean unit-variance, apply:  \\(\\hat{x}^{(k)} = \\frac{x^{(k)} - E[x^{(k)}]}{\\sqrt{\\mbox{Var}[x^{(k)}]}}\\)        Usually inserted after Fully Connected or Convolutional layers, and before nonlinearity.        Makes deep networks much easier to train  Improves gradient flow  Allows higher learning rates, faster convergence  Networks become more robust to initialization  Acts as regularization during training  Zero overhead at test-time: can be fused with conv  Behaves differently during training and testing: can have bugs        Comparison of Normalization Layers  Transfer Learning      Deep learning models are trained to capture characteristics of data, from general features at the first layer to specific features at the last layer.        In transfer learning, we import pre-trained model and fine-tune to our cases.        Strategies    E.g.  Transfer learning with CNNs is pervasive,  for Object Detection(Fast R-CNN), Image Captioning(CNN + RNN), etc.  but not always be necessary",
        "url": "/cs231n_lec7"
    }
    ,
    
    "cs231n-lec6": {
        "title": "cs231n - Lecture 6. Hardware and Software",
        "author": "Darron Kwon",
        "category": "",
        "content": "Deeplearning Software  The point of deep learning frameworks  (1) Quick to develop and test new ideas  (2) Automatically compute gradients  (3) Run it all efficiently on GPU (wrap cuDNN, cuBLAS, OpenCL, etc)Computational graph exampleimport numpy as npnp.random.seed(0)N, D = 3, 4x = np.random.randn(N, D)y = np.random.randn(N, D)z = np.random.randn(N, D)a = x * yb = a + zc = np.sum(b)grad_c = 1.0grad_b = grad_c * np.ones((N, D))grad_a = grad_b.copy()grad_z = grad_b.copy()grad_x = grad_a * ygrad_y = grad_a * x  in Numpy  Good: Clean API, easy to write numeric code  Bad: Have to compute our own gradients and can’t run on GPUimport torchdevice = 'cuda:0'N, D = 3, 4x = torch.randn(N, D, requires_grad=True,\t\t\t\tdevice=device)y = torch.randn(N, D)z = torch.randn(N, D)a = x * yb = a + zc = torch.sum(b)c.backward()print(x.grad)  in PyTorch  PyTorch handles gradients for us  Can run on GPUPyTorch: Fundamental Concepts  torch.Tensor: Like a numpy array, but can run on GPU  torch.autograd: Package for building computational graphs out of Tensors, and automatically computing gradients  torch.nn.Module: A neural network layer; may store state or learnable weights  we are using PyTorch version 1.7 herePyTorch: Autograd# Running example: Train a two-layer ReLU network on random data with L2 lossimport torchN, D_in, H, D_out = 64, 1000, 100, 10x = torch.randn(N, D_in)y = torch.randn(N, D_out)w1 = torch.randn(D_in, H, requires_grad=True)\t# enables autogradw2 = torch.randn(H, D_out, requires_grad=True)learning_rate = 1e-6for t in range(500):\th = x.mm(w1)\t\t\t\t\t\t\t# Forward pass\th_relu = h.clamp(min=0)\t\t\t\t\t# no need to track intermediate values\ty_pred = h_relu.mm(w2)\t\t\t\t\t# = x.mm(w1).clamp(min=0).mm(w2)\tloss = (y_pred - y).pow(2).sum()\t\tloss_backward()\t\t\t\t\t\t\t# Compute gradient of loss\twith torch.no_grad():\t\t\t\t\t# Gradient descent\t\tw1 -= learning_rate * w1.grad\t\t\t\t\tw2 -= learning_rate * w2.grad\t\tw1.grad.zero_()\t\tw2.grad.zero_()Or you can define your ownclass MyReLU(torch.autograd.Function):\t@staticmethod\tdef forward(ctx, x):\t#Use ctx object to “cache” values for the backward pass\t\tctx.save_for_backward(x)\t\treturn x.clamp(min=0)\t\t@staticmethod\tdef backward(ctx, grad_y):\t\tx, = ctx.saved_tensors\t\tgrad_input = grad_y.clone()\t\tgrad_input[x &lt; 0] = 0\t\treturn grad_input\t\tdef my_relu(x):\t\t# a helper function to make it easy to use the new function\treturn MyReLU.apply(x)  Now we can replace y_pred = x.mm(w1).clamp(min=0).mm(w2) with y_pred = my_relu(x.mm(w1)).mm(w2). In practice, do it only when you need custom backward.PyTorch: nn# Higher-level wrapper for working with neural netsimport torchN, D_in, H, D_out = 64, 1000, 100, 10x = torch.randn(N, D_in)y = torch.randn(N, D_out)model = torch.nn.Sequential(\t\t\ttorch.nn.Linear(D_in, H),\t\t\ttorch.nn.ReLU(),\t\t\ttorch.nn.Linear(H, D_out))learning_rate = 1e-2for t in range(500):\ty_pred = model(x)\tloss = torch.nn.functional.mse_loss(y_pred, y)\t\tloss.backward()\t\twith torch.no_grad():\t\tfor param in model.parameters():\t\t\tparam -= learning_rate * param.grad\tmodel.zero_grad()PyTorch: optimimport torchN, D_in, H, D_out = 64, 1000, 100, 10x = torch.randn(N, D_in)y = torch.randn(N, D_out)model = torch.nn.Sequential(\t\t\ttorch.nn.Linear(D_in, H),\t\t\ttorch.nn.ReLU(),\t\t\ttorch.nn.Linear(H, D_out))learning_rate = 1e-4optimizer = torch.optim.Adam(model.parameters(),\t\t\t\tlr=learning_rate)\t# different update rulesfor t in range(500):\ty_pred = model(x)\tloss = torch.nn.functional.mse_loss(y_pred, y)\t\tloss.backward()\toptimizer.step()\toptimizer.zero_grad()PyTorch: Define new Modulesimport torchclass TwoLayerNet(torch.nn.Module):\tdef __init__(self, D_in, H, D_out):\t\t# init sets up two children\t\tsuper(TwoLayerNet, self).__init__()\t\tself.linear1 = torch.nn.Linear(D_in, H)\t\tself.linear2 = torch.nn.Linear(H, D_out)\t\tdef forward(self, x):\t\th_relu = self.linear1(x).clamp(min=0)\t\ty_pred = self.linear2(h_relu)\t\treturn y_predN, D_in, H, D_out = 64, 1000, 100, 10x = torch.randn(N, D_in)y = torch.randn(N, D_out)model = TwoLayerNet(D_in, H, D_out)optimizer = torch.optim.SGD(model.parameters(), lr=1e-4)for t in range(500):\ty_pred = model(x)\tloss = torch.nn.functional.mse_loss(y_pred, y)\t\tloss.backward()\toptimizer.step()\toptimizer.zero_grad()PyTorch: Pretrained Modelsimport torchimport torchvisionalexnet = torchvision.models.alexnet(pretrained=True)vgg16 = torchvision.models.vgg16(pretrained=True)resnet101 = torchvision.models.resnet101(pretrained=True)TensorFlow 2.4  Default dynamic graph, optionally static.import numpy as npimport tensorflow as tfN, D, H = 64, 1000, 100x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)w1 = tf.Variable(tf.random.uniform((D, H))) # weightsw2 = tf.Variable(tf.random.uniform((H, D))) # weightslearning_rate = 1e-6for t in range(50):\twith tf.GradientTape() as tape:\t\t\t\t\t# build dynamic graph\t\th = tf.maximum(tf.matmul(x, w1), 0)\t\t\t# forward pass\t\ty_pred = tf.matmul(h, w2)\t\tdiff = y_pred - y\t\tloss = tf.reduce_mean(tf.reduce_sum(diff ** 2, axis=1))\tgradients = tape.gradient(loss, [w1, w2])\t\t# backward pass\tw1.assign(w1 - learning_rate * gradients[0])\t# gradient descent\tw2.assign(w2 - learning_rate * gradients[1])Keras: High-level Wrapperimport numpy as npimport tensorflow as tfN, D, H = 64, 1000, 100x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)model = tf.keras.Sequential()model.add(tf.keras.layers.Dense(H, input_shape=(D,),\t\t\tactivation=tf.nn.relu))model.add(tf.keras.layers.Dense(D))optimizer = tf.optimizers.SGD(1e-1)losses = []for t in range(50):\twith tf.GradientTape() as tape:\t\ty_pred = model(x)\t\tloss = tf.losses.MeanSquaredError()(y_pred, y)\tgradients = tape.gradient(\t\tloss, model.trainable_variables)\toptimizer.apply_gradients(\t\tzip(gradients, model.trainable_variables))      We can make use of different update rules with tf.optimizers.{} and predefined loss functions as well.        Keras can handle the training loop;  N, D, H = 64, 1000, 100x = tf.convert_to_tensor(np.random.randn(N, D), np.float32)y = tf.convert_to_tensor(np.random.randn(N, D), np.float32)model = tf.keras.Sequential()model.add(tf.keras.layers.Dense(H, input_shape=(D,),\t\t\tactivation=tf.nn.relu))model.add(tf.keras.layers.Dense(D))optimizer = tf.optimizers.SGD(1e-1)model.compile(loss=tf.keras.losses.MeanSquaredError(),\t\t\t optimizer=optimizer)history = model.fit(x, y, epochs=50, batch_size=N)TensorFlow: compile static graph\t...model.add(tf.keras.layers.Dense(D))optimizer = tf.optimizers.SGD(1e-1)@tf.functiondef model_func(x, y):\ty_pred = model(x)\tloss = tf.losses.MeanSquaredError()(y_pred, y)\treturn y_pred, lossfor t in range(50):\t...  @tf.function decorator (implicitly) compiles python functions to static graph for better performance.Dynamic vs. Static      Dynamic Computation Graphs:   Building the graph and computing the graph happen at the same time.  Graph building and execution are intertwined, so always need to keep code around  Inefficient, especially if we are building the same graph over and over again.        Static Computation Graphs:  Build computational graph describing our computation(including finding paths for backprop)  Reuse the same graph on every iteration  Once graph is built, can serialize it and run it without the code that built the graph  Framework can optimize the graph before it runs  PyTorch vs. TensorFlow      PyTorch  Dynamic Graphs as default set  Static: ONNX, TorchScript        TensorFlow  Dynamic: Eager set  Static: @tf.function  Model Parallel vs. Data Parallel      Model parallelism:  split computation graph into parts and distribute to GPUs/nodes        Data parallelism:  split minibatch into chunks and distribute to GPUs/ nodes  PyTorch: nn.DataParallel, nn.DistributedDataParallel  TensorFlow: tf.distributed.Strategy  ",
        "url": "/cs231n_lec6"
    }
    ,
    
    "cs231n-lec5": {
        "title": "cs231n - Lecture 5. Convolutional Neural Networks",
        "author": "Darron Kwon",
        "category": "",
        "content": "Convolutional Neural Networks      ConvNets are everywhere  Classification, Retrieval, Detection, Segmentation, Image Captioning, etc.        Recap: Fully Connected Layer  $32\\times 32\\times 3$ image $\\rightarrow$ stretch to $3072\\times 1$  Then a dot product of $3072\\times 1$ input x and scoring weights W, Wx is in $10 \\times 3072$. With some activation function, we can make classification scores in 10 classes.  Convolution Layer: preserve spatial structure      Convolve the filter with the image, slide over the image spatially, computing dot products. Filters always extend the full depth of the input volume.Convolve(slide) over all spatial locations, we can make an activation map of size $28\\times 28\\times 1$ for each convolution filter. For example, if we had 6 $5\\times 5$ filters, we’ll get 6 separate activation maps. We stack these up to get a “new image” of size $28\\times 28\\times 6$.        ConvNet is a sequence of Convolution Layers, interspersed with activation functions.Input convolved repeatedly with filters shrinks volumes spatially. By each sequence, an image is processed from low-level features to high-level features. Shrinking too fast is not good, doesn’t work well.        We call the layer convolutional because it is related to convolution of two signals: \\(f[x,y]*g[x,y]=\\sum_{n_1=-\\infty}^\\infty \\sum_{n_2=-\\infty}^\\infty f[n_1,n_2]\\cdot g[x-n_1,y-n_2]\\); elementwise multiplication and sum of a filter and the signal (image)        Zero pad the border:  The data on the border of an image will be convolved only once with each filter, while the others on the center of an image will be treated several times. Zero padding is introduced to solve this problem.        General CONV layers:  with $N\\times N$ input, $F\\times F$ filter, applied with stride s, pad with p pixel border, the output is $(N+2P-F)/s + 1$        Example:  Input volume $32\\times 32\\times 3$  10 $5\\times 5$ filters with stride 1, pad 2    $\\rightarrow$ Output volume size: $(32+2*2-5)/1+1=32$ spatially, so $32\\times 32\\times 10$.    $\\rightarrow$ Number of parameters in this layer: each filter has $5\\times 5\\times 3+1=76$ parameters(+1 for bias), thus for all 760 params.    $1\\times 1$ convolution layers used:  To reduce the number of channels, so the number of parameters,  Then we can perform a deeper layers(Bottleneck architecture).Pooling layer      Summarize the data in a partial space, into some representations  Reducing output dimensions and the number of parameters  Make it smaller and more manageable  Operate over each activation map independently(downsampling)        e.g. max pool with $2\\times 2$ filters and stride 2, $4\\times 4$ input reduced to $2\\times 2$ output consisted of regional maximums.  Fully Connected Layer (FC layer)  Contains neurons that connect to the entire input volume, as in ordinary NeuralNetworks. Stacked and followed by some activations, finally we make predictions or classifications.Summary  ConvNets stack CONV,POOL,FC layers  Trend towards smaller filters and deeper architectures  Trend towards getting rid of POOL/FC layers (just CONV)  Historically architectures looked like [(CONV-RELU)*N-POOL?]*M-(FC-RELU)*K,SOFTMAX where N is usually up to ~5, M is large, $0\\le K \\le 2$.  but recent advances such as ResNet/GoogLeNet have challenged this paradigm",
        "url": "/cs231n_lec5"
    }
    ,
    
    "cs231n-lec4": {
        "title": "cs231n - Lecture 4. Neural Networks and Backpropagation",
        "author": "Darron Kwon",
        "category": "",
        "content": "Image Features  Problem: Linear Classifiers are not very powerful          Visual Viewpoint: Linear classifiers learn one template per class      Geometric Viewpoint: Linear classifiers can only draw linear decision boundaries            Image Features: MotivationAfter applying feature transform, points can be separated by linear classifier$f(x,y) = (r(x,y), \\theta(x,y))$    Image Features vs. ConvNetsNeural Networks      Neural networks, also called Fully connected networks(FCN) or sometimes multi-layer perceptrons(MLP)(Before) Linear score function:\\(\\begin{align*}&amp; f=Wx \\\\&amp; x\\in\\mathbb{R}^D, W\\in\\mathbb{R}^{C\\times D}\\end{align*}\\)$\\rightarrow$ 2-layer Neural Network:\\(\\begin{align*}&amp; f=W_2 \\mbox{max}(0,W_1 x) \\\\&amp; x\\in\\mathbb{R}^D, W_1\\in\\mathbb{R}^{H\\times D}, W_2\\in\\mathbb{R}^{C\\times H}\\end{align*}\\)$\\rightarrow$ or 3-layer Neural Network:\\(f=W_3\\mbox{max}(0,W_2 \\mbox{max}(0,W_1 x)) \\\\ \\vdots\\)(In practice we will usually add a learnable bias at each layer as well)        Neural networks: hierarchical computationLearning 100s of templates instead of 10 and share templates between classes        Why is max operator important?The function $\\mbox{max}(0,z)$ is called the activation function.Q: What if we try to build a neural network without one?A: We end up with a linear classifier again!$f=W_2 W_1 x, W_3=W_1 W_2, f = W_3 x$        Activation functions  ReLU($\\mbox{max}(0,z)$) is a good default choice for most problems  Others: Sigmoid, tanh, Leaky ReLU, Maxout, ELU, etc.        Neural networks: ArchitecturesExample feed-forward computation of a neural network  # forward-pass of a 3-layer neural network:f = lambda x: 1.0/(1.0 + np.exp(-x)) # activation function (use sigmoid)x = np.random.randn(3,1) # random input vector of three numbers (3x1)h1 = f(np.dot(W1, x) + b1) # calculate first hidden layer activations (4x1)h2 = f(np.dot(W2, h1) + b2) #calculate second hidden layer activations (4x1)out = np.dot(W3, h2) + b3 #output neuron (1x1)Full implementation of training a 2-layer Neural Network:import numpy as npfrom numpy.random import randnN, D_in, H, D_out = 64, 1000, 100, 10\t# Define the networkx, y = randn(N, D_in), randn(N, D_out)w1, w2 = randn(D_in, H), randn(H, D_out)for t in range(2000):\t\t\t\t\t# Forward pass\th = 1 / (1 + np.exp(-x.dot(w1)))\ty_pred = h.dot(w2)\tloss = np.square(y_pred - y).sum()\tprint(t, loss)\t\tgrad_y_pred = 2.0 * (y_pred - y)\t# Calculate the analytical gradients\tgrad_w2 = h.T.dot(grad_y_pred)\tgrad_h = grad_y_pred.dot(w2.T)\tgrad_w1 = x.T.dot(grad_h * h * (1-h))\t\tw1 -= 1e-4 * grad_w1\t\t\t\t# Gradient descent\tw2 -= 1e-4 * grad_w2      Plugging in neural networks with loss functions$s = f(x;W_1,W_2) = W_2\\mbox{max}(0,W_1 x)$ Nonlinear score function$L_i = \\sum_{j\\ne y_i}\\mbox{max}(0,s_j-s_{y_i}+1)$ SVM Loss on predictions$R(W)=\\sum_k W_k^2$ Regularization$L=\\frac{1}{N}\\sum_{i=1}^N L_i + \\lambda R(W_1) + \\lambda R(W_2)$ Total loss: data loss + regularization        Problem: How to compute gradients?If we can compute partial derivaties, then we can learn $W_1$ and $W_2$.  Backpropagation      Chain rule:\\(\\begin{align*}\\frac{\\partial f}{\\partial y}=\\frac{\\partial f}{\\partial q} \\frac{\\partial q}{\\partial y} \\mbox{Upstream gradient} \\times \\mbox{Local gradient}\\end{align*}\\)        Patterns in gradient flow  ",
        "url": "/cs231n_lec4"
    }
    ,
    
    "cs231n-lec3": {
        "title": "cs231n - Lecture 3. Loss Functions and Optimization",
        "author": "Darron Kwon",
        "category": "",
        "content": "Linear Classifier (cont.)  Todo:          Define a loss function: how good the classifier is      Optimization: efficient way of finding the parameters that minimize the loss function            Loss functiongiven a dataset of examples \\(\\left\\{ (x_i,y_i) \\right\\}_{n=1}^N\\)where $x_i$ is image and $y_i$ is (integer) labelAverage of loss over examples: \\(L=\\frac{1}{N}\\sum_i L_i(f(x_i,W),y_i)\\)    Multiclass SVM loss:using the shorthand for the scores vector: $s = f(x_i,W)$\\(L_i=\\sum_{j\\ne y_i}\\mbox{max}(0,s_j-s_{y_i}+1)\\)where +1 is a safety marginQ1: What happens to loss if car scores decrease by 0.5 for this training example?L = max(0,0.8-4.4+1) + max(0,1.5-4.4+1) = 0Result will not be changed; SVM hinge loss is robust to small change of scores.Q2: what is the min/max possible SVM loss $L_i$?The possible minimum value of SVM loss is 0 and maximum value is $\\infty$.Q3: At initialization W is small so all s ≈ 0. What is the loss $L_i$, assuming N examples and C classes?C-1 the number of classes minus 1.(Sanity check for weight initialization)Q4: What if the sum was over all classes? (including $j = y_i$)All losses increased by 1, so as the average loss over full dataset. In this case, the minimum value of loss will be 1. What we want is to minimize the loss function and that’s why we remove the class $s_j=s_{y_i}$ to set it 0.Q5: What if we used mean instead of sum?Because a loss function is to find optimizing parameters, rescaling loss has no effect to the result.Q6: What if we used squared function of\\(L_i=\\sum_{j\\ne y_i}\\mbox{max}(0,s_j-s_{y_i}+1)^2\\)A squared hinge loss can be better at finding optimizing parameters W. If the observation is close to the answer, it will reflect the loss much smaller than original hinge loss.def L_i_vectorized(x,y,W):  \tscores = W.dot(x)  \tmargins = np.maximum(0, scores -scores[y] +1)\tmargins[y]=0\tloss_i = np.sum(margins)\treturn loss_i$f(x,W) = Wx$\\(L=\\frac{1}{N}\\sum_{i=1}^N \\mbox{max}(0,f(x_i;W)_j -f(x_i;W)y_i +1)\\)Q7: Suppose that we found a W such that $L = 0$. Is this W unique?No. 2W is also has $L=0$. W not a unique solution.$\\rightarrow$ How do we choose between W and 2W?      Regularization: introduce penalty term $\\lambda R(W)$ on L(W)L2 regularization: $R(W)=\\sum_k\\sum_l W_{k,l}^2$; likes to spread out the weightsL1 regularization: $R(W)=\\sum_k\\sum_l |W_{k,l}|$Elastic net (L1 + L2): $R(W) = \\sum_k\\sum_l\\beta W_{k,l}^2 + |W_{k,l}|$Dropout, Batch normalization, Stochastic depth, fractional pooling, etc.        Why regularize?Express preferences over weightsMake the model simple so it works on test dataImprove optimization by adding curvature  Softmax classifier(Multinomial Logistic Regression)The information content(also called the surprisal or self-information) is described as $h(E) = -\\log P(E)$. For a discrete random variable X, its entropy(or expected; mean information) $H(X) = -\\sum_{i=1}^N p_i \\log p_i$. Cross-entropy is an approximaton of q to p is to minimizing KL(p|q), while the Kullback–Leibler divergence as $D_{KL}(P||Q)=\\sum_y P(y)\\log\\frac{P(y)}{Q(y)} = \\sum_y P(y)\\log P(y) - \\sum_y P(y)\\log Q(y)$. Thus, cross entropy loss $L = -\\sum_y P(y)\\log Q(y)$.Q1: What is the min/max possible softmax loss $L_i$?min 0 to max $\\infty$Q2: At initialization all $s_j$ will be approximately equal; what is the softmax loss $L_i$, assuming C classes?$-\\log(1/C)=\\log C$RecapFor some dataset of $(x,y)$, a score function $s = f(x;W)$, a loss function $L_i$,Full loss \\(L=\\frac{1}{N}\\sum_{i=1}^N L_i + R(W)\\)Optimization      Strategy: Follow the slopeIn 1-dimension, the derivative of a function:\\(\\frac{df(x)}{dx}=\\lim_{n\\to 0}\\frac{f(x+h)-f(x)}{h}\\)In multiple dimensions, the gradient is the vector of (partial derivatives) along each dimension.The slope in any direction is the dot product of the direction with the gradient. The direction of steepest descent is the negative gradient.The loss is just a function of W, what we want is $\\nabla_w L$In practice: Always use analytic gradient, but check implementation with numerical gradient. This is called a gradient check.        Stochastic Gradient Descent(SGD)Full sum expensive when N is large. Approximate su using a minibatch of examples(32 / 64 / 128 common)  # Vanilla Minibatch Gradient Descentwhile True:\tdata_batch = sample_training_data(data,256)  \tweights_grad = evaluate_gradient(loss_fun, data_batch, weights)\tweights += - step_size * weights_grad",
        "url": "/cs231n_lec3"
    }
    ,
    
    "cs231n-lec2": {
        "title": "cs231n - Lecture 2. Image Classification",
        "author": "Darron Kwon",
        "category": "",
        "content": "Image Classification: A Core Task in Computer Vision      The Problem: Semantic Gapconsidering image as a tensor of integers between [0,255] with 3 channels RGB        Challenges:  Viewpoint variation  Background Clutter  Illumination  Occlusion  Deformation  Intraclass variation        An image classifier  def classify_image(image):  # Some magic here?  \treturn class_label    ML: Data-Driven Approach          Collect a dataset of images and labels      Use ML algorithms to train a classifier      Evaluate the classifier on new images      def train(images,labels):  \t# Machine Learning!  \treturn model  def predict(model, test_images):  \t# Use model to predict labels  \treturn test_labels    Nearest Neighbor ClassifierPredict the label of the most similar training imgaeTraining data with labels x $\\leftrightarrow$ query data \\(x^*\\)distance metric \\(|x,x^*| \\rightarrow R\\)L1 distance \\(d_1(I_1,I_2) = \\sum_p |I_1^p-I_2^p|\\)pixel-wise absolute value differences $\\rightarrow$ sum for scoringimport numpy as npclass NearestNeighbor:  \tdef __init__(self):  \t\tpass\tdef train(self,X,y):  ### Memorize training data\t\t\"\"\" X is N x D for n example. Y is 1-dim of size N\"\"\"  \t\tself.Xtr = Xf\t\tself.ytr = y  \tdef predict(self,X):  \t\tnum_test = X.shape[0]  \t\tYpred = np.zeros(num_test, dtype = self.ytr.dtype)\t\t\t\tfor i in xrange(num_test):\t\t\t### find closest train image for each test image, predict label of its\t\t\tdistances = np.sum(np.abs(self.Xtr - X[i,:]), axis=1)\t\t\tmin_index = np.argmin(distances)  \t\t\tYpred[i] = self.ytr[min_index]\t\treturn Ypred      Q: With N examples, how fast are training and prediction?Answer: Train O(1), predict O(N)$\\rightarrow$ Bad: we want fast at prediction; slow for training is ok.        KNN with majority voteDistance metric: L1(Manhattan), L2(Euclidean)        HyperparametersTo find best value of k and best distance(metric) to use, use train-val-test approach        However, pixel distances are not informative for KNNvery slow at test time &amp; curse of dimensionality  Linear Classifier      Parametric Approach$f(x,W)=Wx+b$; W for parameters or weights        Interpreting a linear classifier: Geometric Viewpointhard cases in non-linearity  ",
        "url": "/cs231n_lec2"
    }
    ,
    
    "fashion-gnn": {
        "title": "GNN-based Fashion Coordinator",
        "author": "Darron Kwon",
        "category": "",
        "content": "  1. About          1.1. Project Goal      1.2. Model Architecture        2. Load Data and Preprocess  3. Initialize a Graph Model          3.1. Generate graphs and edge data for each item categories        4. Model Training          4.1. Load Evaluation Data      4.2. Train with HinSAGE and Link Prediction Error      1. About1.1. Project Goal      Building a “Heterogeneous GNN model” using networkx and stellargraphas a submission for Fashion-how Challenge, ETRI, 2021.        Running GNN model on a cuda:GPU environment  Windows 11 &gt; docker - ubuntu kernel &gt; CUDA on WSL        Data Reference:Euisok Chung at al., “Dataset for Interactive Recommendation System”, HCLT-2020  1.2. Model Architecture2. Load Data and Preprocess# a sample of raw metadata DBprint(len(name),len(data_item))print(name[0],data_item[:4]) # 4 descriptions for each item2607 10428BL-001  ['단추 여밈 의 전체 오픈형 스탠드 칼라 와 브이넥 네크라인 의 결합 스타일 손목 까지 내려오 는 일자형 소매 여유로운 핏 어깨 에서 허리 까지 세로 절개 에 풍성 한 러플 장식 와이드 커프스',  '면 100% 구김 이 가 기 쉬운 드라이 클리닝 권장',  '시원_해 보이 는 소라색 SKY BLUE 단색 의 깔끔_한 느낌',  '여성 스러운 페미닌 한 세련 된 사랑 스러운 깔끔_한 오피스 룩 로맨틱 한 데이트 룩 포멀 한 이미지 단정 한 오피스 걸 룩 이미지'][cat.shape for cat in g_model._metadata] # vectorized with pre-trained subword embedding# [(1162, 512), (673, 512), (641, 512), (131, 512)][cat.shape for cat in g_model._feats] # vecotrized image features# [(1162, 4096), (673, 4096), (641, 4096), (131, 4096)]# in 4 categories, each items has 2 vectorized data, 512-length metadata &amp; 4096-length imagedataprint(len(slot_name)) # 4print(slot_name[0][0], slot_item[0][0].shape, slot_feat[0][0].shape)# CD-001 (512,) (4096,)[cat.shape for cat in g_model._meta_similarities]# [(1162, 1162), (673, 673), (641, 641), (131, 131)]from file_io_edit import _load_trn_dialogdialog, coordi, reward, delim_dlg, delim_crd, delim_rwd = \\                                             _load_trn_dialog(in_file_dialog)print(len(dialog)) # all sentences in full dialogsprint(dialog[:21]) # example of the first dialog92444['어서 오 세 요 코디 봇 입 니다 무엇 을 도와 드릴_까 요',  '처음 대학교 들어가 는데 입 을 옷 코디 해 주 세 요',  '신입생 코디 에 어울리 게 화사 한 스웨터 를 추천_해 드릴_게 요',  '이 옷 에 어울리 는 치마 로 추천_해 주 세 요',  '고객 님 의 키 사이즈 에 맞추 면 이런 옷 도 잘 어울리 실 것 같_은데 어떠 신가 요',  '제 가 키 가 작_아서 짧 은 치마 로 추천_해 주 세 요',  '상의 색상 과 도 매칭 이 잘 어울리 는 짧 은 치마 입 니다',  '어두운 계열 은 없 나 요',  '언밸런스 한 컷팅 으로 세련미 를 돋보이 게_하 는 치마 인데 마음 에 드 시_나 요',  '나쁘 지_않 네 요 외투 도 추천_해 주 시 겠_어 요',  '요즘 계절 에는 가디건 이나 자켓 을 걸치기 에 좋_은데 특정 종류 로 원하 는 게 있 으신가 요',  '트렌치 코트 종류 로 추천_해 주 세 요',  '이너 색상 과 무난_하 게 잘 어울릴 트렌치 코트 입 니다',  '신발 도 추천_해 주 세 요',  '운동화 나 구두 중 어떤 걸 선호_하 시_나 요',  '운동화 로 추천_해 주 세 요',  '어떤 스타일 과 도 무난_하 게 잘 어울리 는 기본 아이템 입 니다',  '맘 에 드_네 요 전체 코디샷 볼_수 있 나 요',  '네 지금 까지 제안 해 드린 아이템 으로 전체 코디샷 을 제안 해 드립 니다 마음 에 드 시_나 요',  '네 마음 에 드_네 요 감사_합 니다',  '마음 에 드 신_다 니 다행 입 니다 이용_해 주 셔 서 감사_합 니다']from file_io_edit import _episode_slicedialog = _episode_slice(dialog, delim_dlg)coordi = _episode_slice(coordi, delim_crd)reward = _episode_slice(reward, delim_rwd)print(len(dialog))print(dialog[0]) # cut for each dialogs7236['어서 오 세 요 코디 봇 입 니다 무엇 을 도와 드릴_까 요',  '처음 대학교 들어가 는데 입 을 옷 코디 해 주 세 요',  '신입생 코디 에 어울리 게 화사 한 스웨터 를 추천_해 드릴_게 요',  '이 옷 에 어울리 는 치마 로 추천_해 주 세 요',  '고객 님 의 키 사이즈 에 맞추 면 이런 옷 도 잘 어울리 실 것 같_은데 어떠 신가 요',  '제 가 키 가 작_아서 짧 은 치마 로 추천_해 주 세 요',  '상의 색상 과 도 매칭 이 잘 어울리 는 짧 은 치마 입 니다',  '어두운 계열 은 없 나 요',  '언밸런스 한 컷팅 으로 세련미 를 돋보이 게_하 는 치마 인데 마음 에 드 시_나 요',  '나쁘 지_않 네 요 외투 도 추천_해 주 시 겠_어 요',  '요즘 계절 에는 가디건 이나 자켓 을 걸치기 에 좋_은데 특정 종류 로 원하 는 게 있 으신가 요',  '트렌치 코트 종류 로 추천_해 주 세 요',  '이너 색상 과 무난_하 게 잘 어울릴 트렌치 코트 입 니다',  '신발 도 추천_해 주 세 요',  '운동화 나 구두 중 어떤 걸 선호_하 시_나 요',  '운동화 로 추천_해 주 세 요',  '어떤 스타일 과 도 무난_하 게 잘 어울리 는 기본 아이템 입 니다',  '맘 에 드_네 요 전체 코디샷 볼_수 있 나 요',  '네 지금 까지 제안 해 드린 아이템 으로 전체 코디샷 을 제안 해 드립 니다 마음 에 드 시_나 요',  '네 마음 에 드_네 요 감사_합 니다',  '마음 에 드 신_다 니 다행 입 니다 이용_해 주 셔 서 감사_합 니다']# vectorized dialog datag_model._mem_trn_dlg.shape # (7236, 2048)3. Initialize a Graph Model  Procedure of loading and preprocessing data includedimport randomrandom.seed(2021)import numpy as npnp.random.seed(2021)import tensorflow as tftf.random.set_seed(2021)tf.device('/device:GPU:0')import networkx as nximport stellargraph as sgimport argparsefrom graph_model import *import osg_model = graph_model(args)&lt;Initialize subword embedding&gt;loading= ./sstm_v0p5_deploy/sstm_v4p49_np_final_n36134_d128_r_eng_upper.dat&lt;Make metadata&gt;loading fashion item metadatavectorizing data&lt;Make input &amp; output data&gt;loading dialog DB# of dialog: 7236 setsvectorizing datamemorizing data&lt;Make input &amp; output data&gt;loading dialog DB# of dialog: 200 setsvectorizing datamemorizing data3.1. Generate graphs and edge data for each item categoriesg_model._graph_cats(&lt;stellargraph.core.graph.StellarGraph at 0x7f58a4f11bb0&gt;, &lt;stellargraph.core.graph.StellarGraph at 0x7f58a4f11f10&gt;, &lt;stellargraph.core.graph.StellarGraph at 0x7f58a4f11c40&gt;, &lt;stellargraph.core.graph.StellarGraph at 0x7f58a4758af0&gt;)for g in g_model._graph_cats:    print(g.info())StellarGraph: Undirected multigraph Nodes: 8398, Edges: 9222 Node types:  dialog: [7236]    Features: float32 vector, length 2048    Edge types: dialog-default-&gt;item  item: [1162]    Features: float32 vector, length 4608    Edge types: item-default-&gt;dialog Edge types:    dialog-default-&gt;item: [9222]        Weights: range=[0.5, 1], mean=0.607623, std=0.205508        Features: noneStellarGraph: Undirected multigraph Nodes: 7909, Edges: 9022 Node types:  dialog: [7236]    Features: float32 vector, length 2048    Edge types: dialog-default-&gt;item  item: [673]    Features: float32 vector, length 4608    Edge types: item-default-&gt;dialog Edge types:    dialog-default-&gt;item: [9022]        Weights: range=[0.5, 1], mean=0.607515, std=0.205433        Features: noneStellarGraph: Undirected multigraph Nodes: 7877, Edges: 11549 Node types:  dialog: [7236]    Features: float32 vector, length 2048    Edge types: dialog-default-&gt;item  item: [641]    Features: float32 vector, length 4608    Edge types: item-default-&gt;dialog Edge types:    dialog-default-&gt;item: [11549]        Weights: range=[0.5, 1], mean=0.613733, std=0.209607        Features: noneStellarGraph: Undirected multigraph Nodes: 7367, Edges: 9757 Node types:  dialog: [7236]    Features: float32 vector, length 2048    Edge types: dialog-default-&gt;item  item: [131]    Features: float32 vector, length 4608    Edge types: item-default-&gt;dialog Edge types:    dialog-default-&gt;item: [9757]        Weights: range=[0.5, 1], mean=0.618479, std=0.212619        Features: noneg_model._graph_datas[0]                  dialog      item      label                  0      d_2      o_0      1.0              1      d_53      o_0      1.0              2      d_133      o_0      0.5              3      d_337      o_0      0.5              4      d_437      o_0      0.5              ...      ...      ...      ...              9217      d_5649      o_1160      0.5              9218      d_5938      o_1160      0.5              9219      d_5972      o_1160      1.0              9220      d_6439      o_1160      0.5              9221      d_6788      o_1160      0.5      9222 rows × 3 columnsg_model._graph_datas[1]                  dialog      item      label                  0      d_514      t_0      0.5              1      d_560      t_0      0.5              2      d_815      t_0      0.5              3      d_839      t_0      0.5              4      d_884      t_0      0.5              ...      ...      ...      ...              9017      d_5905      t_672      1.0              9018      d_5919      t_672      0.5              9019      d_5999      t_672      0.5              9020      d_6745      t_672      1.0              9021      d_6746      t_672      0.5      9022 rows × 3 columnsg_model._graph_datas[2]                  dialog      item      label                  0      d_34      b_0      0.5              1      d_225      b_0      0.5              2      d_272      b_0      1.0              3      d_302      b_0      1.0              4      d_380      b_0      0.5              ...      ...      ...      ...              11544      d_6239      b_637      0.5              11545      d_6379      b_637      0.5              11546      d_5506      b_638      0.5              11547      d_5576      b_638      0.5              11548      d_5097      b_639      1.0      11549 rows × 3 columnsg_model._graph_datas[3]                  dialog      item      label                  0      d_47      s_0      0.5              1      d_52      s_0      0.5              2      d_74      s_0      0.5              3      d_124      s_0      0.5              4      d_175      s_0      0.5              ...      ...      ...      ...              9752      d_6643      s_129      0.5              9753      d_6684      s_129      0.5              9754      d_7050      s_129      1.0              9755      d_7082      s_129      0.5              9756      d_7124      s_129      1.0      9757 rows × 3 columns4. Model Training4.1. Load Evaluation Datanp.array(g_model._mem_tst_dlg).shape # (200, 2048)np.array(g_model._tst_crd).shape # (200, 3, 4)4.2. Train with HinSAGE and Link Prediction Error  work on building a base model, not fully optimized...# training functiondef _graph_train(self,data,data_graph):    batch_size = 200    epochs = 10    train_size = 0.7    test_size = 0.3    num_samples = [8, 4]    num_workers = 2    edges_train, edges_test = model_selection.train_test_split(data, train_size=train_size, test_size=test_size)    edgelist_train = list(edges_train[[\"dialog\", \"item\"]].itertuples(index=False))    edgelist_test = list(edges_test[[\"dialog\", \"item\"]].itertuples(index=False))    labels_train = edges_train[\"label\"]    labels_test = edges_test[\"label\"]    generator = HinSAGELinkGenerator(        data_graph, batch_size, num_samples, head_node_types=[\"dialog\", \"item\"])    train_gen = generator.flow(edgelist_train, labels_train, shuffle=True)    test_gen = generator.flow(edgelist_test, labels_test)    hinsage_layer_sizes = [32, 32]    assert len(hinsage_layer_sizes) == len(num_samples)    hinsage = HinSAGE(        layer_sizes=hinsage_layer_sizes, generator=generator, bias=True, dropout=0.0)    x_inp, x_out = hinsage.in_out_tensors()    score_prediction = link_regression(edge_embedding_method=\"concat\")(x_out)    model = Model(inputs=x_inp, outputs=score_prediction)    model.compile(        optimizer=optimizers.Adam(learning_rate=1e-2),        loss=losses.mean_squared_error,        metrics=[root_mean_square_error, metrics.mae],)    test_metrics = model.evaluate(        test_gen, verbose=1, use_multiprocessing=False, workers=num_workers    )    history = model.fit(        train_gen,        validation_data=test_gen,        epochs=epochs,        verbose=1,        shuffle=False,        use_multiprocessing=False,        workers=num_workers,)    test_metrics = model.evaluate(        test_gen, use_multiprocessing=False, workers=num_workers, verbose=1)    print(\"Test Evaluation:\")    for name, val in zip(model.metrics_names, test_metrics):        print(\"\\t{}: {:0.4f}\".format(name, val))    y_true = labels_test    y_pred = model.predict(test_gen)    y_pred_baseline = np.full_like(y_pred, np.mean(y_true))...g_model.train()link_regression: using 'concat' method to combine node embeddings into edge embeddings14/14 [==============================] - 3s 92ms/step - loss: 0.1245 - root_mean_square_error: 0.3521 - mean_absolute_error: 0.2666Untrained model's Test Evaluation:\tloss: 0.1245\troot_mean_square_error: 0.3521\tmean_absolute_error: 0.2666Epoch 1/1033/33 [==============================] - 8s 222ms/step - loss: 0.0947 - root_mean_square_error: 0.2792 - mean_absolute_error: 0.2281 - val_loss: 0.0451 - val_root_mean_square_error: 0.2123 - val_mean_absolute_error: 0.1991Epoch 2/1033/33 [==============================] - 7s 217ms/step - loss: 0.0441 - root_mean_square_error: 0.2093 - mean_absolute_error: 0.1761 - val_loss: 0.0427 - val_root_mean_square_error: 0.2062 - val_mean_absolute_error: 0.1558Epoch 3/1033/33 [==============================] - 8s 226ms/step - loss: 0.0426 - root_mean_square_error: 0.2062 - mean_absolute_error: 0.1684 - val_loss: 0.0423 - val_root_mean_square_error: 0.2053 - val_mean_absolute_error: 0.1613Epoch 4/1033/33 [==============================] - 8s 224ms/step - loss: 0.0425 - root_mean_square_error: 0.2053 - mean_absolute_error: 0.1683 - val_loss: 0.0422 - val_root_mean_square_error: 0.2050 - val_mean_absolute_error: 0.1620Epoch 5/1033/33 [==============================] - 8s 234ms/step - loss: 0.0423 - root_mean_square_error: 0.2053 - mean_absolute_error: 0.1679 - val_loss: 0.0425 - val_root_mean_square_error: 0.2058 - val_mean_absolute_error: 0.1805Epoch 6/1033/33 [==============================] - 8s 231ms/step - loss: 0.0423 - root_mean_square_error: 0.2057 - mean_absolute_error: 0.1682 - val_loss: 0.0420 - val_root_mean_square_error: 0.2047 - val_mean_absolute_error: 0.1751Epoch 7/1033/33 [==============================] - 8s 233ms/step - loss: 0.0421 - root_mean_square_error: 0.2046 - mean_absolute_error: 0.1701 - val_loss: 0.0417 - val_root_mean_square_error: 0.2039 - val_mean_absolute_error: 0.1685Epoch 8/1033/33 [==============================] - 8s 229ms/step - loss: 0.0421 - root_mean_square_error: 0.2050 - mean_absolute_error: 0.1662 - val_loss: 0.0415 - val_root_mean_square_error: 0.2033 - val_mean_absolute_error: 0.1686Epoch 9/1033/33 [==============================] - 8s 238ms/step - loss: 0.0415 - root_mean_square_error: 0.2036 - mean_absolute_error: 0.1679 - val_loss: 0.0411 - val_root_mean_square_error: 0.2025 - val_mean_absolute_error: 0.1695Epoch 10/1033/33 [==============================] - 8s 232ms/step - loss: 0.0411 - root_mean_square_error: 0.2023 - mean_absolute_error: 0.1668 - val_loss: 0.0409 - val_root_mean_square_error: 0.2017 - val_mean_absolute_error: 0.153514/14 [==============================] - 2s 121ms/step - loss: 0.0408 - root_mean_square_error: 0.2016 - mean_absolute_error: 0.1535Test Evaluation:\tloss: 0.0408\troot_mean_square_error: 0.2016\tmean_absolute_error: 0.1535Mean Baseline Test set metrics:\troot_mean_square_error =  0.2054230809528016\tmean_absolute_error =  0.1687945779971711Model Test set metrics:\troot_mean_square_error =  0.20211308444911932\tmean_absolute_error =  0.15357324988306925.........Done trainingfrom numba import cudadevice = cuda.get_current_device()device.reset()",
        "url": "/fashion_GNN"
    }
    ,
    
    "stock-portfolio": {
        "title": "Stock Market Portfolio Modeling with R",
        "author": "Darron Kwon",
        "category": "",
        "content": "",
        "url": "/stock_portfolio"
    }
    ,
    
    "kpop-fandom": {
        "title": "K-POP Fandom Data Analysis with networkX",
        "author": "Darron Kwon",
        "category": "",
        "content": "  1. Introduction  2. Supporting Activities          2.1. Fandom Supporting Ratio (Total Supporting activities in Total activities)      2.2. Case by Gender Type      2.3. Case by Agents (Sum of artists data in a company)        3. Correlation between supporting and supported activities          3.1. by Pearson correlation      3.2. by Spearman rank correlation        4. Hyphothesis test by independent t-test          4.1. Supported activities and gender types      4.2. Supporting activities and gender types        5. Graph Analysis          5.1. Generating graphs with different time periods      5.2. Cumulative Distribution Function(CDF) with G0’s degree      5.3. Top 5 fandoms in G0 sorted by Pagerank and Degree Centrality      5.4. Supporting-supported cases by gender types in G0        6. Comparison between G1 and G2          6.1. Persistence of edges-supporting and gender types      6.2. Graph Role Extraction by RolX algorithm      6.3. Community Detection by Girvan-Newman algorithm      6.4. Page Rank and Degree Centrality in G1, G2        7. Effect of the fandom activities on the monthly chart1. Introduction      In K-POP scene, a fandom plays a critical role in the success of their idol. They even cooperate with other fandoms to achieve their goal. For example, they do “supports”; steam albums or encourage to vote in awards for another idol and get helped in the same way when their idol release an album or be nominated for an award. With these data collected in 2018, we will find out the effect of the fandom activities.    fandom information data: {fandom_id, fandom_name, nov_post, dec_post, nov_support, dec_support, type(gender)}  fandom support activities data: {source, target, nov_support, dec_support}  monthly chart data: {album, artist, rank, title, start, end}  fandoms metadata: {fandom_name, artist, agent, year(debut), #articles}import pandas as pdfrom pandas import DataFrame, Seriesimport matplotlib.pyplot as plt%matplotlib inlineimport numpy as npimport networkx as nx2. Supporting Activities2.1. Fandom Supporting Ratio (Total Supporting activities in Total activities)nodes = pd.read_csv('./dataset/fandom_nodes_2018.csv')nodes['total_support'] = nodes.loc[:,['nov_support','dec_support']].sum(axis=1)nodes['total_activity'] = nodes.loc[:,['nov_post','dec_post','nov_support','dec_support']].sum(axis=1)nodes['support_ratio'] = nodes['total_support'] / nodes['total_activity']nodes['support_ratio'] = nodes['support_ratio'].fillna(0)nodes.loc[:,['fandom_id','total_support','total_activity','support_ratio']].sort_values(by=['support_ratio'],ascending=False).head(10)                  fandom_id      total_support      total_activity      support_ratio                  213      oh_soul      14      28      0.500000              283      tbz1206      1      2      0.500000              196      myname      1      2      0.500000              3      2PM      1      2      0.500000              98      imcenter      1      2      0.500000              259      shinjihoon      921      1848      0.498377              180      livematilda0317      1458      2932      0.497271              315      xtracam      2527      5083      0.497147              303      we100      2848      5759      0.494530              201      namyujin      516      1048      0.492366        5 fandoms with very few activities seems to be not quite active in the period.nodes.describe()                  nov_post      dec_post      nov_support      dec_support      type      total_support      total_activity      support_ratio                  count      330.000000      330.000000      330.000000      330.000000      330.000000      330.000000      330.000000      330.000000              mean      5854.921212      5249.675758      1455.627273      859.090909      0.493939      2314.718182      13419.315152      0.226563              std      17573.678298      16329.999791      2329.251725      1166.459438      0.500723      3310.463410      35436.387630      0.174810              min      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000              25%      250.000000      127.500000      19.750000      7.250000      0.000000      53.750000      656.250000      0.043461              50%      1739.000000      1472.000000      535.500000      403.500000      0.000000      984.500000      4776.000000      0.221352              75%      5047.000000      4258.000000      1736.750000      1187.500000      1.000000      3077.750000      13687.000000      0.397054              max      261517.000000      249246.000000      12462.000000      6989.000000      1.000000      16917.000000      525546.000000      0.500000      2.2. Case by Gender Typeedges = pd.read_csv('./dataset/fandom_edges_2018.csv')edges['total_support'] = edges.loc[:,['nov_support','dec_support']].sum(axis=1)df_supported = edges.groupby(['target']).sum()df_supported = df_supported.reset_index()df_supported.columns = ['fandom_id','nov_supported','dec_supported','total_supported']df = pd.merge(nodes,df_supported,on='fandom_id',how='outer')df = df.fillna(0)# Supporting Top 10 fandoms for both gendersdf.loc[:,['fandom_id','total_support']].sort_values(by=['total_support'],ascending=False).head(10)                  fandom_id      total_support                  308      winner      16917              301      wannaonego      16036              31      btob      15739              181      lovelyz      15328              209      nuest      14895              292      twice      14783              183      mamamoo      14472              32      bts      14006              243      roykim      13149              81      gx9      11954      # Supporting Top 10 fandoms for boy groupsdf.loc[df['type']==1,['fandom_id','total_support']].sort_values(by=['total_support'],ascending=False).head(10)                  fandom_id      total_support                  308      winner      16917              301      wannaonego      16036              31      btob      15739              209      nuest      14895              32      bts      14006              243      roykim      13149              298      vikon      10589              88      highlight      10575              124      jsh      9673              288      tj3579      9314      # Supporting Top 10 fandoms for girl groupsdf.loc[df['type']==0,['fandom_id','total_support']].sort_values(by=['total_support'],ascending=False).head(10)                  fandom_id      total_support                  181      lovelyz      15328              292      twice      14783              183      mamamoo      14472              81      gx9      11954              67      gf      11564              234      real__izo      11104              26      blackpink      10678              214      ohmygirl      9091              236      redvelvetreveluv      8155              64      fromis      8003      # Supported Top 10 fandoms for both gendersdf.loc[:,['fandom_id','total_supported']].sort_values(by=['total_supported'],ascending=False).head(10)                  fandom_id      total_supported                  301      wannaonego      33609.0              181      lovelyz      29083.0              234      real__izo      25459.0              32      bts      24865.0              308      winner      21896.0              209      nuest      19312.0              183      mamamoo      18795.0              67      gf      14899.0              124      jsh      14437.0              243      roykim      14267.0      # Supported Top 10 fandoms for boyt groupsdf.loc[df['type']==1,['fandom_id','total_supported']].sort_values(by=['total_supported'],ascending=False).head(10)                  fandom_id      total_supported                  301      wannaonego      33609.0              32      bts      24865.0              308      winner      21896.0              209      nuest      19312.0              124      jsh      14437.0              243      roykim      14267.0              298      vikon      14245.0              137      kim      13884.0              4      6kies      13565.0              31      btob      11493.0      # Supported Top 10 fandoms for girl groupsdf.loc[df['type']==0,['fandom_id','total_supported']].sort_values(by=['total_supported'],ascending=False).head(10)                  fandom_id      total_supported                  181      lovelyz      29083.0              234      real__izo      25459.0              183      mamamoo      18795.0              67      gf      14899.0              64      fromis      13957.0              292      twice      12942.0              214      ohmygirl      12335.0              26      blackpink      9632.0              262      shitaomiu      8563.0              125      jungchaeyeon      6820.0      2.3. Case by Agents (Sum of artists data in a company)meta = pd.read_json('./dataset/fandom_meta_2018.json')df_meta = meta.copy()df_meta.rename(columns={'fandom_name':'fandom_id'},inplace=True)df_metadf = pd.merge(df,df_meta,on='fandom_id')# Supporting Top 10 Agentsdf.groupby(['agent'])[['total_support','total_supported']].sum().sort_values(by='total_support',ascending=False).head(10)                  total_support      total_supported              agent                              YG Entertainment      67790      81735.0              JYP Entertainment      54025      41464.0              Off The Record      47300      75508.0              Swing Entertainment      41180      73716.0              SM Entertainment      38862      23736.0              PLEDIS Entertainment      38839      43115.0              Cube Entertainment      30991      20990.0              Woollim Entertainment      22780      35219.0              Jellyfish Entertainment      17606      7583.0              Fantagio Music      15853      8202.0      # Supported Top 10 Agentsdf.groupby(['agent'])[['total_support','total_supported']].sum().sort_values(by='total_supported',ascending=False).head(10)                  total_support      total_supported              agent                              YG Entertainment      67790      81735.0              Off The Record      47300      75508.0              Swing Entertainment      41180      73716.0              PLEDIS Entertainment      38839      43115.0              JYP Entertainment      54025      41464.0              Woollim Entertainment      22780      35219.0              Big Hit Entertainment      14006      24865.0              SM Entertainment      38862      23736.0              Cube Entertainment      30991      20990.0              AKS      8554      19646.0      3. Correlation between supporting and supported activities3.1. by Pearson correlationfrom scipy import statsprint(stats.pearsonr(df['total_activity'],df['total_support']))print(stats.pearsonr(df['total_activity'],df['total_supported']))(0.538005581735917, 3.725917667518625e-26)(0.5114446175904475, 2.1548883750451727e-23)3.2. by Spearman rank correlationprint(stats.spearmanr(df['total_activity'],df['total_support']))print(stats.spearmanr(df['total_activity'],df['total_supported']))SpearmanrResult(correlation=0.8461473515842707, pvalue=1.1711298194140583e-91)SpearmanrResult(correlation=0.8244727920052708, pvalue=4.2257040130501645e-83)  Spearman rank method shows better correlation and confidence level in average.4. Hyphothesis test by independent t-test4.1. Supported activities and gender types  H_0: There is a difference in supported activities between girl and boy groups.  H_1: There is no difference in supported activities between girl and boy groups.boy = df.loc[df['type']==1,['fandom_id','total_supported','total_support']]girl = df.loc[df['type']==0,['fandom_id','total_supported','total_support']]len(boy),len(girl)(163, 167)# t-teststats.ttest_ind(boy['total_supported'], girl['total_supported'])Ttest_indResult(statistic=1.494285307111671, pvalue=0.1360624474957505)4.2. Supporting activities and gender types  H_0: There is a difference in supporting activities between girl and boy groups.  H_1: There is no difference in supporting activities between girl and boy groups.# t-teststats.ttest_ind(boy['total_support'], girl['total_support'])Ttest_indResult(statistic=1.33823756824641, pvalue=0.1817459557355244)  both H_0’s would not be rejected5. Graph Analysis5.1. Generating graphs with different time periods  G0; graph with data in entire periodG1; grpah with data in novemberG2; grpah with data in decembertotal_edges = edges[['source','target','total_support']].sort_values(by='total_support',ascending=False)total_edges = total_edges.iloc[:int(len(total_edges)*0.01),]G0 = nx.DiGraph(total_edges.loc[:,('source','target')].values.tolist())nx.set_edge_attributes(G0, total_edges.set_index(['source', 'target'])['total_support'], 'weight')nx.set_node_attributes(G0,df.set_index(['fandom_id'])['agent'],'agent')nx.set_node_attributes(G0,df.set_index(['fandom_id'])['year(debut)'],'debut_year')nx.set_node_attributes(G0,df.set_index(['fandom_id'])['type'],'gender_type')nov_edges = edges[['source','target','nov_support']].sort_values(by='nov_support',ascending=False)nov_edges = nov_edges.iloc[:int(len(nov_edges)*0.01),]G1 = nx.DiGraph(nov_edges.loc[:,('source','target')].values.tolist())nx.set_edge_attributes(G1, nov_edges.set_index(['source', 'target'])['nov_support'], 'weight')nx.set_node_attributes(G1,df.set_index(['fandom_id'])['agent'],'agent')nx.set_node_attributes(G1,df.set_index(['fandom_id'])['year(debut)'],'debut_year')nx.set_node_attributes(G1,df.set_index(['fandom_id'])['type'],'gender_type')dec_edges = edges[['source','target','dec_support']].sort_values(by='dec_support',ascending=False)dec_edges = dec_edges.iloc[:int(len(dec_edges)*0.01),]G2 = nx.DiGraph(dec_edges.loc[:,('source','target')].values.tolist())nx.set_edge_attributes(G2, dec_edges.set_index(['source', 'target'])['dec_support'], 'weight')nx.set_node_attributes(G2,df.set_index(['fandom_id'])['agent'],'agent')nx.set_node_attributes(G2,df.set_index(['fandom_id'])['year(debut)'],'debut_year')nx.set_node_attributes(G2,df.set_index(['fandom_id'])['type'],'gender_type')print(len(G0.nodes),len(G0.edges)) print(len(G1.nodes),len(G1.edges)) print(len(G2.nodes),len(G2.edges)) 59 23662 23690 2365.2. Cumulative Distribution Function(CDF) with G0’s degreeG0_degree = dict(nx.degree(G0))h = plt.hist(G0_degree.values())cdf = stats.norm().cdf(sorted(G0_degree.values()))plt.plot(sorted(G0_degree.values()), cdf)plt.show()5.3. Top 5 fandoms in G0 sorted by Pagerank and Degree Centrality  in both results, top fandoms shows very high scores in features - supporting, supported, total activites, while the average of supporting/supported activities for all data is  2,314 and the average of total activities for all data is about 13,419.def viewer(_dict_data, col_name):    result = pd.DataFrame().from_dict(_dict_data, orient='index', columns=[col_name])    return df.set_index('fandom_id').join(result, how='right').sort_values(col_name, ascending=False)pagerank = nx.pagerank(G0)pagerank = viewer(pagerank, 'pagerank')pagerank.head(5)[['type','total_support','total_activity','total_supported','agent','year(debut)','pagerank']]                  type      total_support      total_activity      total_supported      agent      year(debut)      pagerank                  wannaonego      1      16036      77608      33609.0      Swing Entertainment      2017      0.131164              real__izo      0      11104      90757      25459.0      Off The Record      2018      0.081406              lovelyz      0      15328      171752      29083.0      Woollim Entertainment      2014      0.076592              jsh      1      9673      20872      14437.0      Antenna      2016      0.065368              nuest      1      14895      56741      19312.0      PLEDIS Entertainment      2012      0.064216      degree_centrality = nx.degree_centrality(G0)degree_centrality = viewer(degree_centrality, 'degree_centrality')degree_centrality.head(5)[['type','total_support','total_activity','total_supported','agent','year(debut)','degree_centrality']]                  type      total_support      total_activity      total_supported      agent      year(debut)      degree_centrality                  wannaonego      1      16036      77608      33609.0      Swing Entertainment      2017      0.827586              lovelyz      0      15328      171752      29083.0      Woollim Entertainment      2014      0.482759              winner      1      16917      41928      21896.0      YG Entertainment      2014      0.465517              nuest      1      14895      56741      19312.0      PLEDIS Entertainment      2012      0.448276              bts      1      14006      125849      24865.0      Big Hit Entertainment      2013      0.431034      df[['total_support','total_activity','total_supported']].describe()                  total_support      total_activity      total_supported                  count      330.000000      330.000000      330.000000              mean      2314.718182      13419.315152      2314.718182              std      3310.463410      35436.387630      4464.948830              min      0.000000      0.000000      0.000000              25%      53.750000      656.250000      2.000000              50%      984.500000      4776.000000      511.500000              75%      3077.750000      13687.000000      2923.500000              max      16917.000000      525546.000000      33609.000000      5.4. Supporting-supported cases by gender types in G0  Generally, boy group fandoms are more supporting.G0_support = pd.DataFrame().from_dict({e for e in G0.edges})G0_support.columns = ['source','target']tmp = pd.DataFrame().from_dict({n for n in G0.nodes.data('gender_type')})tmp.columns = ['source','source_gender']G0_support = pd.merge(G0_support,tmp,how='left')tmp.columns = ['target','target_gender']G0_support = pd.merge(G0_support,tmp,how='left')G0_support                  source      target      source_gender      target_gender                  0      winner      day6      1      1              1      btob      mamamoo      1      0              2      mmld      ohmygirl      0      0              3      nuest      got7vlive      1      1              4      nuest      ch_freemonth      1      0              ...      ...      ...      ...      ...              231      sanarang      twice      0      0              232      6kies      wannaonego      1      1              233      redvelvetreveluv      wannaonego      0      1              234      mamamoo      twice      0      0              235      gx9      vikon      0      1      236 rows × 4 columns# boy -&gt; boyprint(len(G0_support[(G0_support.source_gender==1) &amp; (G0_support.target_gender==1)]) / len(G0_support))# boy -&gt; girlprint(len(G0_support[(G0_support.source_gender==1) &amp; (G0_support.target_gender==0)]) / len(G0_support))# girl -&gt; boyprint(len(G0_support[(G0_support.source_gender==0) &amp; (G0_support.target_gender==1)]) / len(G0_support))# girl -&gt; girlprint(len(G0_support[(G0_support.source_gender==0) &amp; (G0_support.target_gender==0)]) / len(G0_support))0.32203389830508470.26271186440677970.25423728813559320.161016949152542366. Comparison between G1 and G26.1. Persistence of edges-supporting and gender typesG1_support = set(e for e in G1.edges)G2_support = set(e for e in G2.edges)G1_only = pd.DataFrame.from_dict(G1_support - G2_support)G1_only.columns = ['source','target']tmp = pd.DataFrame().from_dict({n for n in G1.nodes.data('gender_type')})tmp.columns = ['source','source_gender']G1_only = pd.merge(G1_only,tmp,how='left')tmp.columns = ['target','target_gender']G1_only = pd.merge(G1_only,tmp,how='left')# Supporting in november onlyG1_only                  source      target      source_gender      target_gender                  0      winner      day6      1      1              1      mamamoo      wannaonego      0      1              2      btob      mamamoo      1      0              3      mmld      ohmygirl      0      0              4      nuest      got7vlive      1      1              ...      ...      ...      ...      ...              139      anyujin      wannaonego      0      1              140      buzz      mamamoo      1      0              141      redvelvetreveluv      wannaonego      0      1              142      idlesong      lovelyz      0      0              143      gx9      vikon      0      1      144 rows × 4 columnsG2_only = pd.DataFrame.from_dict(G2_support-G1_support)G2_only.columns = ['source','target']tmp = pd.DataFrame().from_dict({n for n in G2.nodes.data('gender_type')})tmp.columns = ['source','source_gender']G2_only = pd.merge(G2_only,tmp,how='left')tmp.columns = ['target','target_gender']G2_only = pd.merge(G2_only,tmp,how='left')# Supporting in december onlyG2_only                  source      target      source_gender      target_gender                  0      wheesung      bts      1      1              1      mkyunghoon      lovelyz      1      0              2      bts      nuest      1      1              3      god      bts      1      1              4      onairpril      lovelyz      0      0              ...      ...      ...      ...      ...              139      jjy      vikon      1      1              140      sanarang      twice      0      0              141      onf      lovelyz      1      0              142      got7vlive      fromis      1      0              143      idlesong      blackpink      0      0      144 rows × 4 columnsG1_n_G2 = pd.DataFrame.from_dict(G1_support &amp; G2_support)G1_n_G2.columns = ['source','target']tmp = pd.DataFrame().from_dict({n for n in G1.nodes.data('gender_type')})tmp.columns = ['source','source_gender']G1_n_G2 = pd.merge(G1_n_G2,tmp,how='left')tmp.columns = ['target','target_gender']G1_n_G2 = pd.merge(G1_n_G2,tmp,how='left')# Supporting in both monthsG1_n_G2                  source      target      source_gender      target_gender                  0      twice      roykim      0      1              1      guckkasten      wannaonego      1      1              2      bigbang      wannaonego      1      1              3      btob      bts      1      1              4      ohmygirl      fromis      0      0              ...      ...      ...      ...      ...              87      real__izo      wannaonego      0      1              88      tj3579      jsh      1      1              89      nuest      jsh      1      1              90      6kies      wannaonego      1      1              91      mamamoo      twice      0      0      92 rows × 4 columns# boy -&gt; boyprint(len(G1_n_G2[(G1_n_G2.source_gender==1) &amp; (G1_n_G2.target_gender==1)]) / len(G1_n_G2))# boy -&gt; girlprint(len(G1_n_G2[(G1_n_G2.source_gender==1) &amp; (G1_n_G2.target_gender==0)]) / len(G1_n_G2))# girl -&gt; boyprint(len(G1_n_G2[(G1_n_G2.source_gender==0) &amp; (G1_n_G2.target_gender==1)]) / len(G1_n_G2))# girl -&gt; girlprint(len(G1_n_G2[(G1_n_G2.source_gender==0) &amp; (G1_n_G2.target_gender==0)]) / len(G1_n_G2))0.402173913043478270.217391304347826080.250.130434782608695656.2. Graph Role Extraction by RolX algorithmfrom pprint import pprintimport seaborn as snsfrom graphrole import RecursiveFeatureExtractor, RoleExtractorfeature_extractor = RecursiveFeatureExtractor(G1)features = feature_extractor.extract_features()role_extractor = RoleExtractor(n_roles=None)role_extractor.extract_role_factors(features)G1_roles = role_extractor.rolesG1_role_groups = {}for n,r in G1_roles.items():    if r in G1_role_groups:        G1_role_groups[r].append(n)    else:        G1_role_groups[r] = [n]for r,g in G1_role_groups.items():    print(r,g)role_2 ['6kies', 'ahnhyungsub', 'anyujin', 'apink', 'boa', 'dmlwlsska', 'girlsgeneration_new', 'girlsofthemonth', 'haonkim', 'highfiveofteenager', 'idlesong', 'jjy', 'jungsewoon', 'jungyeon', 'kgkg', 'kim', 'kimsejeong', 'mkyunghoon', 'mmld', 'nth0510', 'onairpril', 'paka', 'pjb', 'sakura0319', 'samkim', 'shinhwa', 'taeyeon_new1', 'unitb', 'wheesung', 'yuseonho']role_4 ['bigbang', 'blackpink', 'ch_freemonth', 'chungha', 'fromis', 'guckkasten', 'iu_tv', 'redvelvetreveluv', 'tj3579', 'vikon']role_1 ['btob', 'bts', 'gx9', 'jsh', 'mamamoo', 'nuest', 'real__izo', 'roykim', 'straykids', 'wannaonego', 'winner', 'zico']role_3 ['buzz', 'got7vlive', 'kimdonghan', 'madewg', 'twice']role_0 ['day6', 'gf', 'lovelyz', 'miyazakimiho', 'ohmygirl']feature_extractor = RecursiveFeatureExtractor(G2)features = feature_extractor.extract_features()role_extractor = RoleExtractor(n_roles=5) # set 'n_roles' same as G1`srole_extractor.extract_role_factors(features)G2_roles = role_extractor.rolesG2_role_groups = {}for n,r in G2_roles.items():    if r in G2_role_groups:        G2_role_groups[r].append(n)    else:        G2_role_groups[r] = [n]for r,g in G2_role_groups.items():    print(r,g)role_2 ['6kies', 'ahnhyungsub', 'berrygood', 'blackpink', 'buzz', 'dickpunks', 'fromis', 'highfiveofteenager', 'jjy', 'jungchaeyeon', 'kgkg', 'kimsejeong', 'lovelyz', 'mmld', 'pjb', 'real__izo', 'sanarang', 'wheesung', 'wjsnvlive', 'woojinyoung', 'zico']role_4 ['astro', 'b1a4', 'bigbang', 'doakim', 'doitamazing7', 'dongbang_new', 'fortediquattro', 'girllaboum', 'girlsgeneration_new', 'god', 'godgayoung', 'goldenchild', 'guckkasten', 'gx9', 'highlight', 'hotshot', 'in2it', 'infinite', 'ioi', 'iu_tv', 'jsh', 'kanghyewon', 'kim', 'kimchaewon', 'kimdonghan', 'ksy', 'ladiescode', 'mamamoo', 'mino0330', 'mkyunghoon', 'nojisun', 'nth0510', 'nuest', 'ohmygirl', 'onairpril', 'onf', 'paka', 'pentagon', 'pledis', 'pushkang', 'redvelvetreveluv', 'sonamoo', 'taewookim', 'tj3579', 'vikon', 'wekimeki']role_1 ['btob', 'bts', 'day6', 'gf', 'got7vlive', 'idlesong', 'madewg', 'roykim', 'straykids', 'twice', 'wannaonego', 'winner']role_0 ['dmlwlsska', 'eunjiwon', 'jdh', 'jeonsomi', 'jungsewoon', 'kdani', 'leechaeyeon', 'miyazakimiho', 'yabukinako']role_3 ['shitaomiu', 'take_miyu']6.3. Community Detection by Girvan-Newman algorithmfrom networkx.algorithms import communitycomp = community.girvan_newman(G1.to_undirected())communities = tuple(sorted(c) for c in next(comp))print([len(c) for c in communities])for c in communities:    print(c)[39, 23]['6kies', 'apink', 'bigbang', 'blackpink', 'btob', 'bts', 'ch_freemonth', 'chungha', 'day6', 'fromis', 'gf', 'girlsgeneration_new', 'girlsofthemonth', 'got7vlive', 'guckkasten', 'gx9', 'haonkim', 'idlesong', 'iu_tv', 'jsh', 'jungyeon', 'kimdonghan', 'lovelyz', 'madewg', 'mamamoo', 'mkyunghoon', 'mmld', 'nuest', 'ohmygirl', 'pjb', 'real__izo', 'redvelvetreveluv', 'roykim', 'straykids', 'tj3579', 'twice', 'vikon', 'winner', 'zico']['ahnhyungsub', 'anyujin', 'boa', 'buzz', 'dmlwlsska', 'highfiveofteenager', 'jjy', 'jungsewoon', 'kgkg', 'kim', 'kimsejeong', 'miyazakimiho', 'nth0510', 'onairpril', 'paka', 'sakura0319', 'samkim', 'shinhwa', 'taeyeon_new1', 'unitb', 'wannaonego', 'wheesung', 'yuseonho']comp = community.girvan_newman(G2.to_undirected())communities = tuple(sorted(c) for c in next(comp))print([len(c) for c in communities])for c in communities:    print(c)[84, 6]['6kies', 'ahnhyungsub', 'astro', 'b1a4', 'berrygood', 'bigbang', 'blackpink', 'btob', 'bts', 'buzz', 'day6', 'dickpunks', 'doakim', 'doitamazing7', 'dongbang_new', 'eunjiwon', 'fortediquattro', 'fromis', 'gf', 'girllaboum', 'girlsgeneration_new', 'god', 'godgayoung', 'goldenchild', 'got7vlive', 'guckkasten', 'gx9', 'highfiveofteenager', 'highlight', 'hotshot', 'in2it', 'infinite', 'ioi', 'iu_tv', 'jdh', 'jjy', 'jsh', 'jungchaeyeon', 'jungsewoon', 'kanghyewon', 'kdani', 'kgkg', 'kim', 'kimchaewon', 'kimdonghan', 'kimsejeong', 'ksy', 'ladiescode', 'leechaeyeon', 'lovelyz', 'madewg', 'mamamoo', 'mino0330', 'mkyunghoon', 'mmld', 'nojisun', 'nth0510', 'nuest', 'ohmygirl', 'onairpril', 'onf', 'paka', 'pentagon', 'pjb', 'pledis', 'pushkang', 'real__izo', 'redvelvetreveluv', 'roykim', 'sanarang', 'sonamoo', 'straykids', 'taewookim', 'tj3579', 'twice', 'vikon', 'wannaonego', 'wekimeki', 'wheesung', 'winner', 'wjsnvlive', 'woojinyoung', 'yabukinako', 'zico']['dmlwlsska', 'idlesong', 'jeonsomi', 'miyazakimiho', 'shitaomiu', 'take_miyu']6.4. Page Rank and Degree Centrality in G1, G2pagerank = nx.pagerank(G1)pagerank = viewer(pagerank, 'pagerank')pagerank.head(10).indexIndex(['wannaonego', 'real__izo', 'jsh', 'nuest', 'winner', 'roykim',       'lovelyz', 'ohmygirl', 'gf', 'twice'],      dtype='object')pagerank = nx.pagerank(G2)pagerank = viewer(pagerank, 'pagerank')pagerank.head(10).indexIndex(['lovelyz', 'bts', 'jsh', 'wannaonego', 'fromis', 'nuest', 'gf', 'twice',       'highfiveofteenager', 'roykim'],      dtype='object')degree_centrality = nx.degree_centrality(G1)degree_centrality = viewer(degree_centrality, 'degree_centrality')degree_centrality.head(10).indexIndex(['wannaonego', 'nuest', 'real__izo', 'winner', 'mamamoo', 'roykim',       'jsh', 'bts', 'lovelyz', 'twice'],      dtype='object')degree_centrality = nx.degree_centrality(G2)degree_centrality = viewer(degree_centrality, 'degree_centrality')degree_centrality.head(10).indexIndex(['lovelyz', 'bts', 'wannaonego', 'winner', 'twice', 'jsh', 'fromis',       'gf', 'nuest', 'btob'],      dtype='object')7. Effect of the fandom activities on the monthly chartmonthly_chart = pd.read_json('./dataset/monthly_chart_2018.json')m11 = monthly_chart[monthly_chart.start==201811]m12 = monthly_chart[monthly_chart.start==201812]df_chart = df[['fandom_id','chart_name','total_activity','nov_supported','dec_supported','total_supported']]in_nov = df_chart['chart_name'].isin(m11['artist'])df_nov = df_chart[in_nov].groupby(['chart_name']).sum()rank_nov = m11[m11['artist'].isin(df_chart['chart_name'])].groupby(['artist'])['rank'].mean()chart_nov = pd.merge(df_nov,rank_nov,left_index=True,right_index=True,how='left')chart_nov.sort_values(by='rank')                  total_activity      nov_supported      dec_supported      total_supported      rank              chart_name                                                바이브      1088      70.0      7.0      77.0      4.000000              임창정      1649      6.0      1.0      7.0      7.000000              벤      304      4.0      0.0      4.0      16.000000              TWICE (트와이스)      606440      8341.0      5549.0      13890.0      17.500000              아이유      130843      2467.0      1407.0      3874.0      19.000000              선미      718      36.0      5.0      41.0      20.000000              IZ*ONE (아이즈원)      309295      37770.0      18416.0      56186.0      22.000000              로이킴      30003      10979.0      3288.0      14267.0      29.500000              iKON      33653      9430.0      5150.0      14580.0      39.500000              비투비      47090      6551.0      4942.0      11493.0      41.250000              BLACKPINK      104426      7314.0      2318.0      9632.0      45.500000              Red Velvet (레드벨벳)      194521      6117.0      3132.0      9249.0      50.000000              EXO      28649      5.0      1.0      6.0      55.272727              방탄소년단      125849      14519.0      10346.0      24865.0      63.300000              Apink (에이핑크)      89709      507.0      492.0      999.0      71.000000              하이라이트 (Highlight)      29392      4317.0      3357.0      7674.0      75.000000              Wanna One (워너원)      427571      47720.0      25996.0      73716.0      77.800000              정승환      20872      9704.0      4733.0      14437.0      78.000000              지코 (ZICO)      19315      2272.0      566.0      2838.0      84.000000              (여자)아이들      22860      1500.0      830.0      2330.0      91.000000      df_chart = df[['fandom_id','chart_name','total_activity','nov_supported','dec_supported','total_supported']]in_dec = df_chart['chart_name'].isin(m12['artist'])df_dec = df_chart[in_dec].groupby(['chart_name']).sum()rank_dec = m12[m12['artist'].isin(df_chart['chart_name'])].groupby(['artist'])['rank'].mean()chart_dec = pd.merge(df_dec,rank_dec,left_index=True,right_index=True,how='left')chart_dec.sort_values(by='rank')                  total_activity      nov_supported      dec_supported      total_supported      rank              chart_name                                                바이브      1088      70.0      7.0      77.0      6.000000              벤      304      4.0      0.0      4.0      12.000000              임창정      1649      6.0      1.0      7.0      15.000000              허각      336      0.0      0.0      0.0      17.000000              WINNER      69689      17153.0      11363.0      28516.0      21.000000              TWICE (트와이스)      606440      8341.0      5549.0      13890.0      25.500000              아이유      130843      2467.0      1407.0      3874.0      33.000000              IZ*ONE (아이즈원)      309295      37770.0      18416.0      56186.0      37.000000              비투비      47090      6551.0      4942.0      11493.0      38.666667              BLACKPINK      104426      7314.0      2318.0      9632.0      39.000000              선미      718      36.0      5.0      41.0      40.000000              로이킴      30003      10979.0      3288.0      14267.0      45.000000              EXO      28649      5.0      1.0      6.0      60.000000              Red Velvet (레드벨벳)      194521      6117.0      3132.0      9249.0      66.000000              EXID      28513      19.0      6.0      25.0      66.000000              방탄소년단      125849      14519.0      10346.0      24865.0      67.875000              iKON      33653      9430.0      5150.0      14580.0      71.000000              Wanna One (워너원)      427571      47720.0      25996.0      73716.0      73.000000      print(stats.spearmanr(chart_nov['nov_supported'],chart_nov['rank']))print(stats.spearmanr(chart_dec['dec_supported'],chart_dec['rank']))SpearmanrResult(correlation=0.2721804511278195, pvalue=0.2456688782803774)SpearmanrResult(correlation=0.42480625827858726, pvalue=0.07887457444015573)common = pd.merge(chart_nov[chart_nov.index.isin(chart_dec.index)],chart_dec['rank'],left_index=True,right_index=True,how='left')common.sort_values(by=['rank_x','rank_y'])                  total_activity      nov_supported      dec_supported      total_supported      rank_x      rank_y              chart_name                                                      바이브      1088      70.0      7.0      77.0      4.000000      6.000000              임창정      1649      6.0      1.0      7.0      7.000000      15.000000              벤      304      4.0      0.0      4.0      16.000000      12.000000              TWICE (트와이스)      606440      8341.0      5549.0      13890.0      17.500000      25.500000              아이유      130843      2467.0      1407.0      3874.0      19.000000      33.000000              선미      718      36.0      5.0      41.0      20.000000      40.000000              IZ*ONE (아이즈원)      309295      37770.0      18416.0      56186.0      22.000000      37.000000              로이킴      30003      10979.0      3288.0      14267.0      29.500000      45.000000              iKON      33653      9430.0      5150.0      14580.0      39.500000      71.000000              비투비      47090      6551.0      4942.0      11493.0      41.250000      38.666667              BLACKPINK      104426      7314.0      2318.0      9632.0      45.500000      39.000000              Red Velvet (레드벨벳)      194521      6117.0      3132.0      9249.0      50.000000      66.000000              EXO      28649      5.0      1.0      6.0      55.272727      60.000000              방탄소년단      125849      14519.0      10346.0      24865.0      63.300000      67.875000              Wanna One (워너원)      427571      47720.0      25996.0      73716.0      77.800000      73.000000      print(stats.spearmanr(common['nov_supported'],common['rank_x']))print(stats.spearmanr(common['dec_supported'],common['rank_y']))SpearmanrResult(correlation=0.4892857142857142, pvalue=0.06416038631454055)SpearmanrResult(correlation=0.5004470273579545, pvalue=0.057440003802729525)",
        "url": "/kpop_fandom"
    }
    ,
    
    "stock-cluster": {
        "title": "Stock Market Cluster Analysis with NetworkX",
        "author": "Darron Kwon",
        "category": "",
        "content": "  1. Data Load and Preprocessing  2. Data Visualization          2.1. Stock Price Volatility      2.2. Rolling Average of Stock Price Correlation        3. Network Analysis          3.1. Build Graph with Correlation table      3.2. Setting threshold on weights      3.3. Community Detection      3.4. Visualization with Gephi      1. Data Load and Preprocessingimport pandas as pdimport numpy as npimport matplotlib.pyplot as pltfrom matplotlib.collections import LineCollectionfrom sklearn import cluster, covariance, manifoldfrom community import community_louvain as louvainimport matplotlib.cm as cmimport networkx as nximport networkx.algorithms.community as nxcomfrom importlib import reloadimport csvimport osimport re%matplotlib inlinedf_prices = pd.read_csv(\"SP500_prices.csv\", index_col = 0)df_indices = pd.read_csv(\"indices.csv\")df_SP500 = pd.read_csv(\"SP500.csv\",index_col = 0)df_prices.describe()                  open      high      low      close      volume      adjusted                  count      282821.000000      282821.000000      282821.000000      282821.000000      2.828210e+05      282821.000000              mean      139.384227      141.184891      137.569435      139.425703      4.983235e+06      137.510842              std      249.635882      253.080583      246.310869      249.739199      1.180107e+07      249.704273              min      3.220000      3.290000      3.020000      3.120000      0.000000e+00      3.092542              25%      47.780000      48.419998      47.120000      47.790001      1.010000e+06      46.309925              50%      86.430000      87.480003      85.320000      86.420000      2.034800e+06      84.330002              75%      151.500000      153.380005      149.600006      151.570000      4.528900e+06      148.930000              max      4742.610000      4832.800000      4700.000000      4776.410000      4.286171e+08      4776.410000      df_prices.head()                  symbol      date      open      high      low      close      volume      adjusted                  1      AAPL      2019-01-02      38.722500      39.712502      38.557499      39.480000      148158800.0      38.505024              2      AAPL      2019-01-03      35.994999      36.430000      35.500000      35.547501      365248800.0      34.669640              3      AAPL      2019-01-04      36.132500      37.137501      35.950001      37.064999      234428400.0      36.149662              4      AAPL      2019-01-07      37.174999      37.207500      36.474998      36.982498      219111200.0      36.069202              5      AAPL      2019-01-08      37.389999      37.955002      37.130001      37.687500      164101200.0      36.756794      df_prices_adj = df_prices[['symbol','date', 'adjusted']]df_prices_adj.columns = ['symbol','date','price']df_prices_adj.tail()                  symbol      date      price                  282817      NWS      2021-03-24      23.69              282818      NWS      2021-03-25      24.42              282819      NWS      2021-03-26      24.01              282820      NWS      2021-03-29      23.39              282821      NWS      2021-03-30      23.83      df_indices.describe()                  Unnamed: 0      price                  count      16385.000000      16215.000000              mean      8193.000000      588.995521              std      4730.086416      3309.895206              min      1.000000      -36.980000              25%      4097.000000      1.284350              50%      8193.000000      4.227200              75%      12289.000000      107.426300              max      16385.000000      59221.230000      df_indices.head()                  Unnamed: 0      symbol      date      price                  0      1      DPROPANEMBTX      2019-01-02      0.641              1      2      DPROPANEMBTX      2019-01-03      0.630              2      3      DPROPANEMBTX      2019-01-04      0.635              3      4      DPROPANEMBTX      2019-01-07      0.623              4      5      DPROPANEMBTX      2019-01-08      0.628      df_indices = df_indices[[\"symbol\",\"date\",\"price\"]]df_indices.tail()                  symbol      date      price                  16380      THREEFY5      2021-03-24      0.8123              16381      THREEFY5      2021-03-25      0.8126              16382      THREEFY5      2021-03-26      0.8354              16383      THREEFY5      2021-03-29      0.8687              16384      THREEFY5      2021-03-30      0.8818      df_SP500.head()                  symbol      company      identifier      sedol      weight      sector      shares_held      local_currency      exchange                  1      AAPL      Apple Inc.      03783310      2046251      0.059338      Information Technology      161340980      USD      SP500              2      MSFT      Microsoft Corporation      59491810      2588173      0.055094      Information Technology      77110660      USD      SP500              3      AMZN      Amazon.com Inc.      02313510      2000019      0.040733      Consumer Discretionary      4376067      USD      SP500              4      FB      Facebook Inc. Class A      30303M10      B7TL820      0.021718      Communication Services      24592958      USD      SP500              5      GOOGL      Alphabet Inc. Class A      02079K30      BYVY8G0      0.019521      Communication Services      3074670      USD      SP500      df = pd.concat([df_prices_adj,df_indices])df['date'] = pd.to_datetime(df['date'], format='%Y%m%d', errors='ignore')df.set_index(['date','symbol'],inplace=True)df=df.unstack()['price']df.fillna(method='bfill',inplace=True)df            symbol      A      AAL      AAP      AAPL      ABBV      ABC      ABMD      ABT      ACN      ADBE      ...      XEL      XLNX      XOM      XRAY      XYL      YUM      ZBH      ZBRA      ZION      ZTS              date                                                                                                                                                2019-01-02      64.511734      31.96316      156.2589      38.505024      79.101799      71.46416      309.96      67.034943      136.179626      224.570007      ...      45.400452      84.360565      60.557911      37.21114      64.63606      87.819199      100.576180      156.24      38.71991      83.337715              2019-01-03      62.135132      29.58167      161.1371      34.669640      76.495514      70.42746      302.29      63.871284      131.530212      215.699997      ...      45.221561      81.184296      59.628124      37.23077      62.42029      85.610275      98.756989      146.88      38.50573      80.457184              2019-01-04      64.285828      31.53016      157.1396      36.149662      78.959961      71.24338      313.44      65.694260      136.644577      226.190002      ...      45.664082      84.943359      61.826595      38.31106      65.05392      87.838394      102.129860      152.97      39.68837      83.613907              2019-01-07      65.650917      32.42568      159.4450      36.069202      80.112411      71.75211      314.80      66.678070      137.119217      229.259995      ...      45.466366      87.187141      62.148109      38.99852      64.09184      87.742371      102.169182      155.29      39.84668      84.117012              2019-01-08      66.613335      31.90411      158.3368      36.756794      80.484734      72.52003      318.42      65.877518      140.586914      232.679993      ...      45.993618      85.526176      62.599968      38.73336      64.69435      87.569496      99.877983      156.33      40.20985      85.369850              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              2021-03-24      120.656403      21.81000      181.7300      120.089996      103.059998      115.37000      294.21      118.019997      267.549988      451.510010      ...      65.580002      119.959999      56.340000      60.25000      101.11000      107.080002      157.210648      463.81      53.01000      155.429993              2021-03-25      121.714798      22.77000      185.6500      120.589996      103.879997      117.34000      294.14      119.050003      268.609985      450.989990      ...      66.000000      120.029999      56.180000      60.55000      101.93000      107.379997      157.639999      461.26      54.74000      152.880005              2021-03-26      125.449112      22.93000      187.3200      121.209999      105.980003      118.73000      301.40      122.070000      280.769989      469.089996      ...      66.309998      123.139999      57.709999      61.28000      104.76000      108.059998      161.320007      476.96      55.85000      156.149994              2021-03-29      125.229446      22.91000      185.0600      121.389999      106.730003      119.05000      305.77      122.230003      279.540009      469.320007      ...      67.000000      122.230003      57.400002      62.06000      104.27000      109.209999      160.210007      467.07      53.89000      158.389999              2021-03-30      124.650322      24.12000      186.0700      119.900002      106.790001      119.06000      309.88      119.750000      278.549988      465.459991      ...      66.010002      120.300003      56.689999      63.54000      104.88000      109.769997      161.220001      474.83      55.91000      157.039993      565 rows × 531 columnsdf = (df-df.mean())/df.std()df.describe()             symbol      A      AAL      AAP      AAPL      ABBV      ABC      ABMD      ABT      ACN      ADBE      ...      XEL      XLNX      XOM      XRAY      XYL      YUM      ZBH      ZBRA      ZION      ZTS                  count      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      ...      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02      5.650000e+02              mean      -5.533430e-16      -1.156990e-15      -2.339132e-15      2.364284e-15      -3.420666e-15      -1.307902e-15      7.797106e-16      4.426744e-15      8.551665e-16      4.326136e-15      ...      -1.237476e-14      4.099769e-15      7.545587e-16      -1.760637e-16      -7.646194e-15      -1.936701e-15      -2.678683e-15      -1.810941e-15      -2.867323e-15      -3.068539e-15              std      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      ...      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00      1.000000e+00              min      -1.402956e+00      -1.578205e+00      -4.368070e+00      -1.422373e+00      -1.783790e+00      -1.920594e+00      -1.960001e+00      -1.883874e+00      -2.071674e+00      -1.646058e+00      ...      -2.597860e+00      -2.077320e+00      -1.906102e+00      -2.730556e+00      -2.111907e+00      -4.089893e+00      -3.106090e+00      -1.373928e+00      -2.269724e+00      -2.059833e+00              25%      -7.205020e-01      -1.081580e+00      -3.269484e-01      -9.160365e-01      -8.075055e-01      -6.871508e-01      -9.956515e-01      -7.258871e-01      -7.138452e-01      -9.190687e-01      ...      -5.309481e-01      -7.727544e-01      -9.708038e-01      -8.461749e-01      -5.681917e-01      -6.355256e-01      -7.359661e-01      -6.979548e-01      -1.004871e+00      -7.099711e-01              50%      -3.988059e-01      3.186508e-01      2.191719e-01      -2.702986e-01      -7.196453e-02      -2.771314e-01      2.134506e-01      -3.168558e-01      -2.189815e-01      -2.961142e-01      ...      6.798383e-02      -1.999376e-01      3.236947e-01      1.573233e-01      -1.819963e-01      3.273311e-02      1.208611e-01      -2.155373e-01      2.149392e-01      -1.179682e-01              75%      6.010351e-01      8.994444e-01      5.329562e-01      1.102648e+00      7.246279e-01      7.769495e-01      8.128134e-01      8.944433e-01      7.914156e-01      1.047349e+00      ...      6.942542e-01      6.930862e-01      8.373723e-01      8.655397e-01      3.657484e-01      7.911210e-01      7.965623e-01      2.228456e-01      6.929752e-01      1.075490e+00              max      2.370841e+00      1.631285e+00      2.129579e+00      2.053239e+00      2.192993e+00      2.759439e+00      1.856881e+00      2.525851e+00      2.386994e+00      1.970695e+00      ...      2.121844e+00      2.439377e+00      1.533337e+00      2.122636e+00      2.542459e+00      1.801157e+00      1.843039e+00      3.113057e+00      2.442046e+00      1.818189e+00      8 rows × 531 columns2. Data Visualization2.1. Stock Price Volatility%matplotlib inlinefig, ax1 = plt.subplots(figsize=(20, 15))df.iloc[:,:20].plot(ax=ax1, legend=False)plt.tight_layout()plt.show()df_delta = df.copy()for column in df_delta.columns.values.tolist():    df_delta[column] = df_delta[column]- df_delta[column].shift(1)df_delta.iloc[0]=0df_delta            symbol      A      AAL      AAP      AAPL      ABBV      ABC      ABMD      ABT      ACN      ADBE      ...      XEL      XLNX      XOM      XRAY      XYL      YUM      ZBH      ZBRA      ZION      ZTS              date                                                                                                                                                2019-01-02      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      ...      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000              2019-01-03      -0.132308      -0.278940      0.281110      -0.123113      -0.190242      -0.096013      -0.126329      -0.210193      -0.138905      -0.100851      ...      -0.029680      -0.171040      -0.072336      0.002954      -0.197347      -0.215205      -0.106702      -0.114809      -0.028157      -0.119316              2019-01-04      0.119732      0.228224      -0.230359      0.047508      0.179889      0.075565      0.183646      0.121119      0.152796      0.119270      ...      0.073418      0.202423      0.171038      0.162583      0.234564      0.217075      0.197830      0.074699      0.155477      0.130757              2019-01-07      0.075996      0.104891      0.132851      -0.002583      0.084121      0.047115      0.022400      0.065364      0.014180      0.034905      ...      -0.032803      0.120826      0.025013      0.103462      -0.085687      -0.009355      0.002306      0.028457      0.020812      0.020839              2019-01-08      0.053579      -0.061091      -0.063861      0.022071      0.027177      0.071120      0.059623      -0.053189      0.103600      0.038885      ...      0.087476      -0.089442      0.035154      -0.039906      0.053662      -0.016842      -0.134387      0.012757      0.047745      0.051895              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              2021-03-24      -0.063369      -0.053879      0.126777      -0.078644      -0.129928      0.148182      -0.072635      -0.164107      0.045411      -0.098804      ...      0.023227      -0.116853      0.087134      0.063104      0.063236      -0.089631      0.076719      0.014228      -0.074936      -0.025267              2021-03-25      0.058922      0.112443      0.225893      0.016050      0.059855      0.182449      -0.001153      0.068434      0.031668      -0.005913      ...      0.069681      0.003769      -0.012448      0.045150      0.073033      0.029227      0.025183      -0.031278      0.227436      -0.105625              2021-03-26      0.207894      0.018741      0.096235      0.019902      0.153287      0.128733      0.119576      0.200649      0.363291      0.205795      ...      0.051431      0.167471      0.119032      0.109865      0.252053      0.066249      0.215845      0.192574      0.145927      0.135448              2021-03-29      -0.012229      -0.002343      -0.130234      0.005778      0.054745      0.029636      0.071976      0.010631      -0.036747      0.002615      ...      0.114477      -0.049003      -0.024117      0.117390      -0.043642      0.112039      -0.065105      -0.121310      -0.257674      0.092785              2021-03-30      -0.032241      0.141726      0.058202      -0.047828      0.004379      0.000926      0.067694      -0.164771      -0.029578      -0.043888      ...      -0.164249      -0.103929      -0.055237      0.222739      0.054329      0.054558      0.059240      0.095183      0.265562      -0.055920      565 rows × 531 columns%matplotlib inlinefig, ax1 = plt.subplots(figsize=(20, 15))df_delta.plot(ax=ax1, legend=False)plt.tight_layout()plt.show()2.2. Rolling Average of Stock Price Correlationdef calculate_corr(df_stock_returns, returns_window, corr_window_size, corr_method):    stocks_cross_corr_dict = {}    x_days = []    y_mean_corr = []            for i in range(returns_window,len(df_stock_returns),corr_window_size):        dic_key = i        stocks_cross_corr_dict[dic_key]=df_stock_returns.iloc[i:(i+W)].corr(method='pearson')        stocks_cross_corr_dict[dic_key].fillna(0,inplace=True)        x_days.append(dic_key)        y_mean_corr.append(np.mean([abs(j) for j in stocks_cross_corr_dict[dic_key].values.flatten().tolist()]))            return stocks_cross_corr_dict, x_days,y_mean_corr%matplotlib inlinestart = 21end = 126step = 21;plt.figure(figsize=(20, 10))for t in range(start, end, step):    x_days = []    y_mean_corr = []    W = t    _, x_days, y_mean_corr = calculate_corr(df,1,W, 'pearson')    plt.plot(x_days, y_mean_corr)    plt.xlabel('Days')    plt.ylabel('Mean Correlation')    l = list(range(start, end, step))    plt.legend(l, loc='upper left')     plt.show()3. Network Analysis3.1. Build Graph with Correlation table# craetes a graph from correlation matrixcor_matrix = df.corr()cor_matrix            symbol      A      AAL      AAP      AAPL      ABBV      ABC      ABMD      ABT      ACN      ADBE      ...      XEL      XLNX      XOM      XRAY      XYL      YUM      ZBH      ZBRA      ZION      ZTS              symbol                                                                                                                                                A      1.000000      -0.512211      0.340607      0.936847      0.901146      0.866659      0.476208      0.932064      0.916575      0.876950      ...      0.581891      0.661159      -0.481706      0.276888      0.819616      0.232105      0.731162      0.947770      0.196208      0.830023              AAL      -0.512211      1.000000      0.452672      -0.709976      -0.567905      -0.636546      0.067317      -0.620271      -0.515571      -0.761706      ...      -0.685099      0.040970      0.950026      0.414638      -0.104279      0.401344      -0.116920      -0.402034      0.675397      -0.720983              AAP      0.340607      0.452672      1.000000      0.132583      0.218725      0.129889      0.598790      0.206132      0.304547      0.062110      ...      -0.102458      0.592191      0.471304      0.536131      0.517752      0.604171      0.464449      0.358634      0.691259      0.045798              AAPL      0.936847      -0.709976      0.132583      1.000000      0.883271      0.900174      0.311099      0.946722      0.931212      0.971310      ...      0.752885      0.464395      -0.694573      0.138280      0.700491      0.103699      0.668931      0.859869      -0.067884      0.937015              ABBV      0.901146      -0.567905      0.218725      0.883271      1.000000      0.842135      0.379425      0.820668      0.826314      0.834858      ...      0.525801      0.430849      -0.525965      0.167883      0.625416      0.017315      0.617159      0.868875      0.131018      0.756742              ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...      ...              YUM      0.232105      0.401344      0.604171      0.103699      0.017315      0.148166      0.135065      0.246568      0.391225      0.042001      ...      0.150926      0.517301      0.446745      0.791644      0.591224      1.000000      0.622313      0.311883      0.601129      0.211623              ZBH      0.731162      -0.116920      0.464449      0.668931      0.617159      0.647128      0.138407      0.709774      0.815626      0.581120      ...      0.583386      0.473123      -0.072924      0.677935      0.793259      0.622313      1.000000      0.754226      0.495103      0.715109              ZBRA      0.947770      -0.402034      0.358634      0.859869      0.868875      0.842147      0.398625      0.902315      0.895845      0.774380      ...      0.477856      0.635769      -0.332037      0.410140      0.824975      0.311883      0.754226      1.000000      0.353050      0.754373              ZION      0.196208      0.675397      0.691259      -0.067884      0.131018      0.003435      0.274263      0.036986      0.155021      -0.207014      ...      -0.314988      0.431878      0.711608      0.768845      0.486766      0.601129      0.495103      0.353050      1.000000      -0.148741              ZTS      0.830023      -0.720983      0.045798      0.937015      0.756742      0.869275      0.075617      0.902965      0.917018      0.930572      ...      0.901222      0.331572      -0.696158      0.206471      0.652798      0.211623      0.715109      0.754373      -0.148741      1.000000      531 rows × 531 columnsmat_pos = cor_matrix[cor_matrix&gt;=0]mat_pos = mat_pos.fillna(0)symbols = cor_matrix.index.valuesmat_pos = np.asmatrix(mat_pos)G_pos = nx.from_numpy_matrix(mat_pos)G_pos = nx.relabel_nodes(G_pos,lambda x: symbols[x])G_pos.remove_edges_from(nx.selfloop_edges(G_pos))mat_neg = cor_matrix[cor_matrix&lt;0]mat_neg = mat_neg.fillna(0)mat_neg = abs(mat_neg)symbols = cor_matrix.index.valuesmat_neg = np.asmatrix(mat_neg)G_neg = nx.from_numpy_matrix(mat_neg)G_neg = nx.relabel_nodes(G_neg,lambda x: symbols[x])G_neg.remove_edges_from(nx.selfloop_edges(G_neg))list(G_pos.edges(data=True))[:5], list(G_neg.edges(data=True))[:5]([('A', 'AAP', {'weight': 0.3406072572702165}),  ('A', 'AAPL', {'weight': 0.9368465656977406}),  ('A', 'ABBV', {'weight': 0.9011464914155253}),  ('A', 'ABC', {'weight': 0.8666593549791352}),  ('A', 'ABMD', {'weight': 0.476208419378593})], [('A', 'AAL', {'weight': 0.5122106576033231}),  ('A', 'AEP', {'weight': 0.010066159905771194}),  ('A', 'AFL', {'weight': 0.14527226301899576}),  ('A', 'AIG', {'weight': 0.21700976911380374}),  ('A', 'ALK', {'weight': 0.13546044591421322})])symbol =  df.columnsdf_sector = df_SP500[df_SP500['symbol'].isin(symbol)]df_sector = df_sector[[\"symbol\",\"sector\"]]tmp = pd.DataFrame({\"symbol\":df_indices[\"symbol\"].unique(), \"sector\":\"Macroeconomic Indices\"})df_sector = pd.concat([df_sector,tmp],ignore_index=True)df_sector['sec_idx']= 0for i,sec in enumerate(df_sector[\"sector\"].unique()):    df_sector.loc[df_sector['sector']==sec,'sec_idx'] = i+1df_sector                  symbol      sector      sec_idx                  0      AAPL      Information Technology      1              1      MSFT      Information Technology      1              2      AMZN      Consumer Discretionary      2              3      FB      Communication Services      3              4      GOOGL      Communication Services      3              ...      ...      ...      ...              526      GOLDAMGBD228NLBM      Macroeconomic Indices      12              527      IOER      Macroeconomic Indices      12              528      IORR      Macroeconomic Indices      12              529      THREEFY1      Macroeconomic Indices      12              530      THREEFY5      Macroeconomic Indices      12      531 rows × 3 columnsnx.set_node_attributes(G_pos, df_sector.set_index('symbol')['sec_idx'],'sec_idx')nx.set_node_attributes(G_neg, df_sector.set_index('symbol')['sec_idx'],'sec_idx')3.2. Setting threshold on weightsdef set_threshold(G,threshold):    edges_rm = list(filter(lambda e: abs(e[2]) &lt; threshold, (e for e in G.edges.data('weight'))))        ids_rm = list(e[:2] for e in edges_rm)    H = G.copy()    H.remove_edges_from(ids_rm)    return HH_pos = set_threshold(G_pos,0.5)H_neg = set_threshold(G_neg,0.5)list(H_pos.edges(data=True))[:5], list(H_neg.edges(data=True))[:5]([('A', 'AAPL', {'weight': 0.9368465656977406}),  ('A', 'ABBV', {'weight': 0.9011464914155253}),  ('A', 'ABC', {'weight': 0.8666593549791352}),  ('A', 'ABT', {'weight': 0.932064482315709}),  ('A', 'ACN', {'weight': 0.916574717968791})], [('A', 'AAL', {'weight': 0.5122106576033231}),  ('A', 'BA', {'weight': 0.5064885797862092}),  ('A', 'BXP', {'weight': 0.522527131570438}),  ('A', 'CCL', {'weight': 0.5559250497113872}),  ('A', 'DEXCAUS', {'weight': 0.6382900166453468})])3.3. Community Detection  with Louvain Algorithm# grid search# for positive weightsnp.random.seed(2021)t=0for cor_thresold in np.linspace(0.8,0.85,20):    H_pos = set_threshold(G_pos,cor_thresold)    partition = louvain.best_partition(H_pos)    modularity = louvain.modularity(partition, H_pos)    values = [partition.get(node) for node in H_pos.nodes()]    communities = []    tmp = list(partition.items())    for i in range(len(set(values))):        communities.append([n for n,c in tmp if c==i])    sum_comm_nodes = 0    k=0    print(\"{}th Total number of Communities = {}\".format(t ,len(communities)))    for i, comm_nodes in enumerate(communities):        if len(comm_nodes)&gt;=10:            k+=1            print('community {}th: '.format(i),len(comm_nodes))        sum_comm_nodes+=len(comm_nodes)    t+=1    print('n_big_communities: ',k)# best partition with 5 big communities at cor_threshold = np.linspace(0.8,0.85,20)[8] ...5th Total number of Communities = 36community 0th:  162community 1th:  188community 4th:  103community 6th:  35n_big_communities:  46th Total number of Communities = 36community 0th:  172community 1th:  180community 3th:  113community 4th:  25n_big_communities:  47th Total number of Communities = 36community 0th:  152community 3th:  112community 4th:  46community 6th:  180n_big_communities:  48th Total number of Communities = 41community 2th:  77community 4th:  107community 5th:  157community 7th:  37community 9th:  108n_big_communities:  59th Total number of Communities = 41community 0th:  153community 4th:  103community 6th:  43community 7th:  79community 9th:  108n_big_communities:  510th Total number of Communities = 41community 0th:  146community 2th:  84community 4th:  109community 6th:  41community 9th:  106n_big_communities:  511th Total number of Communities = 42community 0th:  145community 2th:  178community 4th:  126community 8th:  35n_big_communities:  4...np.random.seed(2021)cor_thresold = np.linspace(0.8,0.85,20)[8]H_pos = set_threshold(G_pos,cor_thresold)partition = louvain.best_partition(H_pos)values = [partition.get(node) for node in H_pos.nodes()]communities = []tmp = list(partition.items())for i in range(len(set(values))):    communities.append([n for n,c in tmp if c==i])sum_comm_nodes = 0k=0print(\"Total number of Communities = {}\".format(len(communities)))for i, comm_nodes in enumerate(communities):    if len(comm_nodes)&gt;=10:        k+=1        print('community {}th: '.format(i),len(comm_nodes))    sum_comm_nodes+=len(comm_nodes)print('n_big_communities: ',k)Total number of Communities = 41community 0th:  164community 2th:  79community 4th:  105community 7th:  30community 9th:  108n_big_communities:  5nx.set_node_attributes(H_pos,partition,'community')values = [partition.get(node) for node in H_pos.nodes()]plt.figure(figsize=(10,10))nx.draw_spring(H_pos, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)np.random.seed(2021)# for negative weightst=0for cor_thresold in np.linspace(0.6,0.65,20):    H_neg = set_threshold(G_neg,cor_thresold)    partition = louvain.best_partition(H_neg)    modularity = louvain.modularity(partition, H_neg)    values = [partition.get(node) for node in H_neg.nodes()]    communities = []    tmp = list(partition.items())    for i in range(len(set(values))):        communities.append([n for n,c in tmp if c==i])    sum_comm_nodes = 0    k=0        print(\"{}th Total number of Communities = {}\".format(t ,len(communities)))    for i, comm_nodes in enumerate(communities):        if len(comm_nodes)&gt;=10:            k+=1            print('community {}th: '.format(i),len(comm_nodes))        sum_comm_nodes+=len(comm_nodes)    t+=1    print('n_big_communities: ',k)# best partition with 5 big communities at cor_threshold = np.linspace(0.6,0.65,20)[11] ...9th Total number of Communities = 37community 0th:  104community 1th:  83community 2th:  177community 5th:  119community 6th:  16n_big_communities:  510th Total number of Communities = 40community 0th:  103community 1th:  83community 2th:  177community 3th:  14community 6th:  119n_big_communities:  511th Total number of Communities = 41community 0th:  104community 1th:  83community 2th:  176community 3th:  13community 6th:  119n_big_communities:  512th Total number of Communities = 42community 0th:  103community 1th:  81community 3th:  13community 6th:  130community 11th:  167n_big_communities:  513th Total number of Communities = 42community 0th:  106community 1th:  81community 2th:  176community 6th:  118community 7th:  13n_big_communities:  514th Total number of Communities = 43community 0th:  204community 1th:  165community 2th:  18community 5th:  105n_big_communities:  4...np.random.seed(2021)cor_thresold = np.linspace(0.6,0.65,20)[11] H_neg_otim = set_threshold(G_neg,cor_thresold)partition = louvain.best_partition(H_neg_otim)modularity = louvain.modularity(partition, H_neg)values = [partition.get(node) for node in H_neg.nodes()]communities = []tmp = list(partition.items())for i in range(len(set(values))):    communities.append([n for n,c in tmp if c==i])sum_comm_nodes = 0k=0print(\"Total number of Communities = {}\".format(len(communities)))for i, comm_nodes in enumerate(communities):    if len(comm_nodes)&gt;=10:        k+=1        print('community {}th: '.format(i),len(comm_nodes))    sum_comm_nodes+=len(comm_nodes)print('n_big_communities: ',k)Total number of Communities = 41community 0th:  102community 1th:  83community 3th:  13community 6th:  130community 11th:  167n_big_communities:  5nx.set_node_attributes(H_neg, partition,'community')values = [partition.get(node) for node in H_neg.nodes()]plt.figure(figsize=(10,10))nx.draw_spring(H_neg, cmap = plt.get_cmap('jet'), node_color = values, node_size=30, with_labels=False)3.4. Visualization with Gephinx.write_graphml(H_pos, \"model_H_pos.graphml\")nx.write_graphml(H_neg, \"model_H_neg.graphml\")",
        "url": "/stock_cluster"
    }
    ,
    
    "r-air-polution": {
        "title": "R - Air Pollution Data Analysis",
        "author": "Darron Kwon",
        "category": "",
        "content": "  1. About  2. Load Data and Preprocess          2.1. Set Attributes      2.2. Handling NA values        3. EDA          3.1. 통합대기환경지수(Comprehensive air-quality index), CAI 계산      3.2. Timestep-wise Visualization                  3.2.1. Hourly          3.2.2. Daily          3.2.3. Montly          3.2.4. Quarterly          3.2.5. Half-yearly                      4. Summary1. About  2020-2, Data Science and R, Final Proejct: Air Pollution Data Analysis2. Load Data and Preprocess  Collected data from Air Korea (https://www.airkorea.or.kr)library(dplyr)library(tidyverse)library(grid)library(vcd)library(ggplot2)library(readxl)data= read_xlsx(\"./final_data/data.xlsx\");head(data,5)nrow(data)\t\t날짜시도측정소명측정소코드아황산가스일산화탄소오존이산화질소PM10PM2.5\t\t\t2017-07-01 01인천 옹진군  백령도       831492       .0016        .3           .052         .0016        44           35           \t\t2017-07-01 02인천 옹진군  백령도       831492       .0016        .3           .052         .0017        21           NA           \t\t2017-07-01 03인천 옹진군  백령도       831492       .0017        .3           .051         .0017        32           18           \t\t2017-07-01 04인천 옹진군  백령도       831492       .0017        .3           .05          .002         10           NA           \t\t2017-07-01 05인천 옹진군  백령도       831492       .0016        .3           .048         .0018        24           22           \t\t263042.1. Set Attributes#   시도, 측정소명, 측정소코드는 모두 같으므로 제외#   날짜는 시구간별 분석을 위해 연, 월, 일, 시로 분리: int타입으로 반환됨#   측정 대상 오염 물질의 자료형 변환data &lt;- data %&gt;%  select(-c(시도,측정소명,측정소코드)) %&gt;%  separate(col=날짜,           into=c(\"year\",\"month\",\"day\",\"hour\"),           convert=TRUE) %&gt;%  mutate_if(is.character,as.numeric) %&gt;%  rename(SO2=아황산가스,CO=일산화탄소,O3=오존,NO2=이산화질소)head(data,5)\t\tyearmonthdayhourSO2COO3NO2PM10PM2.5\t\t\t2017  7     1     1     0.00160.3   0.052 0.001644    35    \t\t2017  7     1     2     0.00160.3   0.052 0.001721    NA    \t\t2017  7     1     3     0.00170.3   0.051 0.001732    18    \t\t2017  7     1     4     0.00170.3   0.050 0.002010    NA    \t\t2017  7     1     5     0.00160.3   0.048 0.001824    22    \t\t2.2. Handling NA values# 일평균 값을 확인daily &lt;- data %&gt;%  group_by(year,month,day) %&gt;%  select_if(is.double) %&gt;%  summarise_all(mean,na.rm=TRUE) %&gt;%  ungroup()summary(daily)      year          month             day             SO2            Min.   :2017   Min.   : 1.000   Min.   : 1.00   Min.   :0.0001765   1st Qu.:2018   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.:0.0012553   Median :2018   Median : 7.000   Median :16.00   Median :0.0017042   Mean   :2018   Mean   : 6.522   Mean   :15.73   Mean   :0.0018339   3rd Qu.:2019   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:0.0022417   Max.   :2020   Max.   :12.000   Max.   :31.00   Max.   :0.0078375                                                   NA's   :1                 CO                O3               NO2                PM10        Min.   :0.04583   Min.   :0.01188   Min.   :0.000850   Min.   :  2.00   1st Qu.:0.23750   1st Qu.:0.03453   1st Qu.:0.002373   1st Qu.: 20.88   Median :0.32917   Median :0.04290   Median :0.003296   Median : 29.25   Mean   :0.37287   Mean   :0.04405   Mean   :0.003853   Mean   : 35.58   3rd Qu.:0.46667   3rd Qu.:0.05192   3rd Qu.:0.004764   3rd Qu.: 42.54   Max.   :1.39167   Max.   :0.09971   Max.   :0.020209   Max.   :217.04   NA's   :2                                              NA's   :5            PM2.5         Min.   :  1.826   1st Qu.: 10.042   Median : 14.625   Mean   : 18.736   3rd Qu.: 22.375   Max.   :126.375   NA's   :23       # NA: 하루 전체 관측치가 NA인 경우에 발생# 월평균 값을 확인monthly &lt;- data %&gt;%  group_by(year,month) %&gt;%  select_if(is.double) %&gt;%  summarise_all(mean,na.rm=TRUE) %&gt;%  ungroup()summary(monthly)      year          month            SO2                 CO         Min.   :2017   Min.   : 1.00   Min.   :0.001099   Min.   :0.1911   1st Qu.:2018   1st Qu.: 3.75   1st Qu.:0.001394   1st Qu.:0.2646   Median :2018   Median : 6.50   Median :0.001789   Median :0.3562   Mean   :2018   Mean   : 6.50   Mean   :0.001832   Mean   :0.3730   3rd Qu.:2019   3rd Qu.: 9.25   3rd Qu.:0.002084   3rd Qu.:0.4491   Max.   :2020   Max.   :12.00   Max.   :0.003140   Max.   :0.7588         O3               NO2                PM10           PM2.5       Min.   :0.02447   Min.   :0.001857   Min.   :20.24   Min.   :10.62   1st Qu.:0.03821   1st Qu.:0.002876   1st Qu.:27.31   1st Qu.:13.94   Median :0.04175   Median :0.004066   Median :35.42   Median :18.41   Mean   :0.04410   Mean   :0.003850   Mean   :35.69   Mean   :18.92   3rd Qu.:0.05154   3rd Qu.:0.004658   3rd Qu.:42.46   3rd Qu.:22.84   Max.   :0.06422   Max.   :0.005683   Max.   :58.00   Max.   :36.51  # NA값들을 일평균 또는 월평균 값으로 대체for (i in (1:nrow(data))){  for (j in c(\"SO2\",\"CO\",\"O3\",\"NO2\",\"PM10\",\"PM2.5\")){    if (is.na(data[i,][[j]])){      tmp&lt;-data[i,]      y&lt;-tmp$year      m&lt;-tmp$month      d&lt;-tmp$day      if (!is.nan(daily[daily$year==y &amp; daily$month==m &amp; daily$day==d,][[j]])){        data[i,][[j]]&lt;-daily[daily$year==y &amp; daily$month==m &amp; daily$day==d,][[j]]      }else{        data[i,][[j]]&lt;-monthly[monthly$year==y &amp; monthly$month==m,][[j]]      }    }  }}summary(data)      year          month             day             hour       Min.   :2017   Min.   : 1.000   Min.   : 1.00   Min.   : 1.00   1st Qu.:2018   1st Qu.: 4.000   1st Qu.: 8.00   1st Qu.: 6.75   Median :2018   Median : 7.000   Median :16.00   Median :12.50   Mean   :2018   Mean   : 6.522   Mean   :15.73   Mean   :12.50   3rd Qu.:2019   3rd Qu.:10.000   3rd Qu.:23.00   3rd Qu.:18.25   Max.   :2020   Max.   :12.000   Max.   :31.00   Max.   :24.00        SO2                 CO               O3               NO2           Min.   :0.000000   Min.   :0.0000   Min.   :0.00100   Min.   :0.000300   1st Qu.:0.001200   1st Qu.:0.2000   1st Qu.:0.03400   1st Qu.:0.002100   Median :0.001700   Median :0.3000   Median :0.04300   Median :0.003000   Mean   :0.001834   Mean   :0.3726   Mean   :0.04405   Mean   :0.003853   3rd Qu.:0.002300   3rd Qu.:0.5000   3rd Qu.:0.05200   3rd Qu.:0.004600   Max.   :0.034700   Max.   :2.5000   Max.   :0.13200   Max.   :0.045900        PM10            PM2.5        Min.   :  1.00   Min.   :  0.00   1st Qu.: 19.00   1st Qu.:  9.00   Median : 28.00   Median : 14.00   Mean   : 35.57   Mean   : 18.78   3rd Qu.: 43.00   3rd Qu.: 22.77   Max.   :461.00   Max.   :219.00  3. EDA3.1. 통합대기환경지수(Comprehensive air-quality index), CAI 계산### 통합대기환경지수CAI 지수를 계산# 항목별 계산 함수를 정의SO2_I_p &lt;- function(C_p){  cut &lt;- c(-Inf,0,0.02,0.05,0.15,1,Inf)  BP_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0.02,0.02,0.05,0.15,1,1))))  BP_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,0.021,0.051,0.151,0.151))))  I_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(50,50,100,250,500,500))))  I_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,51,101,251,251))))  I_p &lt;- (((I_hi-I_lo)/(BP_hi-BP_lo)) * (C_p - BP_lo)) + I_lo  return(I_p)}CO_I_p &lt;- function(C_p){  cut &lt;- c(-Inf,0,2,9,15,50,Inf)  BP_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(2,2,9,15,50,50))))  BP_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,2.01,9.01,15.01,15.01))))  I_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(50,50,100,250,500,500))))  I_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,51,101,251,251))))  I_p &lt;- (I_hi-I_lo)/(BP_hi-BP_lo) * (C_p - BP_lo) + I_lo  return(I_p)}O3_I_p &lt;- function(C_p){  cut &lt;- c(-Inf,0,0.03,0.09,0.15,0.6,Inf)  BP_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0.03,0.03,0.09,0.15,0.6,0.6))))  BP_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,0.031,0.091,0.151,0.151))))  I_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(50,50,100,250,500,500))))  I_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,51,101,251,251))))  I_p &lt;- (I_hi-I_lo)/(BP_hi-BP_lo) * (C_p - BP_lo) + I_lo  return(I_p)}NO2_I_p &lt;- function(C_p){  cut &lt;- c(-Inf,0,0.03,0.06,0.2,2,Inf)  BP_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0.03,0.03,0.06,0.2,2,2))))  BP_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,0.031,0.061,0.201,0.201))))  I_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(50,50,100,250,500,500))))  I_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,51,101,251,251))))  I_p &lt;- (I_hi-I_lo)/(BP_hi-BP_lo) * (C_p - BP_lo) + I_lo  return(I_p)}# PM10, PM2.5의 이동평균을 구하기 위한 함수 정의C12_cal &lt;- function(PM){  C12 &lt;- c()  for (i in (1:length(PM))){    if (i&lt;12){      tmp &lt;- sum(PM[1:i])/i    }else{      tmp &lt;- sum(PM[(i-11):i])/12    }    C12[i] &lt;- tmp  }  return (C12)}C_ai_cal &lt;- function(C_i,M,C12){  if (C_i &lt; M){    C_ai &lt;- C_i  }else if(0.9&lt;= (C_i/C12) &amp;&amp; (C_i/C12) &lt;=1.7){    C_ai &lt;- 0.75*C_i    }else {    C_ai &lt;- C_i  }  return (C_ai)}PM_cal &lt;- function(PM,m,PM_C12){  M=m  C24E=c()  for (i in (1:length(PM))){    if (i&lt;4){      C4 &lt;-0      for (j in (i:1)){        C4 &lt;- C4+ C_ai_cal(PM[j],M,PM_C12[j])      }      C4/i    } else{      C4 &lt;- sum(C_ai_cal(PM[i],M,PM_C12[i]),C_ai_cal(PM[i-1],M,PM_C12[i-1]),              C_ai_cal(PM[i-2],M,PM_C12[i-2]),C_ai_cal(PM[i-3],M,PM_C12[i-3]))/4    }    C12&lt;-PM_C12[i]    C24E[i] = (C12*12+C4*12)/24  }  return (C24E)}PM10_I_p &lt;- function(C_p){  cut &lt;- c(-Inf,0,30,80,150,600,Inf)  BP_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE,                                       labels=c(30,30,80,150,600,600))))  BP_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE,                                       labels=c(0,0,31,81,151,151))))  I_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE,                                      labels=c(50,50,100,250,500,500))))  I_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE,                                      labels=c(0,0,51,101,251,251))))  I_p &lt;- (I_hi-I_lo)/(BP_hi-BP_lo) * (C_p - BP_lo) + I_lo  return(I_p)}PM2.5_I_p &lt;- function(C_p){  cut &lt;- c(-Inf,0,15,35,75,500,Inf)  BP_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(15,15,35,75,500,500))))  BP_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,16,36,76,76))))  I_hi &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(50,50,100,250,500,500))))  I_lo &lt;- as.numeric(as.character(cut(C_p, breaks=cut,right=TRUE,                include.lowest = FALSE, labels=c(0,0,51,101,251,251))))  I_p &lt;- (I_hi-I_lo)/(BP_hi-BP_lo) * (C_p - BP_lo) + I_lo  return(I_p)}PM10_C12&lt;-C12_cal(data$PM10)PM10_C_p &lt;- PM_cal(data$PM10,70,PM10_C12)PM2.5_C12 &lt;- C12_cal(data$PM2.5)PM2.5_C_p &lt;- PM_cal(data$PM2.5,30,PM2.5_C12)data &lt;- data %&gt;%  bind_cols(\"SO2_I_p\" = SO2_I_p(data$SO2)) %&gt;%  bind_cols(\"CO_I_p\" = CO_I_p(data$CO)) %&gt;%  bind_cols(\"O3_I_p\" = O3_I_p(data$O3)) %&gt;%  bind_cols(\"NO2_I_p\" = NO2_I_p(data$NO2)) %&gt;%  bind_cols(\"PM10_I_p\" = PM10_I_p(PM10_C_p)) %&gt;%  bind_cols(\"PM2.5_I_p\" = PM2.5_I_p(PM2.5_C_p))CAI_table &lt;- data %&gt;%  select(ends_with(\"I_p\")) %&gt;%  mutate(BAD = rowSums(. &gt;100)) %&gt;%  mutate(CAI = apply(., 1, max) + case_when(BAD&gt;=3 ~ 75, BAD&gt;=2 ~ 50,TRUE ~ 0)) %&gt;%  mutate(CAI_index = case_when(CAI&gt;250 ~ 3, CAI&gt;100 ~ 2,                               CAI&gt;50 ~ 1, TRUE ~ 0)) %&gt;%  select(starts_with(\"CAI\"))data &lt;- data %&gt;%  bind_cols(CAI_table)head(data[c(11:18)],5)\t\tSO2_I_pCO_I_pO3_I_pNO2_I_pPM10_I_pPM2.5_I_pCAICAI_index\t\t\t4.00     7.5      68.44068 2.666667 64.00000  88.71711 88.717111        \t\t4.00     7.5      68.44068 2.833333 68.75000 103.38782103.387822        \t\t4.25     7.5      67.61017 2.833333 84.66667 131.82942131.829422        \t\t4.25     7.5      66.77966 3.333333 44.58333  66.44682 66.779661        \t\t4.00     7.5      65.11864 3.000000 39.95833  64.79737 65.118641        \t\t3.2. Timestep-wise Visualization  시구간별 시각화 및 분석3.2.1. Hourly# 시간대(주간: 07~18, 야간: 19~06)에 따른 CAI 지수 분포CAI_hourly &lt;- data %&gt;%  mutate(time_tmp = case_when(    06&lt;hour &amp; hour&lt;19 ~ \"daytime\", TRUE ~ \"nighttime\")) %&gt;%  group_by(year,month,day,time_tmp) %&gt;%  summarise(mean_CAI=mean(CAI)) %&gt;%  mutate(CAI_idx = case_when(mean_CAI&gt;250 ~ 3, mean_CAI&gt;100 ~ 2,                             mean_CAI&gt;50 ~ 1, TRUE ~ 0)) %&gt;% # 해당 시간대의 평균 오염도  ungroup()# 시간에 따른 오염도의 분포는 거의 차이가 없음을 확인CAI_hourly %&gt;%  group_by(time_tmp,CAI_idx)%&gt;%  tally()`summarise()` has grouped output by 'year', 'month', 'day'. You can override using the `.groups` argument.\t\ttime_tmpCAI_idxn\t\t\tdaytime  0        100      \t\tdaytime  1        886      \t\tdaytime  2         93      \t\tdaytime  3         17      \t\tnighttime0         73      \t\tnighttime1        895      \t\tnighttime2        115      \t\tnighttime3         13      \t\t3.2.2. Daily### 일단위: 일평균 CAI 지수의 분포CAI_daily &lt;- data %&gt;%  group_by(year,month,day) %&gt;%  summarise_at(.vars=\"CAI\", .funs=mean) %&gt;%  ungroup() %&gt;%  mutate(CAI_idx = case_when(CAI&gt;250 ~ 3, CAI&gt;100 ~ 2,                             CAI&gt;50 ~ 1, TRUE ~ 0))summary(factor(CAI_daily$CAI_idx))# 평균 수준보다 오염도가 높은 날들은 연중 특정 시기에 집중되어있음CAI_daily %&gt;%  unite(\"date\",1:3,sep=\"/\") %&gt;%  mutate_at(\"date\",as.Date) %&gt;%  ggplot() +  geom_point(mapping=aes(x=date,y=CAI))3.2.3. Montly### 월단위: 오염 수준 나쁨 이상인 \"일수\" 확인CAI_monthly &lt;- CAI_daily %&gt;%  group_by(year,month) %&gt;%  summarise(mean_CAI = mean(CAI),sum_CAI_idx = sum(CAI_idx&gt;1)) %&gt;%  mutate(m_tmp = case_when(month&lt;10 ~ paste(\"0\",as.character(month),sep=\"\"),                           TRUE ~ paste(as.character(month))))%&gt;%  mutate(y_tmp=as.character(year)) %&gt;%  unite(date,y_tmp,m_tmp,sep=\"\")# 6월~9월은 장마 영향으로 추정. 겨울~봄에 집중적.CAI_monthly %&gt;%  ggplot() +  geom_col(mapping=aes(x=date,y=sum_CAI_idx))`summarise()` has grouped output by 'year'. You can override using the `.groups` argument.3.2.4. Quarterly### 분기 단위CAI_qtr &lt;- CAI_monthly %&gt;%  mutate(qtr_tmp = case_when(    month &lt; 4 ~ \"Q1\", month &lt; 7 ~ \"Q2\", month &lt; 10 ~ \"Q3\", TRUE ~ \"Q4\")) %&gt;%  mutate(y_tmp=as.character(year)) %&gt;%  unite(Qtr, y_tmp, qtr_tmp, sep=\"-\") %&gt;%  group_by(Qtr) %&gt;%  summarise(mean_CAI = mean(mean_CAI), sum_CAI_idx = sum(sum_CAI_idx))CAI_qtr %&gt;%  ggplot() +  geom_col(aes(x=Qtr,y=sum_CAI_idx))3.2.5. Half-yearly### 반기 단위: 2019년 상반기가 매우 심한 것이었음을 알 수 있음CAI_half &lt;- CAI_monthly %&gt;%  transform(date=as.integer(date)) %&gt;%  mutate(year = case_when(    date &lt; 201801 ~ \"2017_H2\", date &lt; 201807 ~ \"2018-H1\",    date &lt; 201901 ~ \"2018_H2\", date &lt; 201907 ~ \"2019-H1\",    date &lt; 202001 ~ \"2019-H2\", TRUE ~ \"2020-H1\")) %&gt;%  group_by(year) %&gt;%  summarise(mean_CAI = mean(mean_CAI), sum_CAI_idx = sum(sum_CAI_idx))CAI_half %&gt;%  ggplot()+  geom_col(aes(x=year,y=sum_CAI_idx))4. Summary대기오염도는 대체적으로 여름보다 겨울에 높았고, 2019년이 특히 심했다는 것을 알 수 있다. 2020년을 기준으로 비교했을 때, 코로나의 영향은 거의 없었던 것으로 추정된다.",
        "url": "/R_air_polution"
    }
    ,
    
    "nlp-korean-rnn": {
        "title": "NLP - Korean Language Text Analysis with RNN",
        "author": "Darron Kwon",
        "category": "",
        "content": "  1. Data Load  2. Preprocessing          2.1. Remove duplicates      2.2. Regexp on Korean Language        3. Tokenizing with konlpy-Okt  4. Train-test Data  5. LSTM Model# 한국어 자료import sysimport osimport numpy as npimport nltkimport konlpyimport pandas as pdimport reimport randomimport itertoolsimport warningswarnings.filterwarnings(action='ignore')from sklearn.metrics import classification_report,f1_score,precision_score,recall_scorerandom.seed(1)1. Data Loadtrain_data=pd.read_csv('final_train_data.csv')test_data=pd.read_csv('final_test_data.csv')# 384 duplicates in content, 240 in titleprint(train_data.describe())       category                                            content  titlecount     10686                                              10686  10686unique        7                                              10302  10124top        정치개혁  개인회생 36개월 단축소급 전국 적용을 위해 춘천지방법원의 법원에 바란다에 글을 올...   경남제약freq       3094                                                 16     212. Preprocessing2.1. Remove duplicatestrain_data = train_data.drop_duplicates(['content'],keep='first')train_data.duplicated().sum()0all duplicates removedtrain_data['document']=train_data.iloc[:,1]+train_data.iloc[:,2]train_data['document']test_data['document']=test_data.iloc[:,1]+test_data.iloc[:,2]2.2. Regexp on Korean Languagetrain_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")3. Tokenizing with konlpy-Okt# tokenizefrom konlpy.tag import Oktokt = Okt() #형태소 분석기tokenized_data = []stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']for sentence in train_data['document']:    temp_X = okt.morphs(sentence, norm=True, stem=True) # 형태소 추출    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거    tokenized_data.append(temp_X)x_train=tokenized_dataokt = Okt() #형태소 분석기tokenized_data = []stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']for sentence in test_data['document']:    temp_X = okt.morphs(sentence, norm=True, stem=True) # 형태소 추출 - 토큰화 #norm=True : 근사어    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 제거 #https://www.ranks.nl/stopwords/korean    tokenized_data.append(temp_X)x_test=tokenized_data  save and re-import processed dataimport picklewith open('nlp_final_x_tr.data', 'wb') as f:    pickle.dump(x_train, f)with open('nlp_final_x_te.data', 'wb') as f:    pickle.dump(x_test, f)import picklewith open('nlp_final_x_tr.data', 'rb') as f:    x_train = pickle.load(f)with open('nlp_final_x_te.data', 'rb') as f:    x_test = pickle.load(f)from tensorflow.keras.preprocessing.text import Tokenizertokenizer = Tokenizer()tokenizer.fit_on_texts(x_train)threshold = 3total_cnt = len(tokenizer.word_index) # 단어의 수rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.for key, value in tokenizer.word_counts.items():    total_freq = total_freq + value    # 단어의 등장 빈도수가 threshold보다 작으면    if(value &lt; threshold):        rare_cnt = rare_cnt + 1        rare_freq = rare_freq + valueprint('단어 집합(vocabulary)의 크기 :',total_cnt)print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)단어 집합(vocabulary)의 크기 : 34537등장 빈도가 2번 이하인 희귀 단어의 수: 15483단어 집합에서 희귀 단어의 비율: 44.830182123519705전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.1132793250941202vocab_size = total_cnt - rare_cnt + 1 # 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거. 0번 패딩 토큰을 고려하여 +1print('단어 집합의 크기 :',vocab_size)단어 집합의 크기 : 19055tokenizer = Tokenizer(vocab_size) tokenizer.fit_on_texts(x_train)X_train = tokenizer.texts_to_sequences(x_train)X_test = tokenizer.texts_to_sequences(x_test)y_train=np.array(train_data.category)y_test=np.array(test_data.category)drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) &lt; 1]drop_test = [index for index, sentence in enumerate(X_test) if len(sentence) &lt; 1]X_train = np.delete(X_train, drop_train, axis=0)y_train = np.delete(y_train, drop_train, axis=0)print(len(X_train))print(len(y_train))1030110301X_test = np.delete(X_test, drop_test, axis=0)y_test = np.delete(y_test, drop_test, axis=0)print(len(X_train))print(len(X_test))print(len(y_train))print(len(y_test))103011158103011158import matplotlib.pyplot as pltprint('리뷰의 최대 길이 :',max(len(l) for l in X_train))print('리뷰의 평균 길이 :',sum(map(len, X_train))/len(X_train))plt.hist([len(s) for s in X_train], bins=50)plt.xlabel('length of samples')plt.ylabel('number of samples')plt.show()리뷰의 최대 길이 : 9032리뷰의 평균 길이 : 170.45791670711583def below_threshold_len(max_len, nested_list):  cnt = 0  for s in nested_list:    if(len(s) &lt;= max_len):        cnt = cnt + 1  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))*100))max_len = 600below_threshold_len(max_len, X_train)전체 샘플 중 길이가 600 이하인 샘플의 비율: 96.02951169789341from tensorflow.keras.preprocessing.sequence import pad_sequencesX_train = pad_sequences(X_train, maxlen = max_len)X_test = pad_sequences(X_test, maxlen = max_len)y_train=np.array(train_data.category)y_test=np.array(test_data.category)y_train = np.delete(y_train, drop_train, axis=0)y_test = np.delete(y_test, drop_test, axis=0)print(len(y_train),len(y_test))10301 11584. Train-test Datat={'경제민주화': 1, '교통/건축/국토': 2, '보건복지': 3, '육아/교육': 4, '인권/성평등': 5, '일자리': 6, '정치개혁': 7}print(t['보건복지'])index1=np.zeros([10301,7])for i in range(len(y_train)):  index1[i][t[y_train[i]]-1]=1y_train=index1index1=np.zeros([1158,7])for i in range(len(y_test)):  index1[i][t[y_test[i]]-1]=1y_test=index1print(y_train.shape,y_test.shape)3(10301, 7) (1158, 7)X_train=np.array(X_train)X_test=np.array(X_test)y_train=np.array(y_train)y_test=np.array(y_test)print(X_train.shape)print(X_test.shape)print(y_train.shape)print(y_test.shape)print(vocab_size)(10301, 600)(1158, 600)(10301, 7)(1158, 7)190555. LSTM Modelfrom tensorflow.keras.layers import Embedding, Dense, LSTMfrom tensorflow.keras.models import Sequentialfrom tensorflow.keras.models import load_modelfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpointimport tensorflow_addons as tfaf1 = tfa.metrics.F1Score(num_classes=7,threshold=0.5)from tensorflow import keraskeras.__version__# '2.6.0'model = Sequential()model.add(Embedding(vocab_size, 128))model.add(LSTM(128))model.add(Dense(7, activation='sigmoid'))es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=4)mc = ModelCheckpoint('best_model.h5', monitor=f1, mode='max', verbose=2, save_best_only=True)model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc',f1])model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=512, validation_split=0.2)Epoch 1/1517/17 [==============================] - 39s 2s/step - loss: 1.8842 - acc: 0.2830 - f1_score: 0.2583 - val_loss: 1.7326 - val_acc: 0.3081 - val_f1_score: 0.2726WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 2/1517/17 [==============================] - 38s 2s/step - loss: 1.6177 - acc: 0.4615 - f1_score: 0.3981 - val_loss: 1.5555 - val_acc: 0.4639 - val_f1_score: 0.3776WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 3/1517/17 [==============================] - 38s 2s/step - loss: 1.3590 - acc: 0.5495 - f1_score: 0.4018 - val_loss: 1.3879 - val_acc: 0.5075 - val_f1_score: 0.4232WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 4/1517/17 [==============================] - 38s 2s/step - loss: 1.1364 - acc: 0.6211 - f1_score: 0.4351 - val_loss: 1.3140 - val_acc: 0.5303 - val_f1_score: 0.4173WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 5/1517/17 [==============================] - 38s 2s/step - loss: 0.9084 - acc: 0.7212 - f1_score: 0.4893 - val_loss: 1.1852 - val_acc: 0.6487 - val_f1_score: 0.4386WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 6/1517/17 [==============================] - 38s 2s/step - loss: 0.7336 - acc: 0.7920 - f1_score: 0.5183 - val_loss: 1.1071 - val_acc: 0.6473 - val_f1_score: 0.4536WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 7/1517/17 [==============================] - 39s 2s/step - loss: 0.5796 - acc: 0.8381 - f1_score: 0.5395 - val_loss: 1.0900 - val_acc: 0.6458 - val_f1_score: 0.4837WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 8/1517/17 [==============================] - 38s 2s/step - loss: 0.4641 - acc: 0.8757 - f1_score: 0.5575 - val_loss: 0.9854 - val_acc: 0.6982 - val_f1_score: 0.4781WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 9/1517/17 [==============================] - 38s 2s/step - loss: 0.3588 - acc: 0.9039 - f1_score: 0.5759 - val_loss: 1.2205 - val_acc: 0.6458 - val_f1_score: 0.4993WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 10/1517/17 [==============================] - 38s 2s/step - loss: 0.3082 - acc: 0.9181 - f1_score: 0.5908 - val_loss: 1.0990 - val_acc: 0.6870 - val_f1_score: 0.5031WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 11/1517/17 [==============================] - 39s 2s/step - loss: 0.2331 - acc: 0.9408 - f1_score: 0.6076 - val_loss: 1.8883 - val_acc: 0.5793 - val_f1_score: 0.4935WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 12/1517/17 [==============================] - 39s 2s/step - loss: 0.2625 - acc: 0.9380 - f1_score: 0.6111 - val_loss: 1.3714 - val_acc: 0.6642 - val_f1_score: 0.5215WARNING:tensorflow:Can save best model only with &lt;tensorflow_addons.metrics.f_scores.F1Score object at 0x7f1bd3f444f0&gt; available, skipping.Epoch 00012: early stopping&lt;keras.callbacks.History at 0x7f1bf1402a60&gt;# evaluating function: report f1_macrodef evaluate(test_x,test_y,model):    predictions=model.predict(test_x)    y_pred=max(predictions)    print(classification_report(test_y,y_pred))model.evaluate(X_test, y_test)37/37 [==============================] - 6s 149ms/step - loss: 1.1846 - acc: 0.6986 - f1_score: 0.5419[1.1846439838409424, 0.6986182928085327, array([0.5124555 , 0.59907836, 0.48712873, 0.45633796, 0.5854922 ,        0.4855967 , 0.6674057 ], dtype=float32)]# from saved best modelloaded_model = load_model('best_model.h5')loaded_model.evaluate(X_test, y_test)",
        "url": "/NLP_korean_RNN"
    }
    ,
    
    "islr-ch10": {
        "title": "ISLR - Chapter 10. Deep Learning",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 10. Deep Learning  10.1. Single Layer Neural Networks  10.2. Multilayer Neural Networks  10.3. Convolutional Neural Networks          10.3.1. Convolution Layers      10.3.2. Pooling Layers      10.3.3. Architecture of a Convolutional Neural Network      10.3.4. Data Augmentation        10.4. Document Classification  10.5. Recurrent Neural Networks          10.5.1. Sequential Models for Document Classification      10.5.2. Time Series Forecasting                  RNN forecaster          Autoregression                    10.5.3. Summary of RNNs        10.6. When to Use Deep Learning  10.7. Fitting a Neural Network          10.7.1. Backpropagation      10.7.2. Regularization and Stochastic Gradient Descent      10.7.3. Dropout Learning      10.7.4. Network Tuning        10.8. Interpolation and Double DescentChapter 10. Deep Learning10.1. Single Layer Neural Networks      A neural network takes input vector of p variables \\(X=(X_1,X_2,\\ldots,X_p)\\) and builds a nonlinear function $f(X)$ to predict the response Y. What distinguishes neural networks from these methods is the particular structure of the model.        E.g. a simple feed-forward neural network:\\(\\begin{align*}f(X)&amp;= \\beta_0 + \\sum_{k=1}^K\\beta_k h_k(X) \\\\  &amp;= \\beta_0 + \\sum_{k=1}^K\\beta_k g(w_{k0}+\\sum_{j=1}^p w_{kj}X_j).\\end{align*}\\)In the terminology, the features \\(X_1,\\ldots,X_4\\) make up the units in the input layer. Each of the inputs from the input lyaer feed into each of the K hidden units. In two steps; First the K activations $A_k$ in the hidden layer are computed as functions of the input features $X_1,\\ldots,X_p$,\\(A_k = h_k(X) = g(w_{k0}+\\sum_{j=1}^p w_{kj}X_j)\\),where \\(g(z)\\) is a nonlinear activation function that is specified in advance. We can think of each \\(A_k\\) as a different transformation \\(h_k(X)\\) of the original features, like basis functions of Chapter 7. These K activations then feed into the output layer, resulting in\\(f(X) = \\beta_0 + \\sum_{k=1}^K \\beta_k A_k\\),a linear regression model. All the parameters $\\beta_0,\\ldots,\\beta_K$ and $w_{10},\\ldots,w_{Kp}$ need to be estimated from data.        With deriving K new features by computing K different linear combinations of X, the model squashes each through an activation function $g(\\cdot)$ to transform it. The final model is linear in these derived variables.    Activation functions          sigmoid activation function:  \\(g(z)=\\frac{e^z}{1+e^z}=\\frac{1}{1+e^{-z}}\\)  which is the same function used in logistic regression to convert a linear function into probabilities between zero and one.      ReLU(rectified linear unit) activation function:  \\(g(z) = (z)_{+} = \\begin{cases}0, &amp; \\mbox{if }z&lt;0 \\\\                              z, &amp; \\mbox{othersize}.\\end{cases}\\)  can be computed and stored more efficiently than a sigmoid function. Although it thresholds at zero, because we apply it to a linear function the constant term \\(w_{k0}\\) will shift this inflection point.            The nonlinearity in the activation function \\(g(\\cdot)\\) is essential, since without it the model would collapse into a simple linear model. Moreoever, having a nonlinear activation function allows the model to capture complex nonlinearities and interaction effects.    Fitting a neural network requires estimating the unknown parameters. For a quantitative response, typically squared-error loss is used, so that the parameters are chosen to minimize \\(\\sum_{i=1}^n(y_i-f(x_i))^2\\).10.2. Multilayer Neural Networks      With H multiple hidden layers,the first hidden layer is\\(\\begin{align*}A_k^{(1)} &amp;= h_k^{(1)}(X) \\\\        &amp;= g(w_{k0}^{(1)}+\\sum_{j=1}^p w_{kj}^{(1)}X_j)\\end{align*}\\)for \\(k=1,\\ldots,K_1\\).The hth hidden layer treats the activations \\(A_k^{(h-1)}\\) as inputs and computes new activations\\(\\begin{align*}A_{k'}^{(h)} &amp;= h_{k'}^{(h)}(X) \\\\        &amp;= g(w_{k'0}^{(h)}+\\sum_{k'=1}^{K_1} w_{hk'}^{(h)}A_k^{(h-1)})\\end{align*}\\)for \\(k'=1,\\ldots,K_h\\). Each \\(A_{k'}^{(h)} = h_{k'}^{(h)}(X)\\) is a function of input vector X. Thus, through a chain of transformations, the network is able to build up fairly complex transformations of X that ultimately feed into the output layer as features.        The notation \\(\\mathbf{W}_h\\) represents the entire matrix of weights that feed from the hidden layer $L_{h-1}$ to $L_h$. Each element $A_k^{(h-1)}$ feeds to the hidden layer $L_h$ via the matrix of weights \\(\\mathbf{W}_h\\).        On the output layer in the classification case, compute M different linear models similar to our single model to get separate quantitative responses for each classes. To represent class probabilities \\(f_m(X)=Pr(Y=m|X)\\), we use the softmax activation function\\(f_m(X)=Pr(Y=m|X)=\\frac{e^{Z_m}}{\\sum_{l=0}^{M-1} e^{Z_l}}\\).The classifier assigns the image to the class with the highest probability.        To train this network, since the response is qualitative, we look for coefficient estimates that minimize the negative multinomial log-likelihood\\(-\\sum_{i=1}^n\\sum_{m=0}^{M-1}y_{im}\\log(f_m(x_i))\\),known as the cross-entropy, a generalization of the criterion for two-class logistic regression. If the response were quantitative, we would instead minimize squared-error loss as before.  10.3. Convolutional Neural Networks10.3.1. Convolution Layers      A convolution layer is made up of a large number of convolution filters, each of which is a template that determines whether a particular local feature is present in an image. A very simple operation, called a convolution amounts to repeatedly multiplying matrix elements and then adding the results. Resulting convolved image highlights regions of the original image that resemble the convolution filter.        In a convolution layer, we use a whole bank of filters to pick out a variety of differently-oriented edges and shapes in the image. Using predefined filters in this way is standard practice in image processing. By contrast, we can think of the filter weights as the parameters going from an input layer to a hidden layer. Thus, with CNNs the filters are learned for the specific classification task.  10.3.2. Pooling Layers  A pooling layer provides a way to condense a large image into a smaller summary image. The max pooling operation summarizes each non-overlapping block of pixels in an image using the maximum value in the block. This reduces the size of the image and also provides some location invariance.10.3.3. Architecture of a Convolutional Neural Network  Convolve-then-pool sequence:Start with the three-dimensional feature map of a color image, consist of three $n\\times n$ two-dimensional feature map of pixels.Each convolve layer takes as input the three-dimensional feature map from the previous layer and treats it like a single multi-channel image. Each convolution filter learned has as many channels as this feature map.Since the channel feature maps are reduced in size after each pool layer, we usually increase the number of filters in the next convolve layer to compensate.Sometimes we repeat several convolve layers before a pool layer. This effectively increases the dimension of the filter.These operations are repeated until the pooling has reduced each channel feature map down to just a few pixels in each dimension.Then the three-dimensional feature maps are flattened; the pixels are treated as separate units, and fed into one or more fully-connected layers before reaching the output layer, which is a softmax activation for the classification.10.3.4. Data Augmentation      Each training image is replicated many times, with each replicate randomly distorted in a natural way such that human recognition is unaffected. Typical distortions are zoom, horizontal and vertical shift, shear, small rotations, and horizontal flips. This is a way of increasing the training set considerably with somewhat different examples, and thus protects against overfitting.        We can see this as a form of regularization: we build a cloud of images around each original image, all with the same label. This kind of fattening of the data is similar in spirit to ridge regularization.  10.4. Document Classification      For the two-class response of the sentiment of the text data, which will be positive or negative. Each document can be a different length, include slang or non-words, have spelling errors, etc. We need to find a way to featurize such a document.        The simplest featurization is BOW, bog-of-words model. With dictionary containing M words, we create a binary feature vector of length M for each document, scoring 1 for presence, and 0 otherwise. The resulting training feature matrix X is a sparse matrix, most of the values are the same(to zero); it can be stored efficiently in sparse matrix format. Then we can build a neural network model with the feature matrix as input layers.        The bag-of-words model summarizes a document by the words present, and ignores their context. There are at least two popular ways to take the context into account:          The bag-of-n-grams model recording the consecutive co-occurrence of every distinct set of words.      Treat the document as a sequence, taking account of all the words in the context of those that preceded and those that follow.      10.5. Recurrent Neural Networks      In a recurrent neural network (RNN), the input object X is a sequence. Considering a corpus of documents, each document can be represented as a sequence of L words, so \\(X=\\left\\{ X_1,X_2,\\ldots,X_L\\right\\}\\). RNNs are designed to capture the sequential nature of such(text) input objects like CNNs for the spatial structure of image inputs. The output Y can also be a sequence (such as in language translation), but often is a scalar, like the binary sentiment label of a movie review document.        The structure of a very basic RNN; with a sequence \\(X=\\left\\{ X_1,X_2,\\ldots,X_L\\right\\}\\), a simple output Y, and a hidden-layer sequence \\(\\left\\{ A_l \\right\\}_1^L =\\left\\{ A_1,A_2,\\ldots,A_L\\right\\}\\). Each \\(X_l\\) is a vector representation for the $l$th word.Suppose it has p components \\(X_l^T = (X_{l1},X_{l2},\\ldots,X_{lp})\\), and hidden layer consists of K units \\(A_l^T = (A_{l1},\\ldots,A_{lK})\\). We represent the collection of \\(K \\times (p+1)\\) shared weights $w_{kj}$ for the input layer by a matrix W, and similarly U is a \\(K \\times K\\) matrix of the weights $u_{ks}$ for the hidden-to hideen layers, and B is a K+1 vector of weights $\\beta_k$ for the output layer.Then \\(A_{lk}=g(w_{k0}+\\sum_{j=1}^p w_{kj}X_{lj} + \\sum_{s=1}^K u_{ks} A_{l-1,s})\\), and the output \\(O_l = \\beta_0 + \\sum_{k=1}^K\\beta_k A_{lk}\\) for a quantitative response, for example. Here $g(\\cdot)$ is an activation function such as ReLU. Note that the same weights W, U, and B are not functions of $l$. This is a form of weights sharing used by RNNs, similar to the use of filters in CNNs.Proceeded from beginning to end, the activations $A_l$ accumulate a history of what has been seen before, so that the learned context can be used for prediction.        For regression problems the loss function is $(Y-O_L)^2$, which only references the final output \\(O_L = \\beta_0 + \\sum_{k=1}^K\\beta_k A_{Lk}\\) and others before are not used. With n input sequence/response pairs, the parameters are found by minimizing the sum of squares \\(\\sum_{i=1}^n(y_i-o_{iL})^2\\).  10.5.1. Sequential Models for Document Classification      Beacuse of the dimensionality problem of bag-of-words model(one-hot-encoded vector), we use lower-dimensional embedding space instead. Rather than representing each word by a binary vector with zeros and a single one in some position, we will represent it by a set of m real numbers, none of which are typically zero.        The embedding layer E comes from the optimization part of a neural network, or we can use a weight freezing, inserting a precomputed matrix E in the embedding layer. The idea is that the positions of words in the embedding space preserve semantic meaning: synonyms should appear near each other.        The next step is to limit each document to the last L words. Documents that are shorter get padded with zeros upfront. So now each document is represented by a series consisting of L vectors, and each $X_l$ in the sequence has m components.        Then we run the process of simple RNN as presented before, with B has 2(K+1) for two-class logistic regression. If the embedding layer E is learned, that adds an additional $m \\times D$ parameters, and is by far the biggest cost.        More elaborate versions use long term and short term memory (LSTM). However, LSTM models take a long time to train, which makes exploring many architectures and parameter optimization tedious.  10.5.2. Time Series Forecasting      In an example of Stock price predition, one feature of stock market data is that the day-to-day observations are not independent of each other. The series exhibit auto-correlation; values nearby in time tend to be similar to each other.        Consider pairs of observations $(v_t,v_{t-l})$, a lag of $l$ days apart. If we take all such pairs in the $v_t$ series and compute their correlation coefficient, this gives the autocorrelation at lag $l$.        Another interesting characteristic of this forecasting problem is that the response variable $v_t$; log_volume is also a predictor. We will use the past values of log_volume to predict values in the future.  RNN forecaster      We wish to predict a value $v_t$ from past values $v_{t-1},v_{t-2},\\ldots$ and also to make use of past values of the other series $r_{t-1},r_{t-2},\\ldots$ and $z_{t-1},z_{t-2},\\ldots$.        Idea: to extract many short mini-series of input sequences with a predefined length L(lag), and a corresponding target Y.\\(X_1= \\begin{pmatrix} v_{t-L}\\\\ r_{t-L}\\\\ z_{t-L} \\end{pmatrix}, X_2= \\begin{pmatrix} v_{t-L+1}\\\\ r_{t-L+1}\\\\ z_{t-L+1} \\end{pmatrix}, \\cdots, X_L= \\begin{pmatrix} v_{t-1}\\\\ r_{t-1}\\\\ z_{t-1} \\end{pmatrix}\\), and \\(Y=v_t\\).Here the target Y is the value of response at a single timepoint t, and the input sequence X is the series of 3-vectors \\(\\left\\{X_l\\right\\}_1^L\\) consisting of measurements from day t-L, t-L+1, up to t-1. Each value of t makes a separate pair (X,Y). Then we run RNN model for prediction.  Autoregression      The RNN we just fit has much in common with a traditional autoregression(AR) linear model. Constructed a response vector y and a matrix M of predictors for least squares regression:\\(\\mathbf{y}=\\begin{bmatrix} v_{L+1}\\\\ v_{L+2}\\\\ \\vdots\\\\ v_T \\end{bmatrix}\\), \\(\\mathbf{M}=\\begin{bmatrix} 1 &amp; v_L &amp; v_{L-1} &amp; \\cdots &amp; v_1 \\\\                           1 &amp; v_{L+1} &amp; v_{L} &amp; \\cdots &amp; v_2 \\\\                           \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\                           1 &amp; v_{T-1} &amp; v_{T-2} &amp; \\cdots &amp; v_{T-L}           \\end{bmatrix}\\)each have T-L rows, one per observation. The predictors for any given reponse $v_t$ on day t are the previous L values of the same series. Fitting a regression of y on M amounts to fitting the model\\(\\hat{y}_t = \\hat\\beta_0 + \\hat\\beta_1 v_{t-1} + \\hat\\beta_2 v_{t-2} + \\cdots +               \\hat\\beta_L v_{t-L}\\),and is called an order-L autoregressive model, or simplay AR(L).    The RNN processes data sequence from left to right with the same weights W, while the AR model simply treats all L elements of the sequence equally as a vector of $L \\times p$ predictors; a process called flattening in the neural network. Of course the RNN also includes the hidden layer activations which transfer information along the sequence, and introduces additional nonlinearity with much more parameters.    10.5.3. Summary of RNNs    There are many variations and enhancements of the simple RNN for sequence modeling. One approach uses a onedimensional convolutional neural network, treating the sequence of vectors as an image. One can also have additional hidden layers; multi-layer RNN. Alternative bidirectional RNNs scan the sequences in both directions. In language translation the target is also a sequence of words, in a language different from that of the input sequence. Both the input sequence and the target sequence share the hidden units, so-called Seq2Seq learning.10.6. When to Use Deep Learning      Should we discard all our older tools, and use deep learning on every problem with data? We follow Occam’s razor principle: when faced with several methods that give roughly equivalent performance, pick the simplest.        Typically we expect deep learning to be an attractive choice when the sample size of the training set is extremely large, and when interpretability of the model is not a high priority.  10.7. Fitting a Neural Network      In simple network, the parameters are \\(\\beta = (\\beta_0,\\beta_1,\\ldots,\\beta_K)\\), each of the \\(w_k=(w_{k0},w_{k1},\\ldots,w_{kp})\\) for k in K. Given observations ($x_i,y_i$) for i in n, we fit the model by solving a nonlinear least squares problem\\(\\begin{align*}\\text{min}_{\\left\\{ w_k \\right\\}_1^K, \\beta }\\frac{1}{2}\\sum_{i=1}^n(y_i-f(x_i))^2,\\end{align*}\\)where \\(f(x_i)=\\beta_0+\\sum_{k=1}^K\\beta_k g(w_{k0}+\\sum_{j=1}^p w_{kj}x_{ij})\\).        The minimization objective is quite simple, but because of the nested arrangement of the parameters and the symmetry of the hidden units, it is not straightforward to minimize. The problem is nonconvex in the parameters, and hence there are multiple solutions. To overcome some of these issues and to protect from overfitting, two general strategies are employed when fitting neural networks: Slow learning and Regularization.        Suppose we represent all the parameters in one long vecter \\(\\theta\\). Then we can rewrite the objective as\\(R(\\theta)=\\frac{1}{2}\\sum_{i=1}^n(y_i-f_{\\theta}(x_i))^2\\), where we make explicit the dependence of f on the parameters. The idea of gradient descent is          Start with a guess \\(\\theta^0\\) for all the parameters in \\(\\theta\\), and set \\(t=0\\).      Iterate until the objective fails to decrease:  (a) Find a vector \\(\\delta\\) reflects a small change in \\(\\theta\\), such that \\(\\theta^{t+1} = \\theta^t + \\delta\\) reduces the objective; i.e. such that \\(R(\\theta^{t+1})&lt;R(\\theta^t)\\).  (b) Set \\(t \\leftarrow t+1\\).      10.7.1. Backpropagation      How do we find the directions to move \\(\\theta\\) so as to decrease the objective? The gradient of $R(\\theta)$, evaluated at some current value \\(\\theta=\\theta^m\\), is the vector of partial derivatives at that point:\\(\\begin{align*}\\triangledown R(\\theta^m) = \\frac{\\partial R(\\theta)}{\\partial\\theta}|_{\\theta=\\theta^m}\\end{align*}\\).The subscript \\(\\theta=\\theta^m\\) means that after computing the vector of derivatives, we evaluate it at the current guess, \\(\\theta^m\\). This gives the direction in $\\theta$-space in which $R(\\theta)$ increases most rapidly. The idea of gradient descent is to move $\\theta$ a little in the opposite direction(since we wish to go downhill):\\(\\theta^{m+1}\\leftarrow\\theta^m - \\rho\\triangledown R(\\theta^m)\\).For a small enough value of the learning rate $\\rho$, this step will decrease the objective $R(\\theta)$; i.e. $R(\\theta^{m+1})\\le R(\\theta^m)$. If the gradient vector is zero, then we may have arrived at a minimum of the objective.        Calculation: the chain rule of differentiation  10.7.2. Regularization and Stochastic Gradient Descent      stochastic gradient descent(SGD):When n is large, instead of calculating over all n observations, we can sample a small fraction or minibatch of them each time we compute a gradient step.        Regularization:E.g. Ridge regularization on the weights, augmenting the objective function with a penalty term on classification problem:\\(R(\\theta;\\lambda)=-\\sum_{i=1}^n\\sum_{m=0}^{M-1}y_{im}\\log(f_m(x_i))                  +\\lambda\\sum_j\\theta_j^2\\).With $\\lambda$ as preset at a small value or found using the validation-set approach. We can also use different values of $\\lambda$ for the groups of weights from different layers. Lasso is also a popular alternative.  10.7.3. Dropout Learning  Efficient form of regularization, similar in some respects to ridge regularization. The idea is to randomly remove a fraction of the units in a layer when fitting the model, separately each time a training observation is processed. This prevents nodes from becoming over-specialized, and can be seen as a form of regularization.10.7.4. Network Tuning  Choices that all have an effect on the performance:  The number of hidden layers, and the number of units per layer.  Regularization tuning parameters.  Details of stochastic gradient descent.10.8. Interpolation and Double Descent      In certain specific settings it can be possible for a statistical learning method that interpolates the training data to perform well; or at least, better than a slightly less complex model that does not quite interpolate the data. The phenomenon is known as double descent, where the test error has a U-shape before the interpolation threshold is reached, and then it descends again (for a while, at least) as an increasingly flexible model is fit. The double-descent phenomenon does not contradict the bias-variance trade-off.        It has been used by the machine learning community to explain the successful practice of using an overparametrized neural network (many layers, and many hidden units), and then fitting all the way to zero training error. However, zero error fit is not always optimal, we typically do not want to rely on this behavior.  ",
        "url": "/islr_ch10"
    }
    ,
    
    "islr-ch9": {
        "title": "ISLR - Chapter 9. Support Vector Machines",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 9. Support Vector Machines  9.1. Maximal Margin Classifier          9.1.1. What Is a Hyperplane?      9.1.2. Classification Using a Separating Hyperplane      9.1.3. The Maximal Margin Classifier      9.1.4. Construction of the Maximal Margin Classifier      9.1.5. The Non-separable Case        9.2. Support Vector Classifiers          9.2.1. Overview of the Support Vector Classifier      9.2.2. Details of the Support Vector Classifier        9.3. Support Vector Machines          9.3.1. Classification with Non-Linear Decision Boundaries      9.3.2. The Support Vector Machine        9.4. SVMs with More than Two Classes          9.4.1. One-Versus-One Classification        9.5. Relationship to Logistic RegressionChapter 9. Support Vector Machines9.1. Maximal Margin Classifier9.1.1. What Is a Hyperplane?  a hyperplane is a flat affine subspace of dimemsion p-1, in a p-dimemsional space.The mathematical definition: \\(\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p = 0\\) A hyperplane can be referred as decision boundary, means that a point \\(X=(X_1,X_2,\\ldots,X_p)^T\\) in p-dimemsional space satisfies the equation, then X lies on the hyperplane. Rather, any point $X&gt;0$ or $X&lt;0$ lies to the both side of the hyperplane.9.1.2. Classification Using a Separating Hyperplane      Suppose that $n\\times p$ data matrix X that consists of n training observations in p-dimemsional space, $x_i = (x_{i1},x_{i2},\\ldots,x_{ip})^T$ falls into two classes, $y_i\\in { -1,1 }$. A test observation is a p-vector of observed features \\(x^* = (x_1^* \\cdots x_p^*)^T\\).        Separating Hyperplane  \\(f(x_i) =   \\begin{cases}  \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip} &gt; 0 &amp; \\mbox{if }y_i = 1,\\\\  \\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip} &lt; 0 &amp; \\mbox{if }y_i = -1.  \\end{cases}\\)  Equivalently, it has the property that  \\(y_i f(x_i) = y_i(\\beta_0 + \\beta_1 x_{i1} + \\cdots + \\beta_p x_{ip}) &gt; 0\\)  Classify the test observation \\(x*\\) based on the sign of  \\(f(x^*) = \\beta_0 + \\beta_1 x_1^* + \\beta_2 x_2^* + \\cdots + \\beta_p x_p^*\\).  if \\(f(x^*)\\) is positive, assign the test observation to class 1 and if \\(f(x^*)\\) is negative, then assign it to class -1.        Magnitude of \\(f(x^*)\\)  if \\(f(x^*)\\) is far from zero, it means that \\(x^*\\) lies far from the hyperplane, and so we can be confident about our class assignment for it.  9.1.3. The Maximal Margin Classifier      Separating hyperplanes have no unique solution, there are infinite number of $\\beta$. The maximal margin hyperplane (or optimal separating hyperplane) is the separating hyperplane that is farthest from the training observations.    A margin is the smallest perpendicular distance from the observations to the hyperplane and the maximal margin hyperplane is the separating hyperplane for which the margin is largest. Then we classify a test observation based on which side of the maximal margin hyperplane it lies, is the maximal margin classifier. The observations equidistant from the maximal margin hyperplane are the support vectors.    9.1.4. Construction of the Maximal Margin Classifier        The maximal margin hyperplane is the solution to the optimization problem:  \\(\\text{max}_{\\beta_0,\\beta_1,\\ldots,\\beta_p,M}M\\) subject to \\(\\sum_{j=1}^p\\beta_j^2=1,\\)  \\(y_i(\\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2}+\\cdots+\\beta_p x_{ip})\\ge M\\) \\(\\forall i=1,\\cdots,n.\\)  where the constraint $\\beta^T\\beta=1$ means that it is the unique solution of \\(\\beta\\), the perpendicular distance.    E.g. in 2-dimemsion space:  a hyperplane $\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 = 0$,  the distance \\(M = \\frac{|\\beta_0+\\beta_1 X_1+\\beta_2 X_2|}{\\sqrt{\\beta_1^2+\\beta_2^2}}\\)  with the constraint $\\beta^T\\beta=1$,  \\(M = |\\beta_0+\\beta_1 X_1+\\beta_2 X_2|\\), that is,  \\(y_i(\\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2})&gt;0\\).9.1.5. The Non-separable Case  The maximal margin classifier is a very natural way to perform classification, if a separating hyperplane exists. In cases no separating hyperplane exists, there is no maximal margin classifier and the optimization problem has no solution with $M&gt;0$.9.2. Support Vector Classifiers9.2.1. Overview of the Support Vector Classifier      A classifier based on a separating hyperplane will perfectly classify all of the training observations, can lead to overfit; sensitivity to individual observations. Thus, we consider a classifier based on a hyperplane that does not perfectly separate the two classes, in the interest of greater robustness and better classification.        The support vector classifier, or a soft margin classifier:Rather than seeking the largest possible margin with every observation is on the correct side of the hyperplane or margin, we allow some violations; observations to be on the incorrect side of the hyperplane or margin.  9.2.2. Details of the Support Vector Classifier      The support vector classifier is the solution to the optimization problem:\\(\\begin{align*}\\text{max}_{\\beta_0,\\beta_1,\\ldots,\\beta_p,\\epsilon_1,\\ldots,\\epsilon_n,M}M\\end{align*}\\) subject to \\(\\sum_{j=1}^p\\beta_j^2=1,\\)\\(y_i(\\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2}+\\cdots+\\beta_p x_{ip})\\ge M(1-\\epsilon_i)\\), \\(\\epsilon_i\\ge 0\\), \\(\\sum_{i=1}^n\\epsilon_i\\le C\\),where C is a nonnegative tuning parameter and M is the width of the maximizing margin. $\\epsilon$ are the slack variables that allow individual observations to be on the wrong side. Then we classify a test observation \\(x^*\\) based on the sign of \\(f(x^*)=\\beta_0 + \\beta_1 x_1^* + \\cdots + \\beta_p x_p^*\\).        The slack variable $\\epsilon_i$:If $\\epsilon_i=0$ then the ith observation is on the correct side of the margin and if $\\epsilon_i&gt;0$ then he ith observation is on the wrong side of the margin; we say that the ith observation has violated the margin. If $\\epsilon_i&gt;1$ then it is on the wrong side of the hyperplane.        The tuning parameter C:It bounds the sum of the $\\epsilon_i$’s, determines the number and severity of the violations to the margin(and hyperplane) that we will tolerate. It can be referred as a budget for the amount that the margin can be violated by the n observations. For $C&gt;0$ no more than C observations can be on the wrong side of the hyperplane. As C increases, the model will become more robust and the margin will widen. In practice, C is chosen via cross-validation and it controls the bias-variance trade-off.        The support vectors, only observations that either lie on the margin or that violate the margin will affect the hyperplane and the classifier. In other words, an observation that lies strictly on the correct side of the margin does not affect the support vector classifier. Changing the position of that (correct) observation would not change the classifier at all. The fact that only support vectors affect the classifier is in line with our previous assertion that C controls the bias-variance trade-off of the support vector classifier.        Since the support vector classifier’s decision rule is based only on a potentially small subset of the training observations, it is quite robust to the behavior of observations that are far away from the hyperplane.  9.3. Support Vector Machines9.3.1. Classification with Non-Linear Decision Boundaries  The support vector classifier is for the setting that the decision boundary between the two classes is linear. In non-linear cases, we consider enlarging the feature space using functions of the predictors, such as quadratic and cubic terms.9.3.2. The Support Vector Machine      The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space in a specific way, using kernels.        The linear support vector classifier can be represented as:\\(f(x) = \\beta_0+\\sum_{i=1}^n\\alpha_i\\left\\langle x,x_i \\right\\rangle\\),where there are n parameters $\\alpha_i$, one per training observation. To estimate the parameters $\\alpha_i$ and $\\beta_0$, all we need are the \\({n choose 2}\\) inner products \\(\\left\\langle x,x_i \\right\\rangle\\) between all pairs of training observations.        In order to evaluate the function $f(x)$, we need to compute the inner product between the new point $x$ and each of the training points $x_i$. However, it turns out that $\\alpha_i$ is nonzero only for the support vectors in the solution; that is, if a training observation is not a support vector, then its $\\alpha_i$ equals zero. So if S is the collection of indices of these support points, we can rewrite as:\\(f(x) = \\beta_0+\\sum_{i\\in\\mathcal{S}}\\alpha_i\\left\\langle x,x_i \\right\\rangle\\). To summarize, in representing the linear classifier $f(x)$, and in computing its coefficients, all we need are inner products.        Now we replace the inner product with a generalization of the form \\(K(x_i,x_{i'})\\), where K is some function referred as a kernel, quantifies the similarity of two observations. When the support vector classifier is combined with a non-linear kernel, with the function of polynomial or radial, the resulting classifier is known as a support vector machine. The function has the form:\\(f(x) = \\beta_0+\\sum_{i\\in\\mathcal{S}}\\alpha_i K(x,x_i)\\)        The advantage of using a kernelRather than simply enlarging the feature space using functions of the original features, one advantage is computational, and it amounts to the fact that using kernels, one need only compute kernel function for all $n(n-1)/2$ distinct pairs $i,i’$. This can be done without explicitly working in the enlarged feature space, so large that computations are intractable. For some kernels, the feature space is implicit and infinite-dimensional, the computations are impossible.  9.4. SVMs with More than Two Classes9.4.1. One-Versus-One Classification      An alternative procedure for applying SVMs. Fit K SVMs, each time comparing one of the K classes to the remaining K−1 classes.        Let \\(\\beta_{0k},\\beta_{1k},\\ldots,\\beta_{pk}\\) denote the parameters that result from fitting an SVM comparing the kth class(coded as +1) to the others (coded as −1)        For a test observation \\(x^*\\), assign it to the class for which \\(\\beta_{0k}+\\beta_{1k}x_1^*+\\ldots+\\beta_{pk}x_p^*\\) is largest, as this amounts to a high level of confidence that the test observation belongs to the kth class rather than to any of the other classes.  9.5. Relationship to Logistic Regression      Rewrite the criterion for fitting the support vector classifier as\\(\\text{min}_{\\beta_0,\\beta_1,\\ldots,\\beta_p}\\left\\{\\sum_{i=1}^n\\text{max}\\left[0, 1- y_i f(x_i) \\right] + \\lambda\\sum_{j=1}^p\\beta_j^2 \\right\\}\\),where $\\lambda$ is a nonnegative tuning parameter. When $\\lambda$ is large then the coefficients $\\beta_j$’s are small, more violations to the margin are tolerated, and a low-variance but high-bias classifier will result. Thus, a small value of $\\lambda$ amounts to a small value of C in support vector classifier. Note that \\(\\lambda\\sum_{j=1}^p\\beta_j^2\\) term is the ridge penalty, plays a similar role in controlling the bias-variance trade-off for the support vector classifier.        Now taktes the “Loss + Penalty” form:\\(\\text{min}_{\\beta_0,\\beta_1,\\ldots,\\beta_p}\\left\\{L(\\mathbf{X},\\mathbf{y},\\beta)+\\lambda P(\\beta)\\right\\}\\).Left side term is some loss function quantifying the extent to which the model, parametrized by $\\beta$, fits the data (X,y). Right side term is a penalty function on the parameter vector $\\beta$ whose effect is controlled by a nonnegative tuning parameter $\\lambda$. For support vector machine, the loss function takes the form:\\(L(\\mathbf{X},\\mathbf{y},\\beta)=\\sum_{i=1}^n\\text{max}\\left[0,1- y_i(\\beta_0+\\beta_1 x_{i1}+\\cdots+\\beta_p x_{ip})\\right]\\).This is known as hinge loss. It turns out that the hinge loss function is closely related to the loss function used in logistic regression.        The only support vectors play a role in the classifier obtained; observations on the correct side of the margin do not affect it. This is due to the fact that the hinge loss function is exactly zero for observations for which \\(y_i(\\beta_0+\\beta_1 x_{i1}+\\cdots+\\beta_p x_{ip})\\ge 1\\), the observations that are on the correct side of the margin. In contrast, the loss function for logistic regression is not exactly zero anywhere. But it is very small for observations that are far from the decision boundary. Due to the similarities between two loss functions, they often give very similar results. When the classes are well separated, SVMs tend to behave better than logistic regression; in more overlapping regimes, logistic regression is often preferred.        The tuning parameter C was first thought to be an unimportant “nuisance” parameter that could be set to some default value, like 1. However, the “Loss + Penalty” formulation indicates that this is not the case. Now we see that $\\lambda$ or C, determines the extent to which the model underfits or overfits the data.  ",
        "url": "/islr_ch9"
    }
    ,
    
    "islr-ch8": {
        "title": "ISLR - Chapter 8. Tree-Based Methods",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 8. Tree-Based Methods  8.1. The Basics of Decision Trees          8.1.1. Regression Trees                  Prediction via Stratification of the Feature Space          Tree Pruning                    8.1.2. Classification Trees      8.1.3. Trees Versus Linear Models                  8.1.4. Advantages and Disadvantages of Trees                      8.2. Bagging, Random Forests, Boosting, and Bayesian Additive Regression Trees          8.2.1. Bagging                  Out-of-Bag Error Estimation          Variable Importance Measures                    8.2.2. Random Forests                  Permutation Importance                    8.2.3. Boosting      8.2.4. Bayesian Additive Regression Trees      8.2.5. Summary of Tree Ensemble Methods      Chapter 8. Tree-Based Methods      Background  Tree by binary question, splitting variables with split points.  Partitions of input space &amp; fit a constant to each one.  $X = (X_1,\\ldots,X_p)$ to $R_1,\\ldots,R_M$ regions, p-dimension rectangles.  where \\(R_m\\cap R_{m'}, m\\ne m', \\bigcup_{m=1}^M R_m = \\mathbb{X}.\\)        Model:  \\(f(X)=\\sum_{m=1}^M C_m I(X\\in R_m)\\)  where $C_m$ is a constant for each region m.  8.1. The Basics of Decision Trees8.1.1. Regression TreesPrediction via Stratification of the Feature Space  Two steps of building a regression tree:          Divide the predictor space; the set of possible values for $X_1, \\ldots, X_p$  into J distinct and non-overlapping regions; $R_1, \\ldots, R_J$.      For every observations that falls into the region $R_j$, we make the same  prediction, which is simply the mean of the response values for the training  observations in $R_j$.            To divide the predictor space into high-dimensional rectangles, or boxes, our goal   is to find the boxes that minimize the RSS, given by:  \\(\\sum_{j=1}^J\\sum_{i\\in R_j}(y_i-\\hat{y}_{R_j})^2\\)  where $\\hat{y}_{R_j}$ is the mean response for the training observations within   the jth box.  I.e., the Least Squares Criterion in given regions:  \\(\\begin{align*}  \\text{min}_{C_m}\\sum_{i=1}^N RSS &amp;= \\text{min}_{C_m}\\sum_{i=1}^N(y_i-f(x_i))^2 \\\\      &amp;= \\text{min}_{C_m}\\sum_{i=1}^N\\left[y_i - \\sum_{m=1}^M C_m I(x_i\\in R_m) \\right]^2 \\\\  \\rightarrow \\hat{C}_m &amp;= \\text{ave}(y_i|x_i\\in R_m) = \\bar{y}_m  \\end{align*}\\)        How to split into spaces?  For its computational infeasibility, we take a top-down, greedy approach that   it known as recursive binary splitting. To perform recursive binary splitting,   we first select the predictor $X_j$ and the cutpoint s such that splitting the   predictor spaace in to the regions \\(\\{X|X_j&lt;s\\}\\) and \\(\\{X|X_j\\ge s\\}\\) leads to   the greatest possible reduction in RSS.        For splitting variable $X_j$ and split point s,  In two binary partitions \\(R_1(j,s) = \\{X|X_j&lt;s\\}\\) and \\(R_2(j,s) = \\{X|X_j\\ge s\\}\\),  \\(\\text{min} \\left[ \\sum_{i:x_i\\in R_1(j,s)}(y_i-\\hat{y}_{R_1})^2 + \\sum_{i:x_i\\in R_2(j,s)}(y_i-\\hat{y}_{R_2})^2 \\right]\\), or  \\(\\text{min}_{C_1}\\sum_{i:x_i\\in R_1(j,s)}(y_i-C_1)^2 + \\min_{C_2}\\sum_{i:x_i\\in R_2(j,s)}(y_i-C_2)^2\\).  \\(\\begin{align*}  \\rightarrow &amp; \\text{ave}(y_i|x_i\\in R_1(j,s)) = \\hat{C}_1 = \\hat{y}_{R_1} \\\\              &amp; \\text{ave}(y_i|x_i\\in R_2(j,s)) = \\hat{C}_2 = \\hat{y}_{R_2}  \\end{align*}\\)    We repeat this process over the two previously identified regions, looking for the   best predictor and best cutpoint in order to split the data further so as the minimize   the RSS within each of the resulting regions. The process continues until a stopping   criterion is reached; for instance, until no region contains more than five observations.Tree Pruning      Tree size is based on the number of regions(M) and the model complexity is on the  number of parameters($C_m$). Since there is an extremely large number of possible   subtrees, estimating the CV error for every possible subtree would be too cumbersome.   Instead, to find the optimal M, we use Cost-Complexity Pruning, reducing from a   very large tree $T_0$ to a subtree that has the lowest test error rate.        For each value of a nonnegative tuning parameter $\\alpha$ there corresponds a subtree   $T\\in T_0$, such that minimizing  \\(\\sum_{m=1}^{|T|}\\sum_{i:x_i\\in R_m}(y_i-\\hat{y}_{R_m})^2 + \\alpha|T|\\).  Here |T| indicates the number of terminal nodes of the tree T, $R_m$ is the   rectangle, or the subset of predictor space corresponding to the mth terminal node,   and $\\hat{y}_{R_m} = \\hat{C}_m$ is the predicted response, the mean of the training   observations in $R_m$. When $\\alpha=0$, then the subtree T will simply equal $T_0$.   As $\\alpha$ increases, there is a price to pay for having a tree with many terminal   nodes, and so the quantity will tend to be minimized for a smaller subtree.        Algorithm          Use recursive binary splitting to grow a large tree, stopping only when each  terminal node has fewer than some minimum number of observations, threshold.      Apply cost complexity pruning to obtain a sequence of best subtrees, as a function  of $\\alpha$.      Use K-fold CV to choose $\\alpha$: (a) Repeat Steps 1 and 2 on all but kth fold of the training data. (b) Evaluate the mean squared prediction error on the data in the left-out kth  fold, as a function of $\\alpha$. Average the results for each value of $\\alpha$, and pick a $\\alpha$ to minimize  the average error.      Return the subtree from Step 2 that corresponds to the chosen value of $\\alpha$.      8.1.2. Classification Trees      Instead of the mean response of the training observations that belong to the same   terminal node, a classification tree predict that each observation in the region   to the most commonly occurring class of training observations in the region to   which it belongs. In interpreting the result, we are often interested not only in   the class prediction, but also in the class proportions among the training observations   that fall into that region.        A natural alternative to RSS, the classification error rate; the fraction of the   training observations in that region that do not belong to the most common class:  \\(E=1-\\text{max}_k(\\hat{p}_{mk})\\), where \\(\\hat{p}_{mk} = \\frac{1}{N_m}\\sum_{x_i\\in R_m}I(y_i=k)\\),  represents the proportion of training observations in the mth region that are from   the kth class. By majority vote rule, \\(k(m) = \\text{argmax}_k \\hat{p}_mk\\).    However, the classification error is not sufficiently sensitive for tree-growing,   in practice we use two other measures preferable.          Gini index:  \\(G=\\sum_{k=1}^K\\hat{p}_{mk}(1-\\hat{p}_{mk})\\),  a measure of total variance across the K classes. It is often referred to as   a measure of node purity; a small value indicates that a node contains predominantly   observations from a single class.      Cross-entropy or deviance:  \\(D=-\\sum_{k=1}^K\\hat{p}_{mk}\\log\\hat{p}_{mk}\\),  a nonnegative value that take on a small value if the mth node is pure.  these measures are typically used to evaluate the quality of a particular split,   since they are more sensitive to node purity than is the classification error rate.   The classification error rate is preferable if prediction accuracy of the final   pruned tree is the goal.        Being performed to increase node purity, some of the splits yield two terminal nodes   that have the same predicted value. Even though such splits do not reduce the classification   error, it improves the Gini index and the entropy.8.1.3. Trees Versus Linear Models      Linear regression model is:  \\(f(X) = \\beta_0 + \\sum_{j=1}^p X_j\\beta_j\\),  whereas Regression tree model is:  \\(f(X) = \\sum_{m=1}^M c_m\\cdot 1_{(X\\in R_m)}\\)        If there is a highly non-linear and complex relationship between the features and   the response, then decision trees may outperform classical approaches. Also, trees   may be preffered for the sake of interpretability and visualization.  8.1.4. Advantages and Disadvantages of Trees  Pros          Good interpretability and easy to explain.      Closely mirror human decision-making than do some of the regression and classification   approaches.      Can be displayed graphically, and are easily interpreted even by a non-expert.      Can easily handle qualitative predictors without the need to create dummy variables.        Cons          Do not have the same level of predictive accuracy as the regression and classification   approaches.      Non-robust, a small change in the data can cause a large change in the final   estimated tree(High variance).      Lack of smoothness, can be far from the true function.      By aggregating many decision trees, the predictive performance of trees can be \tsubstantially improved.8.2. Bagging, Random Forests, Boosting, and Bayesian Additive Regression Trees  An ensemble method is an approach that combines many simple “building ensemble block”   models in order to obtain a single and potentially very powerful model. These simple   building block models are sometimes known as weak learners, since they may lead   to mediocre predictions on their own.8.2.1. Bagging      Bootstrap aggregation, or bagging, is a general-purpose procedure for reducing   the variance of a statistical learning method. Given a set of n independent   observations $Z_1,\\ldots,Z_n$, each with variance $\\sigma^2$, the variance of the   mean $\\bar{Z}$ of the observations is given by $\\sigma^2/n$. In other words,   averaging a set of observations reduces variance.  Hence it is a natural way to reduce the variance and increase the test set accuracy   of a statistical learning method. We could calculate \\(\\hat{f}^1(x), \\ldots, \\hat{f}^B(x)\\)   using B seperate training sets, and average them in order to obtain a single   low-variance model, \\(\\hat{f}_{\\text{avg}}(x) = \\frac{1}{B}\\sum_{b=1}^B\\hat{f}^b(x)\\).        In practice, we do not have access to multiple training sets. Instaed, we can bootstrap,   by taking repeated samples from the (single) training data set. The bagging model,  \\(\\hat{f}_{\\text{bag}}(x) = \\frac{1}{B}\\sum_{b=1}^B\\hat{f}^{*b}(x)\\).        It is particularly useful for decision trees. To apply begging to regression trees,   we simply construct B regression trees using B bootstrapped training sets, and   average the resulting predictions. These trees are grown deep but not pruned. Each   individual tree has high variance but low bias. Averaging these trees reduces the   variance. Bagging improves the accuracy by combining hundreds or even thousands of   trees into a single procedure.        To a classification problem where Y is qualitative, the simplest approach is the  majority vote; For a given test observation, record the class predicted by each   of the B trees and the overall prediction is the most commonly occurring class   among those predictions.  Out-of-Bag Error Estimation      Without cross-validation or the validation set approach, there is a very straightforward   way to estimate the test error of a bagged model. The reamining observations not   used to fit a given bagged tree are referred to as the out-of-bag(OOB) observations.   We can predict the response for the ith observation using each of the trees in   which that observation was OOB. To obtain a single prediction for the ith observation,   we average these predicted responses to a regression set, or take a majority vote   to a classification set. An OOB prediction can be obtained in this way for every   n observations, from which the overall OOB MSE or classification error can be computed.        Sinse the response for each observation is predicted using only the trees that were   not fit using that observation, the resulting OOB error is a valid estimate of the   test error for the bagged model.  Variable Importance Measures  Bagging improves prediction accuracy at the expense of interpretability. One can obtain   an overall summary of the importance of each predictor using the RSS or the Gini   index. In the case of bagging regression trees, we can record the total amount that   the RSS is decreased due to splits over a given predictor, averaged over all B   trees. A large value indicates an important predictor.8.2.2. Random Forests      If there is one very strong predictor along with a number of other moderately strong   predictors, in bagging method, most trees will use this strong predictor in the top   split. Consequently, all of the bagged trees will look quite similar and the predictions   from the bagged trees will be highly correlated. Averaging highly correlated quantities   does not lead to a substantial reduction in variance over a single tree in this setting.        Random forests overcome this problem by forcing each split to consider only a subset   of the predictors. As in bagging, we build a number of decision trees on bootstrapped   training samples. But when building these decision trees, each time a split in a   tree is considered, a random sample of m predictors is chosen as split candidates   from the full set of p predictors. Typically, the number of predictors considered   at each split m is approximately equal to the square root of the total number of   predictors p; $m\\approx\\sqrt{p}$.        On average $(p-m)/p$ of the splits will not even consider the strong predictor, and   so other predictors will have more of a chance. This process is decorrelating   the trees, thereby making the average of the resulting trees less variable and more   reliable.  Permutation Importance  Calculate the estimated test error with the original OOB samples as validation data,   then randomly suffle; or permute the order of the jth variable on OOB sample   to break the relationship between $X_j$ and Y. With this permuted OOB samples,   calculate the Permuation Measure. If the result of permuation measure is worse than   that of reference measure, we can consider $X_j$ is an important variable. For all   variables X, we can make the rank of variable importance. However, permuation   importance can overestimates the importance of correlated predictors.8.2.3. Boosting      Bagging creates multiple copies of the original training data set using the bootstrap,   fits a separate decision tree to each copy and then combines all of the trees in   order to create a single predictive model. Each tree is built on a bootstrap data   set, independent of the other trees.        Boosting works in a similar way, except that the trees are grown sequentially: each   each tree is grown using information from previously grown trees. This approach   does not involve bootstrap sampling; instead each tree is fit on a modified version   of the original data set.    Algorithm          Set $\\hat{f}(x)=0$ and $r_i=y_i$ for all i in the training set.      For $b=1,2,\\ldots,B$, repeat: (a) Fit a tree $\\hat{f}^b$ with d splits ($d+1$ terminal nodes) to the  training data (X,r). (b) Update $\\hat{f}$ by adding in a shrunken version of the new tree: \\(\\hat{f}(x)\\leftarrow\\hat{f}(x)+\\lambda\\hat{f}^b(x)\\). (c) Update the residuals, removing the effect of bth tree, Unexplained residuals \\(r_i\\leftarrow r_i - \\lambda\\hat{f}^b(x_i)\\).      Output the boosted model, \\(\\hat{f}(x)=\\sum_{i=1}^B\\lambda\\hat{f}^b(x)\\).            Boosting combines multiple weak learners(poor prediction models) and make better   prediction. In procedure, data(the weights of observations) are repeatedly modified   and the model learns slowly.    Boosting tuning parameters          B the number of trees. Unlike bagging and random forests, boosting can overfit  if B is too large, although this overfitting tends to occur slowly if at all.  We use cross-validation to select B.      $\\lambda$ the shrinkage parameter, a small positive number. This controls the  rate at which boosting learns. Typical values are 0.01 or 0.001. Very small  $\\lambda$ can require using a very large value of B to achieve good performance.      d the number of splits in each tree, which controls the complexity of the boosted  ensemble. $d=1$ works well, in which case each tree is a stump, consisting  of a single split. In this case, the boosted ensemble is fitting an additive  model, each term involves only a single variable. Generally d is the  interaction depth, and controls the interaction order of the boosted model.      8.2.4. Bayesian Additive Regression Trees      Bagging and random forests make predictions from an average of independent trees,   while boosting uses a weighted sum of trees. BART is related to both approaches:   each tree is constructed in a random manner and each tree tries to caputre signal   not yet accounted for by the current model.        let K denote the number of regression trees, and B the number of iterations for   which the BART will be run. The notation $\\hat{f}_k^b(x)$ represents the prediction   at x for the kth regression tree used in the bth iteration. At the end of   each iteration, the K trees from that iteration will be summed;   \\(\\hat{f}^b(x)=\\sum_{k=1}^K\\hat{f}_k^b(x)\\) for $b=1,\\ldots,B$.        First iteration, all trees are initialized to have a single root node, with  \\(\\hat{f}_k^1(x) = \\frac{1}{nK}\\sum_{i=1}^n y_i\\), the mean of the response values  divided by the total number of trees. Thus,  \\(\\hat{f}^1(x)=\\sum_{k=1}^K\\hat{f}_k^1(x)=\\frac{1}{n}\\sum_{i=1}^n y_i = \\bar{y}\\).        Next, updates each of the K trees, one at a time. In the bth iteration, we subtract from each response value the predictions from  all but the kth tree to obtain a partial residual \\(r_i = y_i - \\sum_{k'&lt;k}\\hat{f}_{k'}^b(x_i) - \\sum_{k'&gt;k}\\hat{f}_{k'}^{b-1}(x_i)\\) Rather than fitting a fresh tree to this partial residual, BART randomly chooses  a perturbation to the tree from the previous iteration from a set of possible  perturbations, favoring ones that improve the fit to the partial residual.    Two components to the perturbation:  We may change the structure of the tree by adding or pruning branches.  We may change the prediction in each terminal node of the tree.  Output of BART is a collection of prediction models, \\(\\hat{f}^b(x) = \\sum_{k=1}^K\\hat{f}_k^b(x)\\)  Typically, the first few of these prediction models in earlier iterations, known   as the burn-in period, tend not to provide very good results. For the number of   burn-in iterations L, for instance we might take L=200, we simply remove and   take the average after L iterations; \\(\\hat{f}(x)=\\frac{1}{B-L}\\sum_{b=L+1}^B\\hat{f}^b(x)\\).   Or we can compute quantities other than the average.8.2.5. Summary of Tree Ensemble Methods  Bagging: The trees are grown independently on random samples of the observations and   tend to be quite similar to each other. Thus, bagging can get caught in local optima   and fail to thoroughly explore the model space.  Random Forests: The trees are grown independently on random samples but each split   on each tree is performed using a random subset of the features, decorrelating the   trees and leading to a more thorough exploration of the model space.  Boosting: We only use the original data and do not draw any random samples. Trees   are grown successively, usiang slow learning approach: each new tree is fit to the   signal that is left over from the earlier trees, and shrunken down before it is   used.  BART: WE only use the original data and trees are grown successively. However, each   tree is perturbed in order to avoid local minima and achieve a more thorough exploration   of the model space.",
        "url": "/islr_ch8"
    }
    ,
    
    "nlp-eng-ml": {
        "title": "NLP - Text Analysis with ML algorithms",
        "author": "Darron Kwon",
        "category": "",
        "content": "  1. Data Info  2. Preprocessing          2.1. duplicated data found in train_data        3. Comparing between classification models          3.1 With Tf-idf vectorizer                  3.1.1 MultinomialNB          3.1.2 LogisticRegression                    3.2 With CountVectorizer                  3.2.1 MultinomialNB                      4. Balanced sampling approach - imblearn  5. Result: Best Modelimport sysimport pandas as pdimport osimport numpy as npimport reimport randomimport itertoolsimport warningswarnings.filterwarnings(action='ignore')from sklearn.metrics import classification_reportfrom sklearn.metrics import f1_scorerandom.seed(1)train_data=pd.read_csv('midterm_train.csv')test_data=pd.read_csv('midterm_test.csv')# evaluating functiondef evaluate(test_x,test_y,model):    predictions=model.predict(test_x)    print(classification_report(test_y,predictions))1. Data Infotrain_data.head(3)                  text      senti                  0      J brand is by far the best premium denim line ...      pos              1      I loved this dress. i kept putting it on tryin...      pos              2      I found this at my local store and ended up bu...      pos      print(train_data.groupby('senti').count())print(test_data.groupby('senti').count())print(train_data.describe())print(test_data.describe())        textsenti       neg     2139pos    11279       textsenti      neg     231pos    1260                                                     text  senticount                                               13418  13418unique                                              13414      2top     Perfect fit and i've gotten so many compliment...    posfreq                                                    2  11279                                                     text senticount                                                1491  1491unique                                               1491     2top     Have to disagree with previous posters. i foun...   posfreq                                                    1  12602. Preprocessing2.1. duplicated data found in train_data# remove duplicated dataprint(train_data.text.duplicated().sum())train_data = train_data.drop_duplicates(['text'],keep='first')train_data.duplicated().sum()40print(train_data.describe())                                                     text  senticount                                               13414  13414unique                                              13414      2top     J brand is by far the best premium denim line ...    posfreq                                                    1  11276# train-test split unduplicated datax_train=np.array(train_data.text)x_test=np.array(test_data.text)y_train=np.array(train_data.senti)y_test=np.array(test_data.senti)x_train[0]'J brand is by far the best premium denim line retailer sells! the fit on these jeans is amazing..worth every penny..also, considering it is a crop jean - warm weather wear - the denim weight is light and not too thick...the color is different from ordinary regular denim blue..lighter wash for spring/summer!'# preprocessing: remove non-alphabet charactersx_train_clean=np.array([re.sub('[^a-zA-Z]',' ',text) for text in x_train])x_test_clean=np.array([re.sub('[^a-zA-Z]',' ',text) for text in x_test])x_train_clean[0]'J brand is by far the best premium denim line retailer sells  the fit on these jeans is amazing  worth every penny  also  considering it is a crop jean   warm weather wear   the denim weight is light and not too thick   the color is different from ordinary regular denim blue  lighter wash for spring summer '3. Comparing between classification models# tuning parameter setsngram_range= [(1, 1), (1, 2),(2,2)]stop_words=[None,'english']clf__alpha=[0.005,0.01,0.05,0.1]params = dict(ngram_range=ngram_range,              stop_words=stop_words,              clf__alpha=clf__alpha)keys=params.keys()values = (params[key] for key in keys)combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]# tuning functiondef tuning_model(params,vectorizer,classifier,x_train,x_test,y_train,y_test):    ngram_range=params['ngram_range']    stop_words=params['stop_words']    vec = vectorizer(ngram_range=ngram_range,stop_words=stop_words)    vec_train = vec.fit_transform(x_train)    vec_test = vec.transform(x_test)    if classifier==MultinomialNB:        alpha=params['clf__alpha']        clf=classifier(alpha)    else:        clf=classifier(random_state=1,max_iter=500)    clf.fit(vec_train, y_train)    pred=clf.predict(vec_test)    return f1_score(y_test,pred,average='macro'),params# get best score &amp; parametersdef get_result(combinations,vectorizer,classifier,x_train,x_test,y_train,y_test):    results=[]    for params in combinations:        results.append(tuning_model(params,vectorizer,classifier,x_train,x_test,y_train,y_test))    return max(results,key=lambda item: item[0])3.1 With Tf-idf vectorizer3.1.1 MultinomialNBpreprocessing seems to have no effect in ngram_range: (1, 2) and also stop words are not important featuresf1-score macro avg: 0.85from sklearn.naive_bayes import MultinomialNBfrom sklearn.feature_extraction.text import TfidfVectorizerget_result(combinations,TfidfVectorizer,MultinomialNB,x_train,x_test,y_train,y_test)(0.8528815948449455, {'ngram_range': (1, 2), 'stop_words': None, 'clf__alpha': 0.01})get_result(combinations,TfidfVectorizer,MultinomialNB,x_train_clean,x_test_clean,y_train,y_test)(0.8528815948449455, {'ngram_range': (1, 2), 'stop_words': None, 'clf__alpha': 0.005})3.1.2 LogisticRegressionfrom sklearn.linear_model import LogisticRegressionget_result(combinations,TfidfVectorizer,LogisticRegression,x_train,x_test,y_train,y_test)(0.8811180515581001, {'ngram_range': (1, 1), 'stop_words': None, 'clf__alpha': 0.005})get_result(combinations,TfidfVectorizer,LogisticRegression,x_train_clean,x_test_clean,y_train,y_test)(0.8823175752378818, {'ngram_range': (1, 1), 'stop_words': None, 'clf__alpha': 0.005})3.2 With CountVectorizer3.2.1 MultinomialNBfrom sklearn.feature_extraction.text import CountVectorizerget_result(combinations,CountVectorizer,MultinomialNB,x_train,x_test,y_train,y_test)(0.9366865264206945, {'ngram_range': (1, 2), 'stop_words': None, 'clf__alpha': 0.1})get_result(combinations,CountVectorizer,MultinomialNB,x_train_clean,x_test_clean,y_train,y_test)(0.935509934324805, {'ngram_range': (1, 2), 'stop_words': None, 'clf__alpha': 0.1})4. Balanced sampling approach - imblearnfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.feature_extraction.text import CountVectorizerfrom sklearn.naive_bayes import MultinomialNBfrom sklearn.linear_model import LogisticRegression# tuning parameter sets for all casesvectorizer=[CountVectorizer,TfidfVectorizer]classifier=[MultinomialNB,LogisticRegression]ngram_range= [(1, 1), (1, 2),(2,2)]stop_words=[None,'english']clf__alpha=[0.005,0.01,0.05,0.1]params = dict(ngram_range=ngram_range,              vectorizer=vectorizer,              classifier=classifier,              stop_words=stop_words,              clf__alpha=clf__alpha)keys=params.keys()values = (params[key] for key in keys)combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]from imblearn.over_sampling import SMOTEdef smote_tuning(params,x_train,x_test,y_train,y_test):    ngram_range=params['ngram_range']    stop_words=params['stop_words']    classifier=params['classifier']    vec=params['vectorizer'](ngram_range=ngram_range,stop_words=stop_words)    x_train_imb=vec.fit_transform(x_train)    y_train_imb=np.array(train_data['senti']=='pos').astype('int')    y_test_imb=np.array(test_data['senti']=='pos').astype('int')    vec_train_over, y_train_over = SMOTE(random_state=1).fit_resample(x_train_imb,y_train_imb)    vec_test = vec.transform(x_test)    if classifier==MultinomialNB:        alpha=params['clf__alpha']        clf=classifier(alpha)    else:        clf=classifier(random_state=1,max_iter=500)    clf.fit(vec_train_over, y_train_over)    pred=clf.predict(vec_test)    return f1_score(y_test_imb,pred,average='macro'),params# get best score &amp; parametersdef get_smote_result(combinations,x_train,x_test,y_train,y_test):    results=[]    for params in combinations:        results.append(smote_tuning(params,x_train,x_test,y_train,y_test))    return max(results,key=lambda item: item[0])get_smote_result(combinations,x_train,x_test,y_train,y_test)(0.9285352359562871, {'ngram_range': (1, 2),  'vectorizer': sklearn.feature_extraction.text.TfidfVectorizer,  'classifier': sklearn.naive_bayes.MultinomialNB,  'stop_words': None,  'clf__alpha': 0.1})get_smote_result(combinations,x_train_clean,x_test_clean,y_train,y_test)(0.9276401547886131, {'ngram_range': (1, 2),  'vectorizer': sklearn.feature_extraction.text.TfidfVectorizer,  'classifier': sklearn.naive_bayes.MultinomialNB,  'stop_words': None,  'clf__alpha': 0.1})5. Result: Best Model# 'ngram_range': (1, 2), 'stop_words': None, 'clf__alpha': 0.1}vectorizer=CountVectorizer(ngram_range=(1,2))vectors_train=vectorizer.fit_transform(x_train)vectors_test=vectorizer.transform(x_test)clf=MultinomialNB(alpha=0.1)clf.fit(vectors_train,y_train)evaluate(vectors_test,y_test,clf)              precision    recall  f1-score   support         neg       0.90      0.88      0.89       231         pos       0.98      0.98      0.98      1260    accuracy                           0.97      1491   macro avg       0.94      0.93      0.94      1491weighted avg       0.97      0.97      0.97      1491",
        "url": "/NLP_eng_ml"
    }
    ,
    
    "islr-ch7": {
        "title": "ISLR - Chapter 7. Moving Beyond Linearity",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 7. Moving Beyond Linearity  7.1. Polynomial Regression  7.2. Step Functions  7.3. Basis Functions  7.4. Regression Splines          7.4.1. Piecewise Polynomials      7.4.2. Constraints and Splines      7.4.3. The Spline Basis Representation      7.4.4. Choosing the Number and Locations of the Knots      7.4.5. Comparison to Polynomial Regression        7.5. Smoothing Splines          7.5.1. An Overview of Smoothing Splines      7.5.2. Choosing the Smoothing Parameter $\\lambda$        7.6. Local Regression  7.7. Generalized Additive Models          7.7.1. GAMs for Regression Problems      7.7.2. GAMs for Classification Problems                  Pros and Cons of GAMs                    Chapter 7. Moving Beyond Linearity7.1. Polynomial Regression  standard linear model $y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i$  to a polynomial function $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\cdots + \\beta_d x_i^d + \\epsilon_i$  For large enough degree d, a polynomial regression produces an extremely non-  linear curve. The coefficients $\\beta_d$’s can be easily estimated using least   squares linear regression.7.2. Step Functions      Break the range of X into bins, and fit a different constant in each bin;   converting a continuous variables into an ordered categorical variable.        By cutpoints $c_1, c_2, \\ldots, c_K$ in the range of X, construct K+1 new variables  \\(\\begin{align*}  C_0(X) &amp;= I(X &lt; c_1), \\\\  C_1(X) &amp;= I(c_1 \\le X &lt; c_2), \\\\  C_2(X) &amp;= I(c_2 \\le X &lt; c_3), \\\\         &amp;\\vdots \\\\  C_{K-1}(X) &amp;= I(c_{K-1} \\le X &lt; c_K), \\\\  C_{K}(X) &amp;= I(c_K \\le X), \\\\  \\end{align*}\\)  where I($\\cdot$) is an indicator function returning value of 1 or 0. These are   sometimes called dummy variables. For any value of X, $\\sum_{i=0}^K C_i(X) = 1$.        The least squares model: $y_i = \\beta_0 + \\beta_1 C_1(x_i) + \\cdots + \\beta_K C_K(x_i) + \\epsilon_i$  When $X&lt;c_1$, all of the predictors $C_1(X), C_2(X), \\ldots, C_K(X)$ are zero, so   $\\beta_0$ is the mean value of Y or $X&lt;c_1$. By comparison, the model predicts   a response of $\\beta_0 + \\beta_j$ for $c_j \\le X &lt; c_{j+1}$, so $\\beta_j$ represents the   average increase in the response for X in such range.        Unless there are natural breakpoints in the predictors, piecewise-constant functions   can miss the action.  7.3. Basis Functions      Polynomial and piecewise-constant regression models are in fact special cases of a   basis function approach; with a family of functions or transformations applied   to a variable X: $b_1(X), b_2(X), \\ldots, b_K(X)$, fit a linear model  $y_i = \\beta_0 + \\beta_1 b_1(x_i) + \\beta_2 b_2(x_i) + \\cdots + \\beta_K b_K(x_i) + \\epsilon_i$.  as a standard linear model with predictors $b_i(x_i), b_2(x_i), \\ldots, b_K(x_i)$.   Hence, we can use least squares and all of the inference tools, such as std.err   for coefficient estimates and F-statistics for the model’s overall significance.        Note that the basis functions $b_k(\\cdot)$ are fixed and known(or, we choose the   functions before). E.g., for polynomial regression, the basis functions are $b_j(x_i)=x_i^j$.  7.4. Regression Splines7.4.1. Piecewise Polynomials      Instead of fitting a high-degree polynomial over the entire range of X, piecewise   polynomial regression fits separate low-degree polynomials over different regions.   Divide dimension X by knots and apply different polynomial model to each   region. If we place K knots throughout the range of X, then we fit K+1 different   models.        a cubic regression model; $y_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2 + \\beta_3 x_i^3 + \\epsilon_i$  is a piecewise cubic with no knots with d = 3.  On the other hand,  \\(y_i = \\begin{cases}          \\beta_{01}+\\beta_{11}x_i + \\beta_{21}x_i^2 + \\beta_{31}x_i^3 + \\epsilon_i &amp; \\mbox{if }x_i &lt; c \\\\          \\beta_{02}+\\beta_{12}x_i + \\beta_{22}x_i^2 + \\beta_{32}x_i^3 + \\epsilon_i &amp; \\mbox{if }x_i \\ge c. \\\\          \\end{cases}\\)  is with a single knot at a point c.        For other degrees d:  a piecewise-constant functions are piecewise polynomials of degree 0, a piecewise   linear functions are of degree 1.  7.4.2. Constraints and Splines  To fix the discontinuity and overcomplexity, we add some additional constraints:  in a degree-d spline, or a piecewise degree-d polynomial, it requires the   continuity in derivatives up to degree d-1 at each knot.7.4.3. The Spline Basis Representation      $y_i = \\beta_0 + \\beta_1 b_1(x_i) + \\beta_2 b_2(x_i) + \\cdots + \\beta_{K+3} b_{K+3}(x_i) + \\epsilon_i$  is a cubic spline model with K knots.        with a truncated power basis function per knot $\\xi$, which is defined as \t  \\(h(x,\\xi) = (x-\\xi)_{+}^3 = \\begin{cases} (x-\\xi)^3 &amp; \\mbox{if }x&gt;\\xi \\\\                                                  0\t &amp; \\mbox{otherwise,}                               \\end{cases}\\)  so, in fitting a cubic spline with K knots, we perform least squares regression   with an intercept and 3+K predictors, of the form $X, X^2, X^3, h(X,\\xi_1), h(X,\\xi_2), \\ldots, h(X,\\xi_K)$.  This amounts to estimating a total of K+4 regression coefficients; for this   regression, fitting a cubic spline with K knots uses K+4 degrees of freedom.        However, splines can have high variance at the outer range of the predictors;   $X&lt;c_1$ or $X\\ge c_K$, when X takes on either a very small or very large value.   We see that the confidence bands in the boundary region appear fairly wild.  A natural spline with additional boundary constraints that the function is   required to be linear at the boundary, generally produce more stable estimates. In   this case, the corresponding confidence intervals are narrower.  7.4.4. Choosing the Number and Locations of the Knots      The regression spline is most flexible in regions that contain a lot of knots, because   in those regions the polynomial coefficients can change rapidly. Hence, one option   is to place more knots in places where the function might vary most rapidly, and   to place fewer knots where it seems more stable. In practice, it is common to place   knots in a uniform fashion.        To determine the number of knots, or equivalently the degrees of freedom of the spline   contain, we use cross-validation method.  7.4.5. Comparison to Polynomial Regression      Regression splines often give superior results to polynomial regression. This is   because unlike polynomials, which must use a high degree to produce flexible fits,   splines introduce flexibility by increasing the number of knots but keeping the   degree fixed. Generally, this approach produces more stable estimates.        Splines can produce a reasonable fit at the boundaries and also allow us to place   more knots, or flexibility, over regions where the function f seems to be changing   rapidly, and fewer knots where f appears more stable.  7.5. Smoothing Splines7.5.1. An Overview of Smoothing Splines      In fitting a smooth curve to a set of data, some function $g(x)$, that fits the   observed data well: Minimizing $RSS = \\sum_{i=1}^n(y_i-g(x_i))^2$. But if we don’t   put any constraints on g, then we can always make RSS zero simply by choosing   g such that it interpolates all of the $y_i$. Such a function would woefully   overfit the data, would be too flexible.        Smoothing spline is the function g that minimizes  \\(\\sum_{i=1}^n(y_i - g(x_i))^2 + \\lambda\\int g''(t)^2, dt\\)  with a nonnegative tuning parameter $\\lambda$, takes the “Loss+Penalty” formulation   like the ridge and lasso. The term $\\sum_{i=1}^n(y_i - g(x_i))^2$ is a loss function   that makes g to fit the data well, and the term \\(\\lambda\\int g''(t)^2, dt\\) is a   penalty term that reduces the variability in g. \\(g''(t)\\) indicates the second   derivative of the function g, corresponds to the amount by which the slope(the first   derivative) is changing. Broadly speaking, the second derivative is a measure of   its roughness: large in absolute value if g(t) is very wiggly near t, close   to zero otherwise. It is zero as the derivative of a straight line, the function is   perfectly smooth. The integral is a summation over the range of t, so \\(\\int g''(t)^2, dt\\)   is a measure of the total change in the function $g’(t)$ over its entire range. If   g is very smooth, then $g’(t)$ will be close to constant and \\(\\int g''(t)^2, dt\\) will   take on a small value. Therefore, the penalty term encourages g to be smooth.   The larger the $\\lambda$, the smoother the g will be.  When $\\lambda=0$, then there’s no penalty and the function g will be very jumpy   and have perfect fit. When $\\lambda\\rightarrow\\infty$, g will be perfectly smooth;   a linear least squares line $g(x)=ax+b$. The $\\lambda$ controls the bias-variance   trade-off of the smoothing spline.        Smoothing spline g(x) have some special properties: it is a piecewise polynomial   with knots at the unique values of $x_1,\\ldots,x_n$, and continuous first and second   derivatives at each knot. Furthermore, it is linear in the region outside of the   extreme knots.  In other words, the Smoothing spline function is a nautral spline with knots at   $x_1,\\ldots,x_n$; it is a shrunken version of such a natural spline, where the value   of the tuning parameter $\\lambda$ controls the level of shrinkage.  7.5.2. Choosing the Smoothing Parameter $\\lambda$      Have seen that a smoothing spline is simply a natural spline with knots at every unique   value of $x_i$, it might seem that a smoothing spline will have far too many degrees   of freedom, since a knot at each data point allows a great deal of flexibility.   But $\\lambda$ controls the roughness of the smoothing spline, and hence the effective   degrees of freedom. We can show that as $\\lambda$ increase from 0 to $\\infty$,   the effective degrees of freedom $df_\\lambda$ decrease from n to 2.        Usually degrees of freedom refer to the number of free parameters, such as the number   of coefficients fit in a polynomial or cubic spline. Though a smoothing spline has   n parameters and n nominal degrees of freedom, these n parameters are heavily   constrainted or shrunk down. Thus $df_\\lambda$ is a measure of the flexibility of   the smoothing spline, the higher it is, the more flexible the smoothing spline.        The definition of effective degrees of freedom, the measure of model complexity:  \\(\\hat{\\mathbf{g}}_\\lambda = \\mathbf{S}_\\lambda\\mathbf{y}\\),  where \\(\\hat{\\mathbf{g}}_\\lambda\\) is the solution to the smoothing spline function   g for a particular choice of $\\lambda$, it is an n-vector containing the fitted   values of the model at the training points $x_1,\\ldots,x_n$.  Then the effective degrees of freedom is defined to be  \\(df_\\lambda = \\text{trace}(\\mathbf{S}_\\lambda) = \\sum_{i=1}^n\\{ \\mathbf{S}_\\lambda \\}_{ii}\\),  the sum of the diagonal elements of the matrix $\\mathbf{S}_\\lambda$.  e.g.) for a linear regression model:  \\(\\mathbb{H} = \\mathbb{X}(\\mathbb{X}^T\\mathbb{X})^{-1}\\mathbb{X}^T\\),  \\(\\text{trace}(\\mathbb{H}) = p+1\\)        In fitting a smoothing spline, we do not need to select the number or location of the   knots; there will be a knot at each training observation. Instead, we need to choose   the value of $\\lambda$. For this case, LOOCV can be computed very efficiently with   essentially the same cost as computing a single fit, using the following formula:  \\(RSS_{cv}(\\lambda) = \\sum_{i=1}^n(y_i - \\hat{g}_\\lambda^{(-i)}(x_i))^2   = \\sum_{i=1}^n\\left[\\frac{y_i-\\hat{g}_\\lambda(x_i)}{1-\\{\\mathbf{S}_\\lambda\\}_{ii}}\\right]^2\\)  where \\(\\hat{g}_\\lambda^{(-i)}(x_i)\\) indicates the fitted value for this smoothing   spline evaluated at $x_i$, where the fit uses all the training observations except   for the ith observation. In contrast, \\(\\hat{g}_\\lambda(x_i)\\) indicates the smoothing   spline evaluated at $x_i$, where the function is fit to the full data. Thus, we can compute   each of LOOCV fits, by one-time computing of the original fit to all of the data.        By effective d.f, we can directly compare the model complexities of models discussed so   far, such as linear regression, ridge regression, smoothing splines, cubic splines, etc.  7.6. Local Regression      A different approach for fitting flexible non-linear functions, with the idea of KNN   but closer observations have more weights. This is sometimes referred to as a memory-based   procedure, because we need all the training data each time we compute a prediction.    Algorithm: Local Regression At $X = x_0$          Gather the faction $s = k/n$ of training points whose $x_i$ are closest to $x_0$.      Assign a weight $K_{i0} = K(x_i,x_0)$ to each point in this neighborhood, so that   the point furthest from $x_0$ has weight zero, and the closest has the highest weight.   All other points get weight zero.      Fit a weighted least squares regression using the aforementioned weights;  Objective function: \\(\\text{min}_{\\beta_0,\\beta_1}                 \\left[\\sum_{i=1}^n K_{i0}(y_i - \\beta_0 - \\beta_1 x_i)^2 \\right]\\)      The fitted value at $x_0$ is given by $\\hat{f}(x_0) = \\hat\\beta_0 + \\hat\\beta_1 x_0$.            In performing local regression, there are choices to be made, such as how to define   the weighting function K, and which regression model to fit. The most important   choice is the span s, which is the proportion of points used to compute the local   regression at $x_0$; “How many neighbors?”. It plays a role of the tuning parameter   $\\lambda$, controls the flexibility of the fit. The smaller s, the more local and   wiggly the fit. We can use CV methods to choose s, or we can specify it directly.        The idea of local regression can be generalized in many different ways. In multivariate   settings, one very useful generalization involves fitting a multiple linear regression   model that is global in some variables, but local in another, such as time. Such   varying coefficient models are a useful way of adapting a model to the most recently   gathered data.    Local regression can perform poorly if the dimension p is much larger, suffers the   dimensionality problem. Also, it has a boundary problem because there are less data   points for neighbors.7.7. Generalized Additive Models  Approaches presented in sections above can be seen as extensions of simple linear   regression, flexibly predicting a response Y on the basis of a single predictor X.   GAMs provide a general framework for extending a standard linear model by allowing   non-linear functions of each of the variables, while maintaining additivity. They   can be applied with both quantitative and qualitative responses.7.7.1. GAMs for Regression Problems      standard multiple linear regression model is  \\(y_i = \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\cdots + \\beta_p x_{ip} + \\epsilon_i\\).  for non-linear relationships, replace each linear component \\(\\beta_j x_{ij}\\) with an   unspecified (smoothing) non-linear function \\(f_j(x_{ij})\\), now the model is  \\(\\begin{align*}  y_i &amp;= \\beta_0 + \\sum_{j=1}^p f_j(x_{ij}) + \\epsilon_i \\\\      &amp;= \\beta_0 + f_1(x_{i1}) + f_2(x_{i2}) + \\cdots + f_p(x_{ip}) + \\epsilon_i.  \\end{align*}\\)  It is called an additive model because we calculate a separate f for each X,   then add together all of their contributions.        In case of using a smoothing spline to fit a GAM, it is not quite as simple as a   natural spline case, since the least squares cannot be used. However, Standard   softwares have some functions for GAMs using smoothing splines, via an approach   known as backfitting; a method to fit a multivariate model by repeatedly updating   the fit for each predictor in turn, holding the others fixed. Each time we update   a function, we simply apply the fitting method for that variable to a partial residual.  7.7.2. GAMs for Classification Problems  For qualitative response Y, standard logistic regression model is  \\(\\log\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p.\\)  An extension allowing non-linear relationships; a logistic regression GAM is  \\(\\log\\left(\\frac{p(X)}{1-p(X)}\\right) = \\beta_0 + f_1(X_1) + f_2(X_2) + \\cdots + f_p(X_p).\\)Pros and Cons of GAMs  Pros          GAMs allow us to fit a non-linear function to each variable, so that we can  automatically model non-linear relationships. This means we do not need to  manually try out many different transformations on each variable individually.      Potentially make more accurate predictions with non-linear fits.      Because the model is additive, we can examine the effect of each variable on the  response individually while holding all of the other variables fixed.      The smoothness of the function for the variable can be summarized via degrees  of freedom.        Cons          The model is restricted to be additive; with many variables, important interactions  can be missed. However, we can manually add interaction terms to the model by  including additional predictors of the form like $X_j \\times X_k$.      The solution of the optimization is not unique; $\\beta_0$ is not identifiable  because each $f_j$ model has its intercept term; a GAM has p+1 total intercepts  and they are not distinguishable. For this problem, we make a restriction that  every jth X variable to be centered; \\(\\sum_{i=1}^n f_j(x_{ij}) = 0\\) and  $\\hat\\beta_0 = \\bar{y}$.      ",
        "url": "/islr_ch7"
    }
    ,
    
    "islr-ch6": {
        "title": "ISLR - Chapter 6. Linear Model Selection and Regularization",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 6. Linear Model Selection and Regularization  6.1. Subset Selection          6.1.1. Best Subset Selection      6.1.2. Stepwise Selection                  Forward Stepwise Selection          Backward Stepwise Selection          Hybrid Approaches                    6.1.3. Choosing the Optimal Model                  Validation and Cross-Validation                      6.2. Shrinkage Methods          6.2.1. Ridge Regression                  in Singular Value Decomposition                    6.2.2. The Lasso                  Another Formulation for Ridge Regression and the Lasso          A Simple Special Case          Bayesian Interpretation                      6.3. Dimension Reduction Methods          6.3.1.  Principal Components Regression                  Principal Components Analysis          The Principal Components Regression Approach                    6.3.2. Partial Least Squares        6.4. Considerations in High Dimensions          6.4.1. High-Dimensional Data      6.4.2. What Goes Wrong in High Dimensions?      6.4.3. Regression in High Dimensions      6.4.4. Interpreting Results in High Dimensions      Chapter 6. Linear Model Selection and Regularization  Limitations of LSE          Prediction Accuracy:                  if n is not much larger than p, the least squares fit can have a lot  of variability, results in overfitting and poor predictions to test data.          if p &gt; n, there is no unique solution for the least squares coefficient  estimate; as $ Var(\\hat\\beta)=\\infty$.          if p is large, there can be correlations between X variables. A model  having multicollinearity can have high variance.Constraining or Shrinking the estimated coefficients can reduce the variance with negligible increase in bias, and improve in the accuracy to the test data.                    Model Interpretability:                  There are irrelevant variables $X_j$. Removing by setting coefficient estimates  $\\beta_j = 0$, we can have more interpretability.Feature selection or Variable selection can exclude irrelevant variables from a multiple regression model.                    6.1. Subset Selection6.1.1. Best Subset Selection      fit a separate least squares regression for all $2^p$ possible models with combinations of the p predictors.    Algorithm          $\\mathcal{M}_0$ as null model (i.e., $ Y = \\beta_0 + \\epsilon $)      For $ k = 1, 2, \\ldots, p $:  (a) Fit all \\({p \\choose k}\\) models with k predictors  (b) Pick the smallest RSS, (or largest $R^2$) = $ \\mathcal{M}_k $      Select best model among $\\mathcal{M}_0, \\ldots,\\mathcal{M}_p$ using cross-validated   prediction error, $C_p$ (AIC), BIC, or adjusted $R^2$            Guarantees the best selection, while it suffers from computational limitations. Also, it only works for least squares linear regression.    in the case of logistic regression, we use deviance, $-2\\log$MLE, instead of RSS in the 2nd step of algorithm upon.6.1.2. Stepwise SelectionForward Stepwise Selection  Algorithm          $\\mathcal{M}_0$ as null model      For $ k = 1, 2, \\ldots, p $:  (a) Fit all p - k models in \\(\\mathcal{M}_k\\) with one additional predictor  (b) Pick the smallest RSS among p - k models, $\\mathcal{M}_{k+1}$      Select best model among $\\mathcal{M}_0, \\ldots,\\mathcal{M}_p$ with CV scores        Total $\\frac{p(p+1)}{2}+1$ possible models. No guarantee but available for the case of high dimensional data($n&lt;p$).Backward Stepwise Selection  Algorithm          $\\mathcal{M}_p$ as full model, contains all p predictors      For $ k = p, p-1, \\ldots, 1 $:  (a) Fit all k - 1 models contain all but one of the predictors in \\(\\mathcal{M}_k\\)  (b) Pick the smallest RSS among k - 1 models, $\\mathcal{M}_{k-1}$      Select best model among $\\mathcal{M}_0, ldots,\\mathcal{M}_p$ with CV scores        Total $\\frac{p(p+1)}{2}+1$ possible models. No guarantee and not for n &lt; p case.Hybrid Approaches  add then remove one predictors in each step.6.1.3. Choosing the Optimal Model  A model containing all of the predictors will always have the smallest RSS and the largest $R^2$, since these quantities are related to the training error. Instead, we need a model with a low test error.      $C_p = \\frac{1}{n}(RSS + 2 d \\hat\\sigma^2)$ For a fitted least squares model, with d as the number of predictors and $\\hat\\sigma^2$ as  an estimate of the variance of the error. Typically $\\hat\\sigma^2$ is estimated using the full  model containing all predictors. Adding a penalty to the training RSS is to adjust its  underestimation to the test error. As the number of predictors increase, the penalty increase.  If there is a proof of $\\hat\\sigma^2$ is an unbiased estimate of $\\sigma^2$, $C_p$ is an unbiased  estimate of test MSE. Then, a model with the lowest $C_p$ is the best model.        AIC $= \\frac{1}{n}(RSS + 2 d \\hat\\sigma^2)$ For a models fit by maximum likelihood(MLE), given by omitted irrelevant constants. $C_p$ and  AIC are proportional to each other.        BIC $= \\frac{1}{n}(RSS + \\log(n)d\\hat\\sigma^2)$ From a Bayesian point of view, for a fitted least squares model. Also given by omitted  irrelevant constants. BIC has heavier penalty then $C_p$ or AIC, results in selecting smaller  models.        Adjusted $R^2 = 1 - \\frac{RSS/(n-d-1)}{TSS/(n-1)}$ Since the usual $R^2$ is defined as $1 - RSS/TSS$, it always increases as more variables added.  Adjusted $R^2$ gives penalty of d, the number of predictors in the denominator. Unlike other  statistics, a large value of adjusted $R^2$ indicates a small test error.  Validation and Cross-Validation  one-standard-error ruleFirst calculate the standard error of the estimated test MSE for each model size, then select the smallest model for which the estimated test error is within one standard error of the lowest point on the curve.If a set of models appear to be more or less equally good, then we might as well choose the simplest model; the model with the smallest number of predictors.6.2. Shrinkage Methods6.2.1. Ridge Regression      Ridge regression coefficient estimates\\(\\begin{align*}\\hat\\beta^R &amp;= \\text{min}_{\\beta}\\left[                  \\underbrace{\\sum_{i=1}^n(y_i-\\beta_0-\\sum_{j=1}^p \\beta_j x_{ij})}_{RSS}                  + \\lambda\\sum_{j=1}^p \\beta_j^2 \\right] \\\\            &amp;= (X^TX + \\lambda I)^{-1} X^T\\underline{y}\t\\end{align*}\\)        $\\lambda \\ge 0 $ is a tuning parameter, $\\lambda\\sum_{j=1}^p \\beta_j^2$ is a shrinkage penalty. The penalty is small when the coefficients are close to zero, and so it has the effect of shrinking the estimates of $\\beta_j$ towards zero. Ridge regression will produce a different set of coefficient estimates $\\beta_{\\lambda}^R$, for each value of $\\lambda$.        We do not want to shrink the intercept $\\beta_0$, which is simply a measure of the mean value of the response when $x_{i1}=x_{i2}=\\ldots=x_{ip}=0$. If the variables, the columns of the data matrix$X$, have been centered to have mean zero before ridge regression is performed, then the estiamted intercept will take the form $\\hat\\beta_0 = \\bar{y} = \\sum_{i=1}^n y_i/n$.        The standard least squares coefficient estimates are scale equivariant; multiplying $X_j$ by a constant c leads to a scaling of the least squares coefficient estimates by a factor of 1/c. I.e., regardless of how the jth predictor is scaled, $X_j\\hat\\beta_j$ will remain the same.In contrast, the ridge regression coefficient estimates can change substantially when multiplying a given predictor by a constant. The value of $X_j\\hat\\beta_{j,\\lambda}^R$ may depend on the scaling of the other predictors. Thus, before applying ridge regression, the variables need to be standardized to have a standard deviation of one.The formula: \\(\\tilde{x}_{ij}=\\frac{x_{ij}}{\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(x_{ij}-\\bar{x}_j)^2}}\\)        Ridge regression overperforms the standard least squares when the number of variables p is almost as large as the number of observations n, or even when $p &gt; n$. Also it has computational advantages over best subset selection, which requires searching through $2^p$ models. Ridge regression only fits a single model for any fixed value of $\\lambda$.  in Singular Value Decomposition  where $ X = \\mathbb{UDV}^T$,\\(\\begin{align*} X\\hat\\beta^{\\text{LSE}} &amp;= X(X^TX)^{-1}X^T\\underline{y} \\\\                                         &amp;= \\mathbb{UU}^T\\underline{y} \\\\                            X\\hat\\beta^R &amp;= UD(D^2 + \\lambda I)^{-1}DU^T\\underline{y} \\\\                                         &amp;= \\sum_{j=1}^p\\underline{u}_j\\frac{d_{ij}^2}{d_{ij}^2+\\lambda}\\underline{u}_j^T\\underline{y}\\end{align*}\\)\\(\\begin{align*}\\rightarrow \\partial f(\\lambda) &amp;= tr[X(X^TX + \\lambda I)^{-1} X^T] \\\\                                &amp;= tr(\\mathbb{H}_{\\lambda})  \\\\                                &amp;= \\sum_{j=1}^p\\frac{d_{ij}^2}{d_{ij}^2+\\lambda}\\end{align*}\\)6.2.2. The Lasso      Ridge regression estimates shrink towards zero but will not set nay of them exactly to zero(unless $\\lambda = \\infty$). This may not be a problem for prediction accuracy, but it can be a challenge in model interpretation when p is quite large.        The lasso\\(\\hat\\beta^L_{\\lambda} = \\text{min}_{\\beta}\\left[RSS+\\lambda\\sum_{j=1}^p|\\beta_j|\\right]\\)Instead of $\\mathcal{l}_2$ penalty in Ridge, the lasso uses an $\\mathcal{l}_1$ penalty. The $\\mathcal{l}_1$ norm of a coefficient vector $\\beta$ is given by $\\lVert \\beta \\rVert_1 = \\sum |\\beta_j|$. This penalty has the effect of forcing some of the coefficient estimates to be exactly equal to zero when the tuning parameter is sufficiently large. Hence, the lasso performs variable selection, these sparse models with the lasso are much easier to interpret than those with ridge.  Another Formulation for Ridge Regression and the Lasso      Ridge:\\(\\text{min}_{\\beta}\\left\\{ \\sum_{i=1}^n(y_i-\\beta_0-\\sum_{j=1}^p\\beta_j x_{ij})^2                       \\right\\}\\) subject to $\\sum_{j=1}^p\\beta_j^2 \\le s $Lasso:\\(\\text{min}_{\\beta}\\left\\{ \\sum_{i=1}^n(y_i-\\beta_0-\\sum_{j=1}^p\\beta_j x_{ij})^2                       \\right\\}\\) subject to $\\sum_{j=1}^p|\\beta_j| \\le s $where the budget s as the regularization parameter ($\\lambda\\uparrow \\equiv s\\downarrow$).        when $p = 2$, then the ridge regression estimates have the smallest RSS out of all points that lie within the circle defined by $\\beta_1^2 + \\beta_2^2 \\le s$, while the lasso estimates have within the diamond defined by $|\\beta_1|+|\\beta_2| \\le s$. when $p = 3$, he constraint region for ridge becomes a sphere, for lasso becomes a polyhedron. For larger p, it becomes a hypersphere and a polytope each. The lasso leads to feature selection due to the sharp corners of its constraint region.        the number of predictors that is related to the response is never known a priori for real data sets. A technique such as cross-validation can be used in order to determine which approach is better on a particular data set.  A Simple Special Case      An analytical method(solution) for the case when $n = p$, and X a diagonal matrix with 1’s on the diagonal and 0’s in all off-diagonal elements. I.e., the columns of X are orthogonal. Also, assume that we are performing regression without an intercept(or standardized).(c.f. in real world cases, we need to use numerical methods.)        The usual least squares, $\\hat\\beta$ is that minimizes; $\\sum_{j=1}^p(y_j-\\beta_j)^2$.and for the ridge, minimizing $\\sum_{j=1}^p(y_j-\\beta_j)^2+\\lambda\\sum_{j=1}^p\\beta_j^2$.and for the lasso, minimizing $\\sum_{j=1}^p(y_j-\\beta_j)^2+\\lambda\\sum_{j=1}^p|\\beta_j|$.        The ridge regression estiamtes $\\hat\\beta_j^R = y_j/(1+\\lambda)$ and\\(\\text{the lasso estimates} \\begin{align*}\\hat\\beta_j^L &amp;= \\text{sign}(\\hat\\beta_j)(|\\hat\\beta_j|-\\lambda)_{+}, \\\\    \\text{or} &amp;= \\begin{cases}                  y_j - \\lambda/2, &amp; \\mbox{if }y_j &gt; \\lambda/2; \\\\                  y_j + \\lambda/2, &amp; \\mbox{if }y_j &lt; -\\lambda/2; \\\\                  0\t\t\t\t &amp; \\mbox{if }|y_j| \\le \\lambda/2.                  \\end{cases}\\end{align*}\\)Ridge shrinks all coefficients towards zero by the same “proportion”,Lasso shrinks all coefficients towards zero by the same “amount”.  Bayesian Interpretation  $p(\\beta|X,Y)\\propto f(Y|X,\\beta)p(\\beta|X) = f(Y|X,\\beta)p(\\beta)$with assumption of $p(\\beta)=\\prod_{j=1}^p g(\\beta_j)$ for some density function g.Two special cases of g:          If g is a Gaussian distribution with mean zero and standard deviation a function of $\\lambda$, it follows that the posterior mode for $\\beta$, is given by the ridge regression solution. Also, the solution is equal to posterior mean.      If g is a double-exponential(Laplace) distribution with mean zero and scale parameter a function of $\\lambda$, it follows that the posterior mode for $\\beta$ is the lasso soultion(which is not the posteriror mean in this case).        Hence, the lasso expects a priori that many of the coefficients are (exactly) zero, while ridge assumes the coefficients are randomly distributed about zero.6.3. Dimension Reduction Methods      p predictors to M new transformed variables.Let $Z_m = \\sum_{j=1}^p\\phi_{jm}X_j$ represent M &lt; p linear combinations of original p predictors. Then fit the linear regression model $y_i = \\theta_0 + \\sum_{m=1}^M\\theta_m z_{im} + \\epsilon_i, \\quad i = 1, \\ldots, n$, using least squares. If the constants $\\phi_{1m}, \\ldots, \\phi_{pm}$ are chosen wisely, dimension reduction approaches can outperform least squares regression. I.e., using least squares, fitting reduced model can lead to better results than fitting the standard linear model.        \\(\\sum_{m=1}^M\\theta_m z_{im} = \\sum_{m=1}^M\\theta_m\\sum_{j=1}^p\\phi_{jm}x_{ij} =   \\sum_{j=1}^p\\sum_{m=1}^M\\theta_m\\phi_{jm}x_{ij} = \\sum_{j=1}^p\\beta_j x_{ij},\\)  where \\(\\beta_j = \\sum_{m=1}^M\\theta_m\\phi_{jm}\\).  Hence, this model can be a special case of the standard linear regression model. In situations where   p is large relative to n, demension reduction methods can significantly reduce the variance of the   fitted coefficients. If $M = p$, and all the $Z_m$ are linearly independent, then there are no constraints   and the model is equivalent to the standard linear model.        All dimension reduction methods work in two steps. First, the transformed predictors $Z_m$ are obtained.   Second, the model is fit using these M predictors. The choice of $Z_m$, which is, the selection of the   $\\phi_{jm}$’s can be achieved in different ways.  6.3.1.  Principal Components RegressionPrincipal Components Analysis      Goal of PCA:  PCA is a technique for reducing the dimension of an n by p data matrix X, finding small number   of dimensions M, which have simillar amount of information to original p predictors.        The principal component direction of the data is that along which the observations vary the most;   with the largest variance of the observations projected onto. The principal component vector $Z_m$   defines the line that is as close as possible to the data, minimizing the sum of the squared   perpendicular distances between each point and the line. In other word, the principal component appears   to capture most of the information contained in two variables.        e.g. in the first principal component,    total variance keeped: $Var(X_1)+Var(X_2) = Var(PC_1)+Var(PC_2)$        where $X_s$ is $n \\times p$ standardized matrix,jth Principal Component Vector of $X_s$: $z_j = X_s v_j$,   $\\quad j=1,\\ldots,p$ is that satisfying \\(\\text{max}_{\\alpha}Var(X_s\\alpha)\\) subject to \\(\\lVert\\alpha\\rVert=1\\).   Here, the values of $z_{1j}, \\ldots, z_{nj}$ are known as the principal component scores.  $v_j$ is $p \\times 1$ size eigenvector of $X_s^T X_s$ corresponding to the jth largest eigenvalue,   and $\\alpha$ is $v_j$’s orthogonality to $v_1,\\ldots,v_{j-1}$ ($\\alpha^T S v_k = 0$, where S is the   sample covariance matrix of $X_s$, or $X_s^T X_s$, and $k = 1, \\cdots, j-1$).  Then $z_1 = X_s v_1$, $z_2\\bot z_1$, $z_3\\bot z_1,z_2$, $\\cdots$, $z_p\\bot z_1,\\ldots,z_{p-1}$.        derivation  Since $X_s$ is standardized matrix,  \\(Var(X_s\\alpha) = \\alpha^T X_s^T X_s\\alpha\\)  by Lagrangian form,  \\(\\begin{align*}  \\text{max}_{\\alpha}Q(X_s,\\lambda) &amp;= \\text{max}_{alpha}\\left[\\alpha^T X_s^T X_s\\alpha                                                              -\\lambda\\alpha^T\\alpha \\right] \\\\  \\rightarrow \\frac{\\partial Q}{\\partial\\alpha} &amp;= 2X_s^T X\\alpha - 2\\lambda\\alpha \\\\  \\text{for } \\hat\\alpha, X_s^T X\\alpha &amp;= \\lambda\\alpha  \\end{align*}\\)  note that $\\mathbb{A}_v = ev$, the combination of eigenvalue and eigenvector of $\\mathbb{A}$.  Thus, $\\alpha = v_j$, the jth eigenvector of $X_s^T X_s$, that is, the constraint of orthogonality   is satisfied.        Since PCA has no single solution M;  the proportion of variance explained by mth PC($Z_m$) used:  \\(PVE_m = \\frac{Var(Z_m)}{\\sum_{j=1}^p(Var(Z_j))}\\)  (\\(\\sum_{j=1}^p(Var(Z_j)) = \\sum Var(X_j) =\\) total variance)        in SVD of covariance matrix $X^T X$,  \\(\\begin{align*}  X^T X &amp;= \\mathbb{VDU}^T\\mathbb{UDV}^T \\\\        &amp;= \\mathbb{VD^2 V}^T  \\end{align*}\\)  in this eigen decomposition,  \\(\\mathbb{V} = (v_1,\\ldots,v_p)\\) the eigen vectors of $X^T X$  \\(\\mathbb{D}^2 = \\begin{bmatrix}                      d_1^2 &amp; \\cdots &amp; 0 \\\\                      \\vdots &amp; \\ddots &amp; \\vdots \\\\                      0 &amp; \\cdots &amp; d_p^2                      \\end{bmatrix}\\)                      $d_j^2 = e_j$, jth eigenvalue of $X^T X$  thus,  \\(\\begin{align*}  Var(Z_m) &amp;= \\frac{1}{n}(Z_m^T Z_m) \\\\           &amp;= \\frac{1}{n}(v_m^T X_s^T X_s v_m) \\\\           &amp;= \\frac{1}{n}(v_m^T\\mathbb{VD}^2\\mathbb{V}^T v_m) \\\\           &amp;= \\frac{1}{n}d_m^2 = \\frac{1}{n}e_m  \\end{align*}\\)        Therefore,  \\(PVE_m = \\frac{Var(Z_m)}{\\sum_{j=1}^p(Var(Z_j))} = \\frac{e_m}{\\sum_{j=1}^p e_j}\\)  we can draw a scree plot on the value of $PVE_m$ over the value of m to find optimal “M”.  The Principal Components Regression Approach      The key idea is that a small number of principal components can explain most of the variability in the   data, as well as the relationship with the response. Under this assumption, fitting a least squares model   to $Z_1, \\ldots, Z_M$ will lead to better results than fitting a least squares model to $X_1, \\ldots, X_p$,   since most or all of the information in the data is contained in $Z_m$ and there are smaller number of   coefficients, we can mitigate overfitting.        Note that PCR is not a feature selection method; is a linear combination of all p of the original features.   In this sense, PCR is more closely related to ridge regression than to the lasso.        Deciding “M”:  full model is \\(\\hat{Y} = \\hat{\\theta}_0 + \\hat{\\theta}_1 Z_1 + \\cdots + \\hat{\\theta}_p Z_p\\)  when $Z_1,\\ldots,Z_m$ is from standardized $X_s$ and \\(\\hat{y}_0 = \\bar{y}\\),  as $Z_j$’s are orthogonal, adding variable $Z_{j+1}$ does not affect the coefficients. Thus, $\\theta_j$’s are   not changed by feature selection; that is,  \\(\\hat{Y} = \\hat{\\theta}_0 + \\hat{\\theta}_1 Z_1 \\\\  \\hat{Y} = \\hat{\\theta}_0 + \\hat{\\theta}_1 Z_1 + \\hat{\\theta}_2 Z_2 \\\\  \\vdots \\\\  \\hat{Y} = \\hat{\\theta}_0 + \\hat{\\theta}_1 Z_1 +\\cdots + \\hat{\\theta}_p Z_p\\) the value of $\\theta_k$ is the same.  Then we can use CV methods over these models to get optimal M.  6.3.2. Partial Least Squares      The PCR approach identifies linear combinations, or directions, that best represent the predictors.   These directions are identified in an unsupervised way, since the response Y is not used to help   determine the principal component directions. There, PCR suffers from a drawback: there is no guarantee   that the directions that best explain the predictors will also be the best directions to use for   predicting the response.        PLS is a supervised alternative to PCR; finding PLS directions $Z_1,\\ldots,Z_m$ that   $Cov(Y,Z_1)\\ge Cov(Y,Z_2)\\ge\\cdots\\ge Cov(Y,Z_M)$ instead of $Var(Z_1)\\ge\\cdots\\ge Var(Z_M)$.        First PLS direction is computed, after standardizing predictors, by setting each $\\phi_{j1}$ equal to   the coefficient from the simple linear regression $Y$ onto $X_j$. As $Z_1 = \\sum_{j=1}^p\\phi_{j1}X_j$,   PLS places the highest weight on the variables that are most strongly related to the response.  To find second PLS direction, we adjust each of the variables for $Z_1$, by regressing each variable   on $Z_1$ and taking residuals. The residuals can be interpreted as the remaining information that has   not been explained by the first PLS direction. Then we compute $Z_2$ using this orthogonalized data by   the same way of computing $Z_1$. This predecure repeated M times.        in Simple Regression case,  $\\hat X_j^s$ is a projection of original data $X_j^s$ to a vector $Z_1$; $X_j^s = \\alpha Z_1$.  the residual vector $r_j = \\hat X_j^s - X_j^s$ and $r_j\\bot Z_1$.  Then, $r_j = X_j^{(2)}$ is the orthogonalized data for computing the next $Z_2$.        The mth PLS direction:  \\(\\text{max}_{\\phi} Cov(y,X_s\\phi)\\) subject to $\\lVert\\phi\\rVert = 1$, $\\phi^T S v_l = 0$  for $\\phi$ as orthogonal directions, sample covariance matrix S, and $v_l$ as l th PLS direction.  \\(\\text{max}_{\\phi}[E(\\phi^T X_s^T y)-E(y)E(\\phi^T X_s)]\\), as standardized, $E(X_s) = 0$,  \\(\\equiv \\text{max}_{\\phi}\\phi^T \\dot X_s^T y\\) is maximization of dot product of 2 vectors.  note that, when two vectors are in the same direction, dot product is maximized.  $\\therefore \\phi=X_s^T y$.  6.4. Considerations in High Dimensions6.4.1. High-Dimensional Data  Data sets that containing more features than observations, $p &gt; n$.6.4.2. What Goes Wrong in High Dimensions?  Standard least squares cannot be performed. Regardless of the true relationship between features and response,   least squares will result in a perfect fit to the data, lead to overfitting of the data and poor   predictions.6.4.3. Regression in High Dimensions  new technologies that allow for the collection of measurements for thousands or millions of features   are a double-edged sword: they can lead to improved predictive models if these features are in fact   relevant to the problem at hand, but will lead to worse results if the features are not relevant.   Even if they are relevant, the variance incurred in fitting their coefficients may outweigh the   reduction in bias that they bring.6.4.4. Interpreting Results in High Dimensions      In high-dimensional setting, the multicollinearity problem is extreme:  any variable in the model is a linear combination of all of the other variables in the model. This means   we can never know exactly which variables truly are predictive of the outcome, and we can never identify   the best coefficients for use in the regression.        When $p &gt; n$, it is easy to obtain a a useless model that has zero residuals. Therefore, we should never   use sum of squared errors, p-values, $R^2$ statistics, or other traditional measures of model fit on the   training data as evidence of a good model fit. Instead we report results on an independent test set, or   cross-validation errors.  ",
        "url": "/islr_ch6"
    }
    ,
    
    "islr-ch5": {
        "title": "ISLR - Chapter 5. Resampling Methods",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 5. Resampling Methods  5.1.  Cross-Validation          5.1.1. The Validation Set Approach      5.1.2. Leave-One-Out Cross-Validation      5.1.3. k-Fold Cross-Validation      5.1.4. Bias-Variance Trade-Off for k-Fold Cross-Validation      5.1.5. Cross-Validation on Classification Problems        5.2. The BootstrapChapter 5. Resampling Methods      repeatedly drawing samples from a training set and refitting a model of interest on each sample in order to obtain additional information about the fitted model.        To optain information that would not be available from fitting the model only once using the original training sample.e.g. to estimate the variability of a model fit, draw different samples and fit it to each new sample, then examine the extent to which the resulting fits differ.  5.1.  Cross-Validation  In the absence of a very large designated test set that can be used to directly estimate the test error rate, a class of methods that estimate the test error rate by holding out a subset of the training observations from the fitting process, then applying the statistical learning method to those held out observations.5.1.1. The Validation Set Approach      randomly dividing the available set of observations into two parts;a training set and a validation set (or hold-out set)model is fit on the training set, and the fitted model is used to predict the responses for the observations in the validation set. The validation set error rate estimates the test error rate.        Repeating this predecure, we have different estimate for the test MSE over random splits of the observations and there are two issues:          The validation estimate of the test error rate can be highly variable, depending on which observations  are included in the training set or the validation test.      Only a subset of the observations are used to fit the model. Trained on fewer observations, the  validation set error rate may overestimate the test error rate for the model fit on the entire  data set.      5.1.2. Leave-One-Out Cross-Validation      each single observation is used for the validation set, and the remaining observations are for the training set. The statistical learning method is fit on the n-1 training obs. The prediction is made for the excluded observation.        LOOCV estiamte for the test MSE:\\(CV_{(n)} = \\frac{1}{n}\\sum_{i=1}^n MSE_i\\)No overestimation on the test error, No variance of test MSE, but Expansive.        a shortcut of LOOCV on Least Squares(regression):\\(\\begin{align*}CV_{(n)} = \\frac{1}{n} \\sum_{i=1}^n \\left(\\frac{y_i - \\hat y_i}{1-h_i}\\right)^2\\end{align*}\\)where $\\hat y_i$ is the fitted value from the original least squares fit, one-time build of a full model and set a leverage $h_i = \\frac{1}{n}+\\frac{(x_i-\\bar{x})^2}{\\sum_{i^\\prime=1}^n(x_{i^\\prime}-\\bar{x})^2}$. The levearge lies between 1/n and 1, reflects the amount that an observation influences its own fit.  5.1.3. k-Fold Cross-Validation      random division into k groups, or folds, of approximately equal size. A fold is used for the validation set, and the method is fit on the remaining k-1 folds. The MSE is computed on the observations in the held-out fold and the procedure is repeated k times.        k-Fold CV estimate for the test MSE:\\(CV_{(k)} = \\frac{1}{n}\\sum_{i=1}^k MSE_i\\)when k=n, LOOCV is a special case of k-Fold. Using smaller k, k-fold CV has a computational advantage to LOOCV.        We perform CV to:To determine how well a given model can be expected to perform on independent data.To identify a model results in the lowest test error, over different models or different levels of flexibility.  5.1.4. Bias-Variance Trade-Off for k-Fold Cross-Validation      Besides the computational advantage, k-fold CV often gives more accurate estimates of the test error rate than does LOOCV.        LOOCV will give approximately unbiased estiamtes of the test error, containing n-1, almost as many as the number of observations in the full data set. By contrast, k-fold CV will lead to an intermediate level of bias, containing (k-1)n/k observations. Clearly, LOOCV is to be preferred in the perspective of bias reduction.        But, in LOOCV, averaging the outputs of n fitted models, which are trained on an almost identical set of observations, these outputs are highly correlated with each other. This high correlation results in higher variance of test error estimate from LOOCV than from k-fold CV.  5.1.5. Cross-Validation on Classification Problems      LOOCV on the classification:\\(CV_{(n)} = \\frac{1}{n}\\sum_{i=1}^n Err_i\\),  where \\(Err_i = I(y_i \\ne \\hat{y}_i)\\).        k-fold CV on the classification:\\(\\frac{1}{n}\\sum_{i=1}^k MCR_i\\).  5.2. The Bootstrap      Sampling with replacement on:Dataset $Z = (z_1, \\ldots, z_n)$, $ z_i = (x_i,y_i)$Sample $Z^{*b}$, where $ b = 1, \\ldots, B$ samples        for Any statistic term $S(Z)$ computed from full dataset Z,and $S(Z^{*b})$ from bootstrap samples,\\(\\begin{align*}Var(\\hat{S(Z)}) = \\frac{1}{B-1}\\sum_{b=1}^B(S(Z^{*b})-\\bar{S}^*)^2\\end{align*}\\)$\\cdots \\bar{S}^{*} = \\frac{1}{B}\\sum_{b=1}^B S(Z^{*b})$  ",
        "url": "/islr_ch5"
    }
    ,
    
    "islr-ch4": {
        "title": "ISLR - Chapter 4. Classification",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 4. Classification  4.1. Overview of Classification  4.2. Why Not Linear Regression?  4.3. Logistic Regression          4.3.1. The Logistic Model      4.3.2. Estimating the Regression Coefficients: MLE      4.3.3. Multinomial Logistic Regression        4.4. Generative Models for Classification          4.4.1. LDA: Linear Discriminant Analysis for $p = 1$      4.4.2. LDA: Linear Discriminant Analysis for $p &gt; 1$      4.4.3. QDA: Quadratic Discriminant Analysis      4.4.4. Naive Bayes        4.5. A Comparison of Classification Methods          4.5.1. An Analytical Comparison      4.5.2. An Empirical Comparison        4.6. Generalized Linear Models          4.6.1. Linear Regression Problems      4.6.2. Poisson Regression      4.6.3. Generalized Linear Models in Greater Generality      2020-04-15Chapter 4. Classification4.1. Overview of Classification  Response Y is qualitative(categorical) variable.Predicting a qualitative response, classification4.2. Why Not Linear Regression?  Problem of linear regression in classificatione.g. in binary response group: Y = 0 or 1Model prediction: $\\hat y_i = x_i^T \\hat\\beta$; $\\quad$ where $\\beta$ is LSEDecision rule: if $ \\hat y_i &gt; 0.5 $, classify ith obs. to group 1BUT, possible value of estimates outside the interval,$ \\hat Y &gt;1 \\text{ or } \\hat Y &lt;0 $: do not fit for the range of Y4.3. Logistic Regression4.3.1. The Logistic Model      Supoose that Y has 2 classes where$p(X)=P(Y=1|X)$, $X=(1,X_1, \\ldots, X_p)^T$, $\\beta=(\\beta_0,\\beta_1,\\ldots, \\beta_p)^T$        \\(p(X)= \\frac{e^{x^T\\beta}}{1+e^{x^T\\beta}}\\): logistic function\\(0 &lt; \\frac{p(X)}{1-p(X)} = e^{x^T\\beta} &lt; \\infty\\): odds relative to range of $p(X)= [0,1]$\\(\\log\\frac{p(X)}{1-p(X)} = X^T \\beta\\): log odds or logit  4.3.2. Estimating the Regression Coefficients: MLE      as $\\log\\frac{p(X)}{1-p(X)} = X^T \\beta $, $ p(X) = \\frac{e^{x^T\\beta}}{1+e^{x^T\\beta}} $, $ e^{x^T\\beta} = \\frac{p(X)}{1-p(X)}$where $Y_i | X_i \\sim$ Bernoulli($p(X_i)$),$\\rightarrow \\prod_{i=1}^N p(x_i)^{y_i} (1-p(x_i))^{1-y_i}$likelihood function L = $\\prod_{i:y_i=1}p(x_i) \\prod_{i:y_i=0}(1-p(x_i))$        Maximum Likelihood Estimation MLE:\\(\\hat\\beta = \\text{max}_\\beta [\\prod_{i:y_i=1} \\frac{e^{x^T\\beta}}{1+e^{x^T\\beta}} \\prod_{i:y_i=0} \\frac{1}{1+e^{x^T\\beta}}]\\)take log and get log-likelihood function $l(\\beta)$ and least squares $\\hat\\beta$        But we cannot find analytic solution for $\\frac{\\partial l(\\beta)}{\\partial\\beta} = 0$,use Newton-Raphson method, a numerical method to find $\\hat\\beta$.        if $\\hat\\beta &gt;0$ , p(X) increases by a unit change in Xif $\\hat\\beta &lt;0$ , p(X) decreases by a unit change in X(not a linear relationship, but a direction)  4.3.3. Multinomial Logistic Regression      $P(Y=k | X=x) = \\frac{e^{x^T\\beta_k}}{1+\\sum_{j=1}^{K-1} e^{x^T\\beta_j}}$$P(Y=K | X=x)= \\frac 1{1+\\sum_{j=1}^{K-1} e^{x^T\\beta_j}}$        $\\log\\frac{P(Y=k | X=x)}{P(Y=K | X=x)} = x^T\\beta_k $for $ k=1,\\cdots, K-1$ with $\\sum_{k=1}^K P(Y=k | X=x) = 1 $the choice of denominator the $K_{th}$ class is arbitary        ML estimation (by numerical method):we can have K-1 equations and K-1 number of $\\hat\\beta_k$ (MLE)  4.4. Generative Models for Classification      By logistic regression directly modeling $Pr(Y=K | X=x)$,in statistical jargon, we model the conditional distributionof the response Y, given the predictor(s) X.    then Why do we need another method?          when there is substantial separation between 2 classes and logistic model’s parameter estimates are unstable      when X approximately follow normal distribution and the sample size is small      in the case of more than two response classes            In Generative approach, we model the distribution of the predictors X separately to the response class then use Bayes’ theorem to get $Pr(Y=K | X=x)$.if X for each Ys assumed to follow the normal distribution,model has very similar form to logistic regression.        Suppose that we classify an obs. into one of K$\\ge 2 $ classes$f_k(x)$; is the density funtion of X in class k,$\\pi_k$; is the prior probability of class k with $\\sum_{k=1}^K \\pi_k =1$    Bayes’ Theorem$ Pr(Y=k | X=x) = \\frac{\\pi_k f_k(x)}{\\sum_{l=1}^K \\pi_l f_l(x)}$$ Pr(Y=k | X=x) $ is the posterior probability of obs. at x belongs to k4.4.1. LDA: Linear Discriminant Analysis for $p = 1$  Assumptions:a Gaussian or normal distribution $f_k(x)$          $f_k(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma_k}exp\\left(-\\frac{1}{2\\sigma_k^2}(x-\\mu_k)^2\\right)$      $\\mu_k$ is the mean for the kth class      $\\sigma_k^2$ is the shared variance across for all K classes(=$\\sigma^2$)      $p_k(x) = \\frac{\\pi_k \\frac{1}{\\sqrt{2\\pi}\\sigma}exp\\left(-\\frac{1}{2\\sigma^2}(x-\\mu_k)^2\\right)}              {\\sum_{l=1}^K \\pi_l \\frac{1}{\\sqrt{2\\pi}\\sigma}exp\\left(-\\frac{1}{2\\sigma^2}(x-\\mu_l)^2\\right)}$            Bayes Classifier assigns an observation X = x to the classhaving lagest value of: \\(\\delta_k(x) = x\\cdot\\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + \\log(\\pi_k)\\)        But in real-life situation,such assumptions are not enough to apply the Bayes classifier.have to estimate the parameters $\\mu_1,\\ldots,\\mu_K,\\ \\pi_1,\\ldots,\\pi_K$ and $\\sigma^2$$\\rightarrow$ LDA method used to approximate the Bayes classifier.        LDA estimates model parameters:$\\hat\\pi_k = n_k/n$$\\hat\\mu_k = \\sum_{i:y_i=k}x_i / n_k $\\(\\begin{align*}\\hat\\sigma_k^2 = \\sum_{k=1}^K\\sum_{i:y_i=k}(x_i-\\hat\\mu_k) / (n-K) \\end{align*}\\)    LDA classifier assigns an observation X = x to the classhaving lagest value of discriminant function: \\(\\hat\\delta_k(x) = x\\cdot\\frac{\\hat\\mu_k}{\\hat\\sigma^2} - \\frac{\\hat\\mu_k^2}{2\\hat\\sigma^2} + \\log(\\hat\\pi_k)\\)4.4.2. LDA: Linear Discriminant Analysis for $p &gt; 1$  Assumptions:X from a multivariate Gaussian(or multivariate normal) distribution,where each individual predictor follows a one-dimensional normal distribution,with a class-specific mean vector and a common covariance matrix          $f_k(x) ~ \\text{MVN}(\\mu_k,\\Sigma_k)$      $\\mu_k$ is a $p \\times 1$ vector, the mean for the kth class      $\\Sigma_k = \\Sigma$ is a $p \\times p$ covariance matrix for all K classes            Find k maximizing \\(\\log P(Y=k|X=x)\\):\\(\\begin{align*} \\log P(Y=k|X=x) &amp;= \\log\\frac{f_k(x)\\pi_k}{\\sum_{j=1}^K f_j(x)\\pi_j}\\\\                    \t\t\t   &amp;= \\log(f_k(x)\\pi_k) + C_1 \\\\                                 &amp;= \\cdots \\\\                                 &amp;= \\log\\pi_k - \\frac{1}{2}\\mu_k^T\\Sigma^{-1}\\mu_k + x^T\\Sigma^{-1}\\mu_k + C_3\\\\                                 &amp;= \\delta_k(x) + C_3 \\cdots \\scriptstyle\\text{ : Linear discriminant function (linear in X)} \\\\              \\Rightarrow \\hat Y &amp;= \\text{argmax}_k \\delta_k(x)\\end{align*}\\)        Decision boundary is also in a linear form.when solving x: $\\delta_k(x) = \\delta_l(x)$, we can have linear form of decision boundary.        LDA estimates model parameters:$\\hat\\pi_k = n_k/n$$\\hat\\mu_k = \\sum_{i:y_i=k}x_i / n_k $\\(\\begin{align*}\\hat\\Sigma_k = \\sum_{k=1}^K\\sum_{y_i=k}(x_i-\\hat\\mu_k)(x_i-\\hat\\mu_k)^T / (n-K) \\end{align*}\\)        ROC curve, receiver operating characteristicsto display two types of errors for all possible thresholdsuseful for comparing different classifiers        AUC, area under the (ROC) curveoverall performance of a classifier summarized over all possible thresholds    sensitivity and specificity, from confusion matrixchanges of true positive and false positive rate by varying the classifier threshold4.4.3. QDA: Quadratic Discriminant Analysis      Assumption: Same as LDA, but “$\\Sigma_k \\ne \\Sigma$” for all K classes        Quadratic discriminant function:$\\delta_k(x)=  \\log\\pi_k - \\frac{1}{2}\\log| \\Sigma_k | - \\frac{1}{2}(x-\\mu_k)^T\\Sigma^{-1}(x-\\mu_k) $        Decision boundary is in quadratic line.        Estimation of parameters:$\\hat\\pi_k = n_k/n$$\\hat\\mu_k = \\sum_{y_i=k}x_i / n_k $\\(\\begin{align*}\\hat\\Sigma_k =\\sum_{y_i=k}(x_i-\\hat\\mu_k)(x_i-\\hat\\mu_k)^T / (n-1) \\end{align*}\\) (only obs. in $k_{th}$ group)    LDA vs. QDA: the bias-variance trade-off          LDAfor p predictors, covariance matrix requires estimating $p(p+1)/2$ parameters.linear model in x, which means there are $Kp$ linear coefficientsless flexible classifier having lower variance and potential of improved prediction performancebut with assumption of shared variance, LDA can suffer from high biaswhen there are relatively few training observations and reducing variance is crucial      QDAfor p predictors, estimating seperate covariance matrix requires estimating $Kp(p+1)/2$ parameters.when there are very large training set, the variance of the classifier is not a major concernor there is no common covariance matrix for the K classes        LDA vs. Logistic Regression          LDA:MVN assumption neededQualitative(categorical) inputs are not available      Logistic:No assumption needed and Y ~ Bernoulli is evident; $\\rightarrow$ robust modelQualitative are availablecan run F-test to choose more important features      4.4.4. Naive Bayes      Bayes’ theorem expands posterior prob. $p_k(x) = Pr(Y=k|X=x)$ with two terms:$\\pi_k$ is a prior prob. that an observation belongs to kth class$f_k(x)$ is a p-dim. density function for an observation in the kth class        Estimations:$\\hat\\pi_k$ as the proportion of training observations belonging to the kth class.$\\hat{f}_k(x)$ is more challenging, as we must consider both marginal and jointdistribution of predictors, in a multivariate normal distribution, the joint distributionis summarized by the off-diagonal elements of the covariance matrix, but this associationis still hard to be characterized.    to simplifies task:          LDA assumes,MVN distribution $f_k(x)$ with class-specific mean and shared variance      QDA assumes,MVN distribution $f_k(x)$ with class-specific mean and class-specific variance      naive Bayes assumes,Within the $k$th class, the $p$ predictors are independent, or,$f_k(x) = f_{k1}(x_1) \\times f_{k2}(x_2) \\times \\cdots \\times f_{kp}(x_p)$ where$f_{kj}$ is the density function of the jth predictor among observations in the kth class.a simple assumption that there is NO association between the predictors            the posterior probability $p_k(x)$$Pr(Y=k|X=x) = \\frac{\\pi_k\\times f_{k1}(x_1)\\times f_{k2}(x_2)\\times\\cdots\\times f_{kp}(x_p)}                    {\\sum_{l=1}^K\\pi_l}\\times f_{l1}(x_1)\\times f_{l2}(x_2)\\times\\cdots\\times f_{lp}(x_p)$    To estimate the one-dimensional density function $f_{kj}$:          for quantitative $X_j$, we can assume that $X_j|Y = k \\sim N(\\mu_{jk}, \\sigma_{jk}^2)$within each class, the jth predictor $X_j$ is drawn from a normal distribution      for quantitative $X_j$, or, we use a non-parametric estimate for $f_{kj}$estimate $f_{kj}(x_j)$ as the fraction of the training observations in the kth classthat belong to the same histogram bin as $x_j$,or we can use a kernel density estimator instead of histogram      for qualitative $X_j$, we can simply count the proportion of training observationsfor the jth predictor corresponding to each class.      4.5. A Comparison of Classification Methods4.5.1. An Analytical Comparison  analytical (or mathematical) comparison of LDA, QDA, naive Bayes, and logistic regressionin a setting K as the baseline class and classify to the class that maximizes\\(log\\left(\\frac{Pr(Y=k|X=x)}{Pr(Y=K|X=x)}\\right)\\)          LDA:\\(\\begin{align*}\\log\\left(\\frac{Pr(Y=k|X=x)}{Pr(Y=K|X=x)}\\right)&amp;= \\log\\left(\\frac{\\pi_k f_k(x)}{\\pi_K f_K(x)}\\right) \\\\&amp;= \\log\\left(\\frac{\\pi_k exp(-\\frac{1}{2}(x-\\mu_k)^T\\Sigma^{-1}(x-\\mu_k))}                 {\\pi_K exp(-\\frac{1}{2}(x-\\mu_K)^T\\Sigma^{-1}(x-\\mu_K))}\\right) \\\\&amp;= \\log\\left(\\frac{\\pi_k}{\\pi_K}\\right) - \\frac{1}{2}(\\mu_k+\\mu_K)^T\\Sigma^{-1}(\\mu_k-\\mu_K) \\\\&amp;\\quad + x^T\\Sigma^(\\mu_k-\\mu_K)\\\\&amp;= a_k + \\sum_{j=1}^p b_{kj}x_j,\\end{align*}\\)where $b_jk$ is the jth component of $\\Sigma^{-1}(\\mu_k-\\mu_K)$      QDA:\\(\\log\\left(\\frac{Pr(Y=k|X=x)}{Pr(Y=K|X=x)}\\right)= a_k + \\sum_{j=1}^p b_{kj}x_j + \\sum_{j=1}^p\\sum_{l=1}^p c_{kjl}x_j x_l\\)      naive Bayes:\\(\\begin{align*}\\log\\left(\\frac{Pr(Y=k|X=x)}{Pr(Y=K|X=x)}\\right)&amp;= \\log\\left(\\frac{\\pi_k f_k(x)}{\\pi_K f_K(x)}\\right) \\\\&amp;= \\log\\left(\\frac{\\pi_k\\prod_{j=1}^p f_{kj}(x_j)}                 {\\pi_K\\prod_{j=1}^p f_{Kj}(x_j)}\\right) \\\\&amp;= \\log\\left(\\frac{\\pi_k}{\\pi_K}\\right)    + \\sum_{j=1}^p\\log\\left(\\frac{f_{kj}(x_j)}{f_{Kj}(x_j)}\\right) \\\\&amp;= a_k + \\sum_{j=1}^p g_{kj}(x_j)\\end{align*}\\)which takes the form of a generalized additive model      Logistic Regression:\\(\\log\\left(\\frac{Pr(Y=k|X=x)}{Pr(Y=K|X=x)}\\right)= \\beta_{k0} + \\sum_{j=1}^p\\beta_{kj}x_j\\)        LDA is a special case of QDA with $c_{kjl}=0$ and including any classifier with linear decision boundary, is also a special case of naive Bayes with $g_{kj}(x_j) = b_{kj}(x_j)$,if in the naive Bayes classifier, we model $f_{kj}(x_j)$ using a one-dimensional Gaussian distribution $N(\\mu_{kj},\\sigma_j^2)$, we get $g_{kj}(x_j) = b_{kj}(x_j)$ where $b_{kj} = (\\mu_{kj}-\\mu_{Kj})/{\\sigma_j^2}$. Then naive Bayes is a special case of LDA with variance restriced to be a diagonal matrix with jth diagonal element equal to $\\sigma_j^2$.  Neither QDA nor naive Bayes is a special case of the other.Navie Bayes is in a additive fit, a function of $x_j$ can be added but never multipied. By contrast, QDA takes terms of $c_{kjl}x_j x_l$.  both LDA and Logistic are linear function of the predictors. Predictors in LDA follow a normal distribution, while the coefficients in Logistic are chosen to maximize the likelihood function. LDA outperforms when the normality assumption holds and vice versa for Logistic.  KNN outperforms LDA and Logistic when the decision boundary is highly non-linear provided with large n obs. to small p. KNN tends to reduce bias while incurring a lot of variance.  QDA may be preferrend to KNN when decision boundary is non-linear but n is only modest, or p is not very small. Taking a parametric form, it requires a smaller sample size for accurate classification relative to KNN.4.5.2. An Empirical Comparison      empirical (practical) comparison of classification performances,we can draw boxplots of test error rates.        shortly, no one method will dominate the others in every situation.LDA and Logistic will tend to perform well when decision boundaries are linear. QDA or naive Bayes may be better in non-linear decision boundaries. KNN, non-parametric one is good for much more complicated decision boundaries.        Like in regression using transformations of the predictors, including powers of predictors, we could create a more flexible logistic regression or LDA model. Adding quadratic terms and cross-products to LDA, we can have a model at somewhere between an LDA and a QDA.  4.6. Generalized Linear Models  when Y is neither qualitative nor quantitative;a discrete variable Y takes on non-negative integer values, or countsand treat predictors X as qualitative variables.4.6.1. Linear Regression Problems  a linear regression model seems to provide reasonable and intuitive results on those Y, for example, compared to the clear weather as baseline, there should be negative coefficients to predict bike users on cloudy days and some lower values on rainy days.but there are some problems left in a linear model.      Negative fitted values relative to non-negative response Y. It raise concerns about  the accuracy of model; coefficient estimates, confidence intervals, and other outputs        Mean-variance violates the assumptions of linear model. We assumed error term $\\epsilon$ to  have zero mean and constant value of variance $\\sigma^2$, but in practice, the variance of  $Y_i$ has some definite relationship to the expectation of $Y_i$. This problem is from the  heteroscedasticity of the data.    A solution: transformed response $\\log(Y) = \\sum_{j=1}^p X_j\\beta_j + \\epsilon $It can avoids the possibility of negative predictions and overcomes much of the heteroscedasticity. But there may be a challenge in interpretation and in the fact that log transformation cannot be applied to the responses with the value of zero.Thus, we introduce a Poisson Regression.4.6.2. Poisson Regression      For a random variable Y takes on nonnegative integer values,introduces $\\lambda&gt;0, \\lambda = E(Y) = Var(Y)$;Poisson distribution $Pr(Y=k) = \\frac{e^{-\\lambda}\\lambda^k}{k!}$        a function of $ E(Y) = \\lambda $ of the covariates $X_j$:$\\log(\\lambda(X_1,\\ldots,X_p)) = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p$ or$\\lambda(X_1,\\ldots,X_p) = e^{\\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_p X_p}$predicting mean value of Y in particular conditions(values) of predictor $X_j$s        likelihood $l(\\beta_0,\\beta_1,\\ldots,\\beta_p)  = \\prod_{i=1}^n\\frac{e^{-\\lambda(x_i)}\\lambda(x_i)^{y_i}}{y_i !}$where $\\lambda(x_i) = e^{\\beta_0 + \\beta_1 x_{i1} + \\ldots + \\beta_p x_{ip}}$By solving MLE in this likelihood function, we can have similar fit to the response,while we have more statistical significance of coefficients.        Some important distinctions from the linear regression model.          Interpretation: a one-unit change in $X_j$ is associated with the change by a factor of   $ exp(\\beta_j) $, or $ e^{\\beta_j} $ in E(Y) = $\\lambda$.      Mean-variance relationship: under the introduced term $\\lambda = E(Y) = Var(Y)$, the   Poisson model is more adequate to the data with heteroscedasticity.      No nonnegative fitted values      4.6.3. Generalized Linear Models in Greater Generality  Common characteristics of Linear, Logistic, Poisson Regressions:          Use p predictors $X_j$ to predict a response Y and assume that conditional $P(Y|X)$   belongs to a certain family of distributions(Gaussian, Bernoulli, Poisson distribution).  $*$which are in exponential family(with exponential, Gamma, negative binomial distributions)      Modeling the mean of Y, or expected, $E(Y)$ as a function of predictors X.  $\\text{in Linear: } E(Y|X_1,\\ldots,X_p) = \\beta_0 + \\beta_1 X_1, + \\cdots + \\beta_p X_p$  \\(\\begin{align*}   \\text{in Logistic: } E(Y|X_1,\\ldots,X_p) &amp;= Pr(Y=1|X_1,\\ldots,X_p) \\\\                                        &amp;= \\frac{e^{\\beta_0 + \\beta_1 X_1, + \\cdots + \\beta_p X_p}}                                           {1+e^{\\beta_0 + \\beta_1 X_1, + \\cdots + \\beta_p X_p}}  \\end{align*}\\)  \\(\\begin{align*}  \\text{in Poisson: } E(Y|X_1,\\ldots,X_p) &amp;= \\lambda(X_1,\\ldots,X_p) \\\\                                       &amp;= e^{\\beta_0 + \\beta_1 X_1, + \\cdots + \\beta_p X_p}  \\end{align*}\\)  which can be expressed using a link function, $\\eta$, applying a transformation that   $\\eta(E(Y|X_1,\\ldots,X_p)) = \\beta_0 + \\beta_1 X_1, + \\cdots + \\beta_p X_p$  and each $\\eta(\\mu)$ is $\\mu, \\log(\\mu/(1-\\mu)), \\log(\\mu)$; respectively to models.        GLM, a general recipe of regression approach:with the response Y from one of the exponential family, transform expected Y(or mean) as a linear function of the predictors, we can have a regression model.",
        "url": "/islr_ch4"
    }
    ,
    
    "islr-ch3": {
        "title": "ISLR - Chapter 3. Linear Regression",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 3. Linear Regression  3.1. Simple Linear Regression          3.1.1. Estimating the Coefficients      3.1.2.  Assessing the Accuracy of the Coefficient Estimates      3.1.3. Assessing the Accuracy of the Model                  Residual Standard Error (RSE)          $R^2$ Statistics                      3.2. Multiple Linear Regression          3.2.1. Estimating the Regression Coefficients                  Ordinary Least Squares Estimator          Gauss-Markov Theorem          Properties of Good estimators                    3.2.2. Important Questions                  3.2.2.1. Hypothesis Test          3.2.2.2. Variable Selection          3.2.2.3. Model fit          3.2.2.4. Prediction Errors                      3.3. Other Considerations in Regression Model          3.3.1. Qualitative Predictors      3.3.2. Extensions of the Linear Model      3.3.3. Potential Problems        3.5. Comparison with K-Nearest NeighborsChapter 3. Linear Regression  input variable X can be:Quantitative or Transformations of quantitative inputsBasis expansions leading to polynomial representationDummy coding of qualitative variables: for G groups, G-1 dummy variables requiredInteractions between inputs ( $X_3 = X_1 \\cdot X_2$ )3.1. Simple Linear Regression      $Y \\approx \\beta_0 + \\beta_1 X$saying regressing Y on X,for predicting a quantitative response Yon the basis of a single predictor variable Xassumes a linear relationship between.        $\\beta$: model coefficients or parametersthis case, two unknown constants$\\beta_0$ = intercept$\\beta_1$ = slope  3.1.1. Estimating the Coefficients      for given data of n observastions: {$(x_1,y_1,), (x_2,y_2), \\ldots, (x_n,y_n)$}\\(\\hat{y}_i = \\hat\\beta_0 + \\hat\\beta_1 x_i\\) for prediction of Y on ith value of X,\\(e_i = y_i - \\hat{y}_i\\) for representation of ith residual,\\(\\bar{y} \\equiv \\frac{1}{n}\\sum_{i=1}^n y_i\\) and \\(\\bar{x} \\equiv \\frac{1}{n}\\sum_{i=1}^n x_i\\) are sample means        the least squares coefficient estimates\\(\\begin{align*}RSS &amp;= e_1^2 + e_2^2 + \\cdots + e_n^2 \\\\    &amp;= \\sum_{i=1}^n(y_i-\\beta_0-\\beta_1 x_i)\\end{align*}\\) is a square function of each coefficients $\\beta_0, \\beta_1$,then \\(\\frac{\\partial RSS}{\\partial\\beta_0} = -2\\sum(y_i - \\beta_0 - \\beta_1 x_i)\\)in least squares,\\(\\sum y_i - n\\hat\\beta_0 - \\sum\\hat\\beta_1 x_i = 0\\)\\(\\begin{align*}\\Leftrightarrow \\hat\\beta_0 &amp;= \\frac{1}{n}\\sum_{i=1}^n y_i - \\frac{\\hat\\beta_1}{n}\\sum_{i=1}^n x_i \\\\                            &amp;= \\bar{y} - \\hat\\beta_1\\bar{x} \\\\      \\therefore\\hat\\beta_0 &amp;= \\bar{y} - \\hat\\beta_1 \\bar{x}  \\end{align*}\\)on the other partial derivaties \\(\\frac{\\partial RSS}{\\partial\\beta_1} = -2\\sum x_i(y_i - \\beta_0 - \\beta_1 x_i)\\),substituting $ \\bar{y} - \\hat\\beta_1 \\bar{x} $ for $ \\hat\\beta_0$:\\(\\sum x_i(y_i - \\hat\\beta_0 - \\hat\\beta_1 x_i) = 0 \\\\  \\sum x_i(y_i - \\bar{y} - \\hat\\beta_1(x_i - \\bar{x}) = 0 \\\\  \\sum x_i(y_i - \\bar{y}) - \\hat\\beta_1 \\sum x_i(x_i - \\bar{x}) = 0 \\\\  \\Leftrightarrow \\sum x_i(y_i - \\bar{y}) = \\hat\\beta_1 \\sum x_i(x_i - \\bar{x})\\)\\(\\begin{align*}\\therefore \\hat\\beta_1 &amp;= \\frac{\\sum x_i(y_i - \\bar{y})}                               {\\sum x_i(x_i - \\bar{x})} \\\\ \t\t\t\t\t\t &amp;= \\frac{\\sum(x_i-\\bar{x})(y_i - \\bar{y})} \t\t\t\t\t\t\t\t {\\sum(x_i - \\bar{x})^2}\\end{align*}\\)  3.1.2.  Assessing the Accuracy of the Coefficient Estimates      when the true function of $Y = f(X) + \\epsilon$,linear function $Y = \\beta_0 + \\beta_1 X + \\epsilon$        an unbiased estimation?if we use the sample mean $\\hat\\mu$ to estimate $\\mu$in the sense that unbiased on average, we expact both are equal.for one particular set of obs., its $\\hat\\mu$ might not correct,but if we could average a huge number of estimates from a number of sets of obs.,this average would exactly equal $\\mu$.by the same way, $\\hat\\beta_0$ and $\\hat\\beta_1$ are unbiased estimators.        how accurate is the sample mean $\\hat\\mu$ as an estimate of $\\mu$?for a single estimate $\\hat\\mu$, by computing the standard error $SE(\\hat\\mu)$:\\(Var(\\hat\\mu) = SE(\\hat\\mu)^2 = \\frac{\\sigma^2}{n}\\)        Assume that $\\epsilon_i$ have common variance $\\sigma^2$ and are uncorrelated,standard errors of unbiased estimators in linear regression\\(SE(\\hat\\beta_0)^2 = \\sigma^2\\left[\\frac{1}{n}+\\frac{\\bar{x}^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\right]\\),\\(SE(\\hat\\beta_1)^2 = \\frac{\\sigma^2}{\\sum_{i=1}^n(x_i-\\bar{x})^2}\\)        from data, estimation of $\\sigma$ residual standard errorRSE = \\(\\sqrt{RSS/(n-2)}\\)        standard error and confidence intervalconfidence interval is defined as a range of values such that with given probability,the range will contain the true unknown value of the parameterdefined in terms of lower and upper limits computed from the sample of data95% confidence interval for $\\beta_1$: \\(\\hat\\beta_1 \\pm 2 \\cdot SE(\\hat\\beta_1)\\)95% confidence interval for $\\beta_0$: \\(\\hat\\beta_0 \\pm 2 \\cdot SE(\\hat\\beta_0)\\)        Hypothesis Testnull hyphothesis $H_0$: no relationship between X and Y; $\\beta_1 = 0$alternative hypothesis $H_a$: some relationship between X and Y; $\\beta_1 \\ne 0$How far is $\\hat\\beta_1$ far enough from 0, we can be confident that true $\\beta_1$ is non-zero?        t-statistics\\(t = \\frac{\\hat\\beta_1 - 0}{SE(\\hat\\beta_1)}\\)measures the number of standard deviations that $\\hat\\beta_1$ is away from 0        p-valueprob. of observing any number equal to $|t|$ or larger, assuming $\\beta_1$ = 0with small p-value, infer that there is an association between the predictor and the response,we can reject the null hypothesis  3.1.3. Assessing the Accuracy of the ModelResidual Standard Error (RSE)  RSE = \\(\\sqrt{\\frac{1}{n-2}RSS} = \\sqrt{\\frac{1}{n-2}\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}\\)an estimate of the standard deviation of \\(\\epsilon\\)a measure of the lack of fit of the model to the data$R^2$ Statistics      \\(R^2 = 1 - \\frac{RSS}{TSS}\\)TSS; the total variance in the response Y, amount of variability inherentRSS; amount of variability that is left unexplained after performing the regressionTSS-RSS; amount of variability in the response that is explained$R^2$; proportion of variability in Y that can be explained using X        \\(Cor(X,Y) = \\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{\\sqrt{\\sum_{i=1}^n(x_i - \\bar{x})^2}\\sqrt{\\sum_{i=1}^n(y_i-\\bar{y})^2}}\\)is also a measure of the linear relationship between X and Ywe can use $r = Cor(X,Y) $ instead of $R^2$ to assess the fit of the linear modelin simple linear regression, $R^2 = r^2$,squared correlation and the squared R statistic are identical.  3.2. Multiple Linear Regression  Model: $ f(X) = \\beta_0 + \\sum_{j=1}^p \\beta_j X_j + \\epsilon$$\\Rightarrow$ Prediction of Y from X (p input variables)$\\quad$ f: Regression function $E(Y|X)$3.2.1. Estimating the Regression Coefficients      prediction: $\\hat{y} = \\hat\\beta_0 + \\sum_{j=1}^p \\hat\\beta_j X_j$        How to estimate coefficients $\\beta = (\\beta_0, \\beta_1, \\ldots , \\beta_p)^T$?Least Squares $\\hat\\beta$: $\\beta$ minimizing RSSwhen Y is (n by 1) / X is (n by (p+1)) matrix,RSS = $ ( y - X\\hat\\beta)^T ( y - X\\hat\\beta) $,Least square estimator (LSE): $ \\hat\\beta = (X^T X)^{-1} X^T Y $        derivation\\(\\begin{align*}RSS &amp;= y^T y - \\hat\\beta^T X^T y - y^T X \\hat\\beta \\hat\\beta^T X^T X \\hat\\beta \\\\    &amp;= y^T y - 2\\hat\\beta^T X^T y + \\hat\\beta^T X^T X \\hat\\beta\\end{align*}\\)take the derivative with respect to $\\hat\\beta$ minimizing RSS,\\(\\frac{\\partial e^T e}{\\partial \\hat\\beta} = -2X^T y + 2X^T X\\hat\\beta = 0\\)we get ‘normal equations’ $(X^T X)\\hat\\beta = X^T y$$\\therefore \\hat\\beta = (X^T X)^{-1} X^T y $  Ordinary Least Squares Estimator      With Assumption:1) $Y_i$ responses are uncorrelated and Var($Y_i$) = $\\sigma^2$$\\quad$($\\equiv$ $\\epsilon_i$ are independent and Var($\\epsilon_i$) = $\\sigma^2$)2) $X = (X_1, \\ldots, X_p)^T$ is fixed (not random)        By (1) &amp; (2), for OLS estimator $\\hat\\beta$;\\(\\begin{align*}\\hat\\beta &amp;= (X^TX)^{-1}X^TY &amp; \\cdots Y=X\\beta + \\epsilon \\\\          &amp;= \\beta + (X^TX)^{-1}X^T\\epsilon\\end{align*}\\)$\\hat\\beta$ is a linear estimator of $\\beta$\\(\\begin{align*}E(\\hat\\beta) &amp;= E(\\beta) + (X^TX)^{-1}X^T E(\\epsilon) \\\\             &amp; \\quad \\scriptstyle\\text{ where } E[\\epsilon] = 0 \\\\             &amp;= \\beta\\end{align*}\\)so that $\\hat\\beta$ is an unbiased estimator of $\\beta$   \\(\\begin{align*}Var(\\hat\\beta) &amp;= E[\\hat\\beta - E(\\hat\\beta)]^2 \\\\               &amp;= E[ (X^TX)^{-1}X^T\\epsilon ]^2 \\\\               &amp;= (X^TX)^{-1}X^TE(\\epsilon^2)X(X^TX)^{-1}\\\\               &amp;= \\sigma^2(X^TX)^{-1}X^TX(X^TX)^{-1}\\\\               &amp;=\\sigma^2(X^T X)^{-1}\\end{align*}\\)while $\\hat\\sigma^2$ as Estimator of Variance of $\\epsilon$ (= $\\sigma^2$):\\(\\begin{align*}\\hat\\sigma^2 &amp;= \\frac 1 {n-p-1} \\sum_{i=1}^n (y_i - \\hat y_i)^2 \\\\             &amp;= \\frac1{n-p-1}\\sum_{i=1}^n \\epsilon_i^2 \\\\\\rightarrow E(\\hat\\sigma^2) &amp;= \\sigma^2\\end{align*}\\)$\\therefore \\text{ unbiased estimator; }\\frac{RSS}{n-p-1}$        With Assumption:3) $\\epsilon \\sim ^{\\text{iid}} N(0,\\sigma^2)$ : normal distribution assumption of  error          $\\hat\\beta\\sim MVN(\\beta,\\sigma^2(X^TX)^{-1}), \\quad (Y\\sim MVN(X\\beta,\\sigma^2 I)$ $\\frac{(n-p-1)\\hat\\sigma^2}{\\sigma^2}\\sim\\chi^2_{n-p-1}$$\\hat\\beta$ and $\\hat\\sigma^2$ are independent      Gauss-Markov Theorem  Assumption: $E(\\epsilon_i) = 0, Var(\\epsilon_i) = \\sigma^2 &lt; \\infty\\text{,  } \\epsilon_i$’s are independent  among all linear unbiased estimator $\\tilde{\\beta} = Cy$ &amp; $E(\\tilde{\\beta}) = \\beta)$Then, $Var(\\hat\\beta) \\le Var(\\tilde{\\beta})$ when  LSE $\\hat\\beta$ = BLUE  G-M theorem says that LSE  $\\hat\\beta$ is the best linear unbiased estimator (BLUE)  Conversely, there may exist biased estimators with smaller MSE than LSE.Properties of Good estimators  unbiaseness  efficiency(small variance)  consistancy(as n goes infinity, estimator goes true parameter)  sufficiency3.2.2. Important Questions3.2.2.1. Hypothesis Test      1) Test for all coefficients$H_0$: all $\\beta$ coefficients are zero$H_a$: at least one $\\beta_j$ is non-zero        Test statistic: $ F = \\frac{(TSS-RSS)/p}{RSS/(n-p-1)}$where TSS = $\\sum_{i=1}^n(y_i-\\bar y)^2$ and RSS = $\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$    from the linear model assumptions,\\(E\\left[RSS/(n-p-1)\\right] = \\sigma^2\\)          if $H_0$ is true, \\(E\\left[TSS-RSS/p\\right] = \\sigma^2\\)F-statistic value is close to 1      if $H_a$ is true, \\(E\\left[TSS-RSS/p\\right] &gt; \\sigma^2\\)F-statistic value is greater than 1            2) Test for a particular subset of coefficients$H_0: \\beta_{p-q+1} = \\beta_{p-q+2} = \\cdots = \\beta_{p} = 0$$H_1$: At least one of those is not zero        Full model: $Y=\\beta_0 + \\beta_1X_1 + \\cdots + \\beta_pX_p + \\epsilon$Reduced model under $H_0: Y= \\beta_0  + \\beta_1X_1 + \\cdots + \\beta_{p-q}X_{p-q} + \\epsilon$        Test statistic: F = \\(\\frac{(RSS_0 - RSS)/q}{RSS/(n-p-1)}\\)where RSS is from full model and $RSS_0$ is from reduced model        Check F-test first before t-tests for each $\\beta_j$F-test : test for all coef, T-test: test for indiv. coeffwhen F-test is significant ($H_1$ for all coeff is true)$\\Rightarrow$ perform t-test but still need to control $\\alpha$but if F-test is not sig. $\\Rightarrow$ can’t trust t-test result : all coeffs are ZERO    if $p &gt; n$, more coefficients $\\beta_j$ to estimate than observastions,we cannot fit the MLR model using least squaresand F-statistic cannot be used3.2.2.2. Variable Selection  often, the response is only associated with a subset of the predictorsBut we can’t consider all $2^p$ models that contain subsets of p variables          subset selection, e.g. Forward, Backward, Mixed selection        Criterions to judge the quality of a model          statistics, e.g. Mallow’s $C_p$, Akaike information criterion(AIC),Bayesian information criterion(BIC), adjusted $R^2$      model outputs, residuals, patterns.      3.2.2.3. Model fit  most common measures of model fit: RSE and $R^2$SLR model; $R^2$, square of the correlation of the response and the variableMLR model; $R^2$ = $Cor(Y,\\hat{Y})^2$, correlation between response and fitted modelfitted; model that maximizes this correlation among all possible linear model3.2.2.4. Prediction Errors      Uncertainty between $\\hat Y$ and $f(X)$ the least squares plane $\\hat{Y} = X^T \\hat\\beta$ the true population regression plane $f(X) = X^T\\beta$ Variation due to $\\hat\\beta$ (Model variance) in ideal situation, we can drive number of training datasets from population and have several $f(x)$ and $\\hat\\beta$ $\\scriptstyle\\text{Confidence interval}$ C.I. for Y: $E(\\hat Y) = x^T\\beta = f(x)$, $Var(\\hat Y) = \\sigma^2 x^T( X^TX)^{-1}x$ $\\therefore (1-\\alpha)100$% C.I. for Y = $\\hat Y \\pm t_{(1-\\alpha/2, n-p-1)} \\hat\\sigma\\sqrt{x^T(X^TX)^{-1}x}$        Model bias: caused by assuming a linear model for f(x). $\\rightarrow$ (1)(2) are reducible error        Uncertainty between Y and $\\hat Y$ random error $\\epsilon$ is in the model, irreducible error $\\scriptstyle\\text{Prediction interval}$ P.I. = reducible + irreducible error for new, unseen test obs. $x_0 = (1, x_{01}, \\ldots, x_{op})^T$, $\\hat Y_0 = x_0^T \\beta$ $Var(\\hat Y_0) =  \\sigma^2 + \\sigma^2 x_0^T( X^TX)^{-1}x_0$ $\\scriptstyle\\text{(irreducible + reducible)}$ $\\therefore (1-\\alpha)100$% P.I. for $Y_0$ =  $\\hat Y_0 \\pm t_{(1-\\alpha/2, n-p-1)} \\hat\\sigma\\sqrt{1+x^T(X^TX)^{-1}x}$  3.3. Other Considerations in Regression Model3.3.1. Qualitative Predictors      for p qualitative predictors, create p-1 dummy variableswith a baseline of the last predictor that is not included in the dummies        various  approaches lead to equivalent model fits with different coefficients and interpretations,are designed to measure particular contrasts  3.3.2. Extensions of the Linear Model      standard linear regression model has highly restrictive assumptions,that are often violated in practice.        additivity: relationship between predictor $X_j$ and Y is independentto the values of the other predictors        linearity: model has a constant slope of $X_j$        Removing the Additive Assumptionin real-world problems and it’s potential variables are not independent;it has synergy or interaction effect.by introducing interaction term, we can relax the additive assumption        e.g.\\(\\begin{align*}Y &amp;= \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_1 X_2 + \\epsilon \\\\  &amp;= \\beta_0 + (\\beta_1 + \\beta_3 X_2)X_1 + \\beta_2 X_2 + \\epsilon \\\\  &amp;= \\beta_0 + \\tilde{\\beta_1}X_1 + \\beta_2 X_2 + \\epsilon\\end{align*}\\)        hierarchical principleif we include an interaction in a model, we should also include the main effects,even if the p-values associated with their coefficients are not significant.        Non-linear Relationships; e.g. polynomial regression  3.3.3. Potential Problems  Non-linearity of the response-predictor relationships          Residual plots for identifying non-linearityresiduals $e_i = y_i - \\hat{y}_i$ versus a predictor $x_i$, or fitted values $\\hat{y}_i$            Correlation of error terms we assumed the error terms, $\\epsilon_1, \\epsilon_2, \\ldots, \\epsilon_n$ are uncorrelated But if error terms are correlated, confidence of our model cannot be guaranteed. correlations frequently occur in context of time series data, we may see tracking in the residuals.    Non-constant variance of error terms standard errors, confidence intervals and hyphothesis test in linear model relpy upon the assumption of $Var(\\epsilon_i) = \\sigma^2$, that the error terms have a constant variance.          one solution for this heteroscedasticitytransform using a concave function such as $log Y$ or $\\sqrt{Y}$            Outliers to identify outliers, plot the studentized residuals computed by dividing each residual $e_i$ by its estimated standard error    High-leverage points: unusual value for $x_i$ the least squares line can be heavily affected by just a couple of observations but there is no simple way to plot all dimensions of the data simultaneously          leverage statistic $h_i$ to quantify an observation’s leverage        Collinearity when two or more predictor variables are closely related to one another, it makes difficult  to separate out the individual effects of collinear variables. Reducing the accuracy of the  estimates of the regression coefficients, standard error for $\\hat\\beta_j$ increases and the  t-statistic decreases. we may fail to reject $H_0: \\beta_j = 0$, the power of hypothesis test is reduced by collinearity.          Correlation matrix of the predictors      variance inflation factor(VIF) to assess multicollinearitywhere \\(R^2_{X_j|X_{-j}}\\) is from a regression of \\(X_j\\) onto all of the other predictors,\\(X_j = \\sum_{i\\ne j}\\beta_i X_i + e\\), and \\(VIF(\\hat\\beta_j) = \\frac{1}{1-R^2_{X_j|X_{-j}}}\\).having the smallest possible value of 1 if there’s no collinearity among the predictors and bigger values if there are more collinearity. Practically, a VIF value that exceeds 5 or 10 indicates a problematic amount of collinearity.      solution: Drop or Combine      3.5. Comparison with K-Nearest Neighbors  KNN regressiona non-parameric method: No assumption of $f(x)$\\(\\hat f(x_0) = \\frac{1}{K}\\sum_{x_i\\in\\mathcal{N}_0} y_i\\)          ($x_i,y_i$): training data      $\\mathcal N_0$ : K neighbors of prediction point $x_0$        Preferable situations to linear regression:          True $f(x)$ is nonlinear      when Goal is Prediction rather than Inference      large number of observations per predictor(or low dimensions)        Curse of Dimensionalityto capture 10% data as neighbor space for variable X…          p=1 : X range (0,1), edge rank $e_1(0.1) = 0.1$      p=2 : $X_1, X_2$ range (0,1),edge rank $e_2(0.1) = \\sqrt{0.1} = 0.1^{1/2} \\approx 0.316 $      p=3 : $e_3(0.1) = 0.1^{1/3} \\approx 0.464 $      p=10 : $e_{10}(0.1) = 0.1^{1/10} \\approx 0.794 $            Reduction of r : Average using fewer obs.small K : higher variance of the fit, poor prediction    For the same density, when p = 1, n = 100 -&gt; when p = 10, n = $100^{10}$",
        "url": "/islr_ch3"
    }
    ,
    
    "islr-ch2": {
        "title": "ISLR - Chapter 2. Statistical Learning",
        "author": "Darron Kwon",
        "category": "",
        "content": "  Chapter 2. Statistical Learning  2.1. What is Statistical Learning?          2.1.1. Why Estimate $f$ ?                  Prediction          Inference                    2.1.2. Estimating $f$ : By Using Training Data                  Parametric Methods: Model-based approach          Non-parametric Methods: Data-driven approach          Example of Nonparametric model: KNN Reg.                    2.1.3. Trade-off between Prediction Accuray &amp; Interpretability      2.1.4. Supervised Vs. Unsupervised Learning      2.1.5. Regression Vs. Classification Problems        2.2. Assessing Model Accuracy          2.2.1. Measuring the Quality of Fit                  Mean squared error (MSE)                    2.2.2. Bias-Variance Trade-off                  Trade-off in KNN Reg.                    2.2.3. The Classification Setting                  The Bayes Classifier - Two-class Problem          K-Nearest Neighbors (KNN)                    Chapter 2. Statistical Learning2.1. What is Statistical Learning?  Format of Statistical Learning:$ Y=f(X)+\\epsilon $assume a relationship between $Y$ and $X$;$Y$: observed quantitative response$X$: $p$ different predictors $(X_1, X_2, \\ldots , X_p)$$f$ : Fixed but UNKNOWN function of predictors $X$$\\epsilon$ : a random error term, independent of $X$ which has mean zero; $E(\\epsilon)=0$$\\rightarrow$ Statistical Learning: A set of methods estimating $f$.2.1.1. Why Estimate $f$ ?  Why do we estimate $f$ ?1) Prediction: $Y$2) Inference: Relationship between $X$ &amp; $Y$Prediction      $\\text{Prediction of } \\; Y : \\hat{Y} = \\hat{f}(X)\\quad (\\hat{f} : \\text{Estimate of }f) $$\\text{Accuracy of } \\; \\hat{Y} \\text{ depends on reducible &amp; irreducible errors}$;        with a given(fixed) estimate $\\hat{f}$ and a set of predictors $X$,while true function $f$ is also fixed from definition,\\(\\underbrace{E[Y-\\hat{Y}]^2}_{MSE} = \\underbrace{[f(X)-\\hat{f}(X)]^2}_{\\text{reducible error}}                                   + \\underbrace{Var(\\epsilon)}_{\\text{irreducible error}}\\)        derivation\\(\\begin{align*}E[Y-\\hat{Y}]^2  &amp;= E\\left[\\{f(X)+\\epsilon\\} - \\hat{f}(X) \\right]^2 \\\\              &amp;= E\\left[ \\{f(X)-\\hat{f}(X)\\}^2 + 2 \\epsilon \\ (f(X)-\\hat{f}(X))                                                              + \\epsilon^2 \\right] \\\\              &amp;= E\\left[\\{f(X)-\\hat{f}(X)\\}^2\\right] + 2E[\\epsilon]\\cdot E\\left[f(X)-\\hat{f}(X)\\right]                                                                                      + E[\\epsilon^2] \\\\              &amp; \\quad \\quad \\scriptstyle f, \\hat{f} \\text{ and } X \\text{ are fixed, }                                                      E(\\epsilon)=0 \\text{ and } E(\\epsilon^2)\\ =\\ Var(\\epsilon) \\\\              &amp;= [f(X)-\\hat{f}(X)]^2 + Var(\\epsilon)\\end{align*}\\)        Reducible error : controlable, can be reduced by selecting a better modelIrreducible error: uncontrolable, nature of data  Inference      interested in:Which predictors are associated with the response?What is the relationship between the response and each predictor?Can the relationship between Y and each predictor be adequately summarizedusing a linear equation, or is the relationship more complicated?        Characteristics of linear &amp; nonlinear models:1) Linear : Relatively Simple &amp; interpretable inference but poor prediction(when true function $f$ is nonlinear)2) Nonlinear : More accurate but difficult to interpret$\\rightarrow$ Depends on your Goal of analysis  2.1.2. Estimating $f$ : By Using Training Data  Estimation Methods:1) Parametric: Assume specific function $f$ (linear&amp;non- both)2) Non-parametric: No Assumption; Data-driven method (nonlinear)Parametric Methods: Model-based approach      Step 1: Assumption about the functional form of $f$Training data consist of n obs. {$(x_1,y_1), (x_2,y_2), \\ldots , (x_n,y_n)$}where $x_i = ( x_{i1}, x_{i2}, \\ldots , x_{ip} ) ^T$with $ \\scriptstyle\\text{(p+1)} $ coefficients $\\ \\beta_0, \\beta_1, \\ldots, \\beta_p$$\\rightarrow $ linear form $ f(X)= \\beta_0 + \\beta_1X_1 + … + \\beta_pX_p$        Step 2: Estimate Parameters$Y \\approx \\hat{\\beta}_0 + \\hat{\\beta}_1X_1 + … + \\hat{\\beta}_pX_p = \\hat{f}(X)$$\\rightarrow $ approaches to fitting model        Advantage:Simplifies the problem of estimating $f$ to estimating a set of parameters    Disadvantage: Specific form of $f$Not match with the true $f$: poor estimation &amp; poor prediction$\\rightarrow\\;$ Flexible parametric model : model with more parameters          Flexible model $\\equiv$ Complex modelbut overfitting problem still remains:models could follow errors or noises, too closely        Underfitting vs Overfitting problemsunderfit: estimation has not enough accuracy, miss to capture the true structureoverfit: more complexity than true $f$Non-parametric Methods: Data-driven approach  No assumptions about functional form of $f$$\\Rightarrow $ potential to accurately fit a wider range of possible shapes of $f$  Disadvantage:1) Large number of obs. are required to get an accurate $f$ relative to a parametric method2) Overfitting $\\Leftrightarrow$ Level of smoothness; Model complexity(how to determine it?)Example of Nonparametric model: KNN Reg.  Idea: Similar inputs have Similar outputsStep: when predicting $\\hat{Y}_0$ with input $X_0$          1) Determine $K$ (level of smoothness)              if K==N: Y = Var(Y)if K==1: Y = perfect fit; no training error                    2) find $K$ closest training obs. from the target input point($X_0$) using Euclidean distance            3) average of these #k Y values\\(\\rightarrow\\hat{Y}_0 = \\frac{1}{K}\\sum_{x_i\\in \\mathcal N}^K y_i\\)        Effect of $K$ (tuning parameter/ model flexibility parameter)          decides the level of smoothness (under or overfitting)      As $K \\uparrow \\; \\Rightarrow \\text{flexibility} \\downarrow$ : the fitted line is simple      As $K \\downarrow \\; \\Rightarrow \\text{flexibility} \\uparrow$ : the fitted line is wiggly      2.1.3. Trade-off between Prediction Accuray &amp; Interpretability  tradeoff between flexibility and interpretability  based on our goal:inference ($\\rightarrow$ restrictive model)prediction ($\\rightarrow$ flexible model)BUT NOT ALWAYS THE CASE2.1.4. Supervised Vs. Unsupervised Learning      Supervised:for each observation $x_i$, there is an associated response measurement $y_i$goal is to fit a model, to predict or interpret(inference)        Unsupervised:no associated response $y_i$, not possible to fit a model, no response to predictgoal is to understand the relationships between the variables or between the observations  2.1.5. Regression Vs. Classification Problems  Variables either quantitative or qualitative(categorical)  Different models can be used on both problem2.2. Assessing Model Accuracy  Evaluate the performance of models on a given dataset and Select the best model  Criterions, e.g. Better prediction of $Y$2.2.1. Measuring the Quality of FitMean squared error (MSE)      Training MSE = \\(\\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{f}(x_i))^2\\)the most commonly-used measure in the regression settingcan be used for building model, but is not our interest;cannot be a measure for model selection    when training RSS = \\(\\sum(y_i - \\hat{y_i})^2\\), MSE = \\(\\frac{RSS}{N}\\)\\(R^2 = 1 - \\frac{RSS}{TSS}\\)          as more $X$ variables added, even $X$ are not important predictors,      RSS &amp; MSE decrease and $R^2$ increases, regardless of existence of test data        Test MSE \\(= \\frac{1}{m}\\sum_{i=1}^m(y_i^0 - \\hat{f}(x_i^0))^2\\)with unseen test observation not used to train,Select model that gives the lowest test MSE.          Test MSE(error rate) is always larger than Training MSE;We estimated model function $f$ to minimize its training error      if there’s NO test data: Sample re-use methods(e.g., bootstrap, cross-validation)        for Classification problem: Misclassification rate2.2.2. Bias-Variance Trade-off  expected test MSE($\\scriptstyle\\text{ideal measure}$)= $E[y_0-\\hat{f}(x_0)]^2$ when $(x_0,y_0)$ is a test obs.      in population: #K training sets and #K function $f_k$Estimation of expected test MSE:  \\(\\\\ \\hat{E}[y_0 - \\hat{f}(x_0)]^2 = \\frac{1}{K} \\sum_{k=1}^K[y_0-\\hat{f}_k(x_0)]^2\\)        derivationFor given $x_0$,  (when $\\epsilon$ is irreducible error) \\(\\\\ \\begin{align*}\\hat{E}[y_0 - \\hat{f}(x_0)]^2 &amp;= E [ \\{ y_0 -E(\\hat{f}(x_0)) \\} - \\{ \\hat{f}(x_0) - E(\\hat{f}(x_0)) \\} ]^2 \\\\                  (1) \\cdots\t&amp;= E [  y_0 -E(\\hat{f}(x_0)) ] ^2 \\\\                  (2) \\cdots\t&amp; \\; + E [\\hat{f}(x_0) - E(\\hat{f}(x_0)) ] ^2 \\\\                  (3) \\cdots\t&amp; \\; - 2E[ \\{ y_0 -E(\\hat{f}(x_0)) \\} \\{ \\hat{f}(x_0) - E(\\hat{f}(x_0)) \\} ]\\end{align*}\\)        (1) \\(\\\\ \\begin{align*}   &amp;= E [(f(x_0) + \\epsilon - E(\\hat{f}(x_0)) ] ^2 \\\\  &amp;= E[ f(x_0)^2 +\\epsilon^2 + [E(\\hat{f}(x_0)) ]^2 + 2f(x_0)\\epsilon -2f(x_0)E(\\hat{f}(x_0)) - 2\\epsilon E(\\hat{f}(x_0)) ] \\\\  &amp; \\quad \\scriptstyle\\text{when } E(\\epsilon) \\text{ goes to } 0 \\\\  &amp;= E[E(\\hat{f}(x_0)) - f(x_0)] ^2 + E(\\epsilon^2)  \\\\  &amp; \\quad \\scriptstyle{f(x_0) - E(\\hat{f}(x_0)) -  \\text{ is a Bias}} \\\\  &amp;= [Bias(\\hat{f}(x_0))]^2 + Var(\\epsilon^2)\\end{align*}\\)    (2) = $Var(\\hat{f}(x_0)); $ model variance($\\scriptstyle\\text{different fit’s from randomness of training sets}$)  (3) = 0$\\therefore \\hat{E}[y_0 - \\hat{f}(x_0)]^2 = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\epsilon) $      $Var(\\hat{f}(x_0)$ : model variance        $ [Bias(\\hat{f}(x_0)]$: Systematic model error(caused by model assumptions; e.g. true f: nonlinear)        $ Var(\\epsilon)$ : Irreducible error  Model Flextibility $\\uparrow$ $\\Rightarrow$ model variance $\\uparrow$ &amp; model bias $\\downarrow$Model Flextibility $\\downarrow$ $\\Rightarrow$ model variance $\\downarrow$ &amp; model bias $\\uparrow$$\\rightarrow$ optimal model flextibility is different for each datasetsTrade-off in KNN Reg.  given $Y = f(X) + \\epsilon$, $E(\\epsilon) = 0 $ and $Var(\\epsilon) = \\sigma^2$      Expected test MSE at $x_0$:\\(E[ (Y- \\hat{f_k}(x_0) )^2 | X = x_0 ] = Var(\\hat{f}(x_0)) + [Bias(\\hat{f}(x_0))]^2 + Var(\\epsilon)\\)        (1) \\(\\\\\\begin{align*} Var(\\hat{f_k}(x_0))  &amp;= Var(\\frac 1 K \\sum_{i \\in \\mathcal N (x_0)} Yi )\\\\                                    &amp;= \\frac 1 {K^2} \\sum  Var( Yi ) \\\\                                    &amp;=  \\frac 1 {K^2} \\sum Var( f( x_i) + \\epsilon_i ) \\\\                                    &amp;=  \\frac 1 {K^2} \\sum \\sigma^2 = \\frac 1 {K^2} \\cdot K \\cdot \\sigma^2 = \\frac {\\sigma^2} K\\end{align*}\\)    (2) \\(\\\\ \\begin{align*} Bias(\\hat{f_k}(x_0))   &amp;=  f(x_0) - E(\\hat{f}(x_0)) \\\\                                       &amp;= { f(x_0) - E[\\frac1 K \\sum_{i \\in \\mathcal N (x_0)} ^ K Y_i ] }  \\\\                                      &amp;= { f(x_0)- \\frac 1 K \\sum E (f(x_i)+\\epsilon_i)}  \\\\                                      &amp;= f(x_0) - \\frac 1 K \\sum E (f(x_i)  \\\\\\end{align*}\\)\\(\\therefore\\) Expected test MSE = \\(\\sigma ^2 + [f(x_0) - \\frac{1}{K}\\sum_{x_i \\in \\mathcal N (x_0)}^k f(x_i) ]^2 + \\frac {\\sigma^2}{K}\\)  when we use large number of K - as K increases,model complexity and model variance decreases, then bias increases;which is a simpler model.2.2.3. The Classification Setting      training misclassification rate \\(= \\frac 1 n \\sum_{i=1}^n I(y_i \\not = \\hat y_i )\\)$\\hat y_i$: $i_{th}$ observation using $\\hat f$$I(y_i \\not = \\hat y_i )$: indicator variable that;1 if $y_i \\not = \\hat y_i$ and 0 if $y_i = \\hat y_i$        test error = $ Ave(I(y_0 \\not = \\hat y_0))$ where;$\\hat y_0$ is the predicted class label for the test observation with predictor $x_0$  The Bayes Classifier - Two-class Problem      Assign a test observation with predictor vector $x_0$ to the class $j$ for which;conditional probability $Pr(Y=j|X=x_0)$ is largest.with only two possible response values, say class 1 or class 2,predict class 1 if $Pr(Y=1|X=x_0)$ &gt; 0.5, and class 2 otherwise.        Bayes error ratefor choosing the largest $Pr(Y=j|X=x_0)$,the error rate will be $\\ 1 - max_j Pr(Y=j|X=x_0)$ at $X=x_0$          Overall Bayes error rate = \\(1 - E\\left[max_j Pr(Y=j|X) \\right]\\)expectation averages the probability over all possible values of X      K-Nearest Neighbors (KNN)  \\(Pr(Y=j|X=x_0) = \\frac{1}{K}\\sum_{i \\in \\mathcal{N}_0} I(y_i=j)\\)conditional probability for class j$\\mathcal{N}_0$: K points in the training data that are closest to $x_0$KNN classifies the test obs. to the class with the largest probability.",
        "url": "/islr_ch2"
    }
    
    
    };
</script>
<script src="assets/js/lunr.js"></script>
<script src="assets/js/search.js"></script>
            </section>

        </article>

    </div>
</main>

<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->
<script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>



        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="/">Darron's Devlog</a> &copy; 2022</section>
                <!-- 
				<section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                -->
				<nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                <h1 class="subscribe-overlay-title">Search Darron's Devlog</h1>
                <p class="subscribe-overlay-description">
				</p>
                <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" 
               id="searchtext" type="text" name="searchtext"  
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
            </div>
        </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');

 </script>

	
    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
