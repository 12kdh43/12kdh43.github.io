<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
	
	<!-- On Post front-matter YAML, set "use_math: true" to use LaTex -->
	
	  
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
        equationNumbers: {
        autoNumber: "AMS"
        }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'], ["\\(","\\)"]  ],
    displayMath: [ ['$$', '$$'], ["\\[","\\]"]  ],
    processEscapes: true,
    }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>

<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
	

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Statistical Mining - Chapter 2</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />

    <!-- syntax.css -->
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
	
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="" />
    <link rel="shortcut icon" href="http://0.0.0.0:4000/assets/built/images/favicon.jpg" type="image/png" />
    <link rel="canonical" href="http://0.0.0.0:4000/stat_ch2" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Darron's Devlog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Statistical Mining - Chapter 2" />
    <meta property="og:description" content="Chapter 2. Supervised Learning 2.1. Prediction 2.2. Inference 2.3. Estimation F: By Using Training Data 2.4. Parametric Methods: Model-based approach 2.5. Nonparametric Methods: Data-driven approach 2.5.1. Example of Nonparametric model: KNN Reg. 2.6. Trade-off between Prediction Accuray &amp; Interpretability 2.7. Model Assessment &amp; Selection 2.7.1. Mean squared error (MSE) 2.8." />
    <meta property="og:url" content="http://0.0.0.0:4000/stat_ch2" />
    <meta property="og:image" content="http://0.0.0.0:4000/assets/built/images/blog-cover1.png" />
    <meta property="article:publisher" content="https://www.facebook.com/" />
    <meta property="article:author" content="https://www.facebook.com/" />
    <meta property="article:published_time" content="2020-03-16T00:00:00+09:00" />
    <meta property="article:modified_time" content="2020-03-16T00:00:00+09:00" />
    <meta property="article:tag" content="studies" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Statistical Mining - Chapter 2" />
    <meta name="twitter:description" content="Chapter 2. Supervised Learning 2.1. Prediction 2.2. Inference 2.3. Estimation F: By Using Training Data 2.4. Parametric Methods: Model-based approach 2.5. Nonparametric Methods: Data-driven approach 2.5.1. Example of Nonparametric model: KNN Reg. 2.6. Trade-off between Prediction Accuray &amp; Interpretability 2.7. Model Assessment &amp; Selection 2.7.1. Mean squared error (MSE) 2.8." />
    <meta name="twitter:url" content="http://0.0.0.0:4000/" />
    <meta name="twitter:image" content="http://0.0.0.0:4000/assets/built/images/blog-cover1.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Darron's Devlog" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="studies" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Darron's Devlog",
        "logo": "http://0.0.0.0:4000/"
    },
    "url": "http://0.0.0.0:4000/stat_ch2",
    "image": {
        "@type": "ImageObject",
        "url": "http://0.0.0.0:4000/assets/built/images/blog-cover1.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://0.0.0.0:4000/stat_ch2"
    },
    "description": "Chapter 2. Supervised Learning 2.1. Prediction 2.2. Inference 2.3. Estimation F: By Using Training Data 2.4. Parametric Methods: Model-based approach 2.5. Nonparametric Methods: Data-driven approach 2.5.1. Example of Nonparametric model: KNN Reg. 2.6. Trade-off between Prediction Accuray &amp; Interpretability 2.7. Model Assessment &amp; Selection 2.7.1. Mean squared error (MSE) 2.8."
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Statistical Mining - Chapter 2" href="/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="/">Darron's Devlog</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-projects" role="menuitem"><a href="/tag/projects/">Projects</a></li>
    <li class="nav-studies" role="menuitem"><a href="/tag/studies/">Studies</a></li>
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
</ul>
        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-studies  no-image">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="16 March 2020">16 March 2020</time>
                    
                        <span class="date-divider">/</span>
                        
                            
                               <a href='/tag/studies/'>STUDIES</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Statistical Mining - Chapter 2</h1>
            </header>
	<!--
            
	-->
            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <ul id="markdown-toc">
  <li><a href="#chapter-2-supervised-learning" id="markdown-toc-chapter-2-supervised-learning">Chapter 2. Supervised Learning</a>    <ul>
      <li><a href="#21-prediction" id="markdown-toc-21-prediction">2.1. Prediction</a></li>
      <li><a href="#22-inference" id="markdown-toc-22-inference">2.2. Inference</a></li>
      <li><a href="#23-estimation-f-by-using-training-data" id="markdown-toc-23-estimation-f-by-using-training-data">2.3. Estimation F: By Using Training Data</a></li>
      <li><a href="#24-parametric-methods-model-based-approach" id="markdown-toc-24-parametric-methods-model-based-approach">2.4. Parametric Methods: Model-based approach</a></li>
      <li><a href="#25-nonparametric-methods-data-driven-approach" id="markdown-toc-25-nonparametric-methods-data-driven-approach">2.5. Nonparametric Methods: Data-driven approach</a>        <ul>
          <li><a href="#251-example-of-nonparametric-model-knn-reg" id="markdown-toc-251-example-of-nonparametric-model-knn-reg">2.5.1. Example of Nonparametric model: KNN Reg.</a></li>
        </ul>
      </li>
      <li><a href="#26-trade-off-between-prediction-accuray--interpretability" id="markdown-toc-26-trade-off-between-prediction-accuray--interpretability">2.6. Trade-off between Prediction Accuray &amp; Interpretability</a></li>
      <li><a href="#27-model-assessment--selection" id="markdown-toc-27-model-assessment--selection">2.7. Model Assessment &amp; Selection</a>        <ul>
          <li><a href="#271-mean-squared-error-mse" id="markdown-toc-271-mean-squared-error-mse">2.7.1. Mean squared error (MSE)</a></li>
        </ul>
      </li>
      <li><a href="#28-bias-variance-trade-off-편향분산-교차" id="markdown-toc-28-bias-variance-trade-off-편향분산-교차">2.8. Bias-Variance Trade-off 편향분산 교차</a>        <ul>
          <li><a href="#281-ex-trade-off-in-knn-reg" id="markdown-toc-281-ex-trade-off-in-knn-reg">2.8.1. Ex) Trade-off in KNN Reg.</a></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h1 id="chapter-2-supervised-learning">Chapter 2. Supervised Learning</h1>

<ul>
  <li>
    <p>Format of Supervised Learning:<br />
<strong>$ Y=f(X)+\epsilon $</strong><br />
<strong>$f$</strong> : Fixed but UNKNOWN function of predictors <strong>X</strong><br />
$\rightarrow$ Supervised Learning: A set of methods estimating <strong>$f$</strong>.</p>
  </li>
  <li>
    <p>Why do we estimate <strong>$f$</strong> ?<br />
1) Prediction: <strong>Y</strong><br />
2) Inference: Relationship between <strong>X</strong> &amp; <strong>Y</strong></p>
  </li>
</ul>

<h2 id="21-prediction">2.1. Prediction</h2>
<ul>
  <li>
    <p>$\text{Prediction of } \; Y : \hat{Y} = \hat{f}(X)\quad (\hat{f} : \text{Estimate of }f) $<br />
$\text{Accuracy of } \; \hat{Y} \text{ depends on reducible &amp; irreducible errors}$</p>
  </li>
  <li>
    <p>as $\hat{f}$ and <strong>X</strong> is given(fixed),</p>

    <p><strong>$E[Y-\hat{Y}]^2 = [f(X)-\hat{f}(X)]^2 + Var(\epsilon)$</strong><br />
$\quad (MSE)\quad\quad (reducible)\quad (irreducible)$</p>

    <p>Reducible error : controlable, can be reduced by selecting a better model
Irreducible error: uncontrolable, nature of data</p>
  </li>
</ul>

<h2 id="22-inference">2.2. Inference</h2>
<ul>
  <li>Characteristics of linear &amp; nonlinear models:<br />
1) Linear : Relatively Simple &amp; interpretable inference but poor prediction (when true function $f$ is nonlinear)<br />
2) Nonlinear : More accurate but difficult to interpret<br />
$\rightarrow$ Depends on your Goal of analysis</li>
</ul>

<h2 id="23-estimation-f-by-using-training-data">2.3. Estimation F: By Using Training Data</h2>
<ul>
  <li>Estimation Methods:<br />
1) Parametric: Assume specific function $f$ (linear&amp;non- both)<br />
2) Nonparametric: No Assumption; Data-driven method (nonlinear)</li>
</ul>

<h2 id="24-parametric-methods-model-based-approach">2.4. Parametric Methods: Model-based approach</h2>
<ul>
  <li>
    <p>Step 1: Assume about the functional form of $f$<br />
$\text{e.x) when } X_j = ( x_{1j}, \ldots , x_{nj} ) ^T : n \ast 1$ obs.; $\;$ vector for the $j_{th}$ predictor<br />
simply estimate $ p+1 $ coefficients $\beta_0, \beta_1, \ldots, \beta_p$<br />
$\rightarrow linear form: f(X)= \beta_0 + \beta_1X_1 + … + \beta_pX_p$</p>
  </li>
  <li>
    <p>Step 2: Estimate Parameters<br />
$Y \approx \hat{\beta}_0 + \hat{\beta}_1X_1 + … + \hat{\beta}_pX_p = \hat{f}(X)$</p>
  </li>
  <li>Disadvantage: Specific form of $f$<br />
$\rightarrow\;$ Not match with the true $f$: poor estimation &amp; poor prediction<br />
$\rightarrow\;$ Flexible parametric model : model with more parameters
    <ul>
      <li>Flexible model $\equiv$ Complex model<br />
but overfitting problem still remains: model could follow errors or noises</li>
    </ul>
  </li>
  <li>Underfitting vs Overfitting<br />
under: estimation has not enough accuracy, miss to capture the true structure<br />
over: more complexity than true $f$</li>
</ul>

<h2 id="25-nonparametric-methods-data-driven-approach">2.5. Nonparametric Methods: Data-driven approach</h2>
<ul>
  <li>No assumptions about functional form of $f$<br />
$\Rightarrow $ potential to accurately fit a wider range of possible shapes of $f$</li>
  <li>Disadvantage:
    <ul>
      <li>1) Large <strong>#</strong> of obs. are required to get an accurate $f$<br />
(relative to a parametric method)</li>
      <li>2) Overfitting $\Leftrightarrow$ <strong>Level of smoothness</strong>; $\;$ Model complexity<br />
(how to determine it?)</li>
    </ul>
  </li>
</ul>

<h3 id="251-example-of-nonparametric-model-knn-reg">2.5.1. Example of Nonparametric model: KNN Reg.</h3>
<ul>
  <li>Idea: Similar inputs have Similar outputs<br />
Step: when predicting $\hat{Y}_0$ with input $X_0$
    <ul>
      <li>1) Determine $K$ (level of smoothness)</li>
      <li>
        <p>if K==N: Y = Var(Y)<br />
if K==1: Y = perfect fit; no training error</p>
      </li>
      <li>
        <p>2) find $K$ closest training obs. from the target input point($X_0$) using Euclidean distance</p>
      </li>
      <li>3) average of these #k Y values<br />
\(\rightarrow\hat{Y}_0 = \frac{1}{K}\sum_{x_i\in \mathcal N}^K y_i\)</li>
    </ul>
  </li>
  <li>Effect of $K$ (tuning parameter/ model flexibility parameter)
    <ul>
      <li>decides the level of smoothness (under or overfitting)</li>
      <li>As $K \uparrow \; \Rightarrow \text{flexibility} \downarrow$ : the fitted line is simple</li>
      <li>As $K \downarrow \; \Rightarrow \text{flexibility} \uparrow$ : the fitted line is wiggly</li>
    </ul>
  </li>
</ul>

<h2 id="26-trade-off-between-prediction-accuray--interpretability">2.6. Trade-off between Prediction Accuray &amp; Interpretability</h2>
<ul>
  <li>Restrictive model(Simple model) vs. Flexible model</li>
  <li>our goal:<br />
inference ($\rightarrow$ restrictive model)<br />
prediction ($\rightarrow$ flexible model)</li>
</ul>

<h2 id="27-model-assessment--selection">2.7. Model Assessment &amp; Selection</h2>
<ul>
  <li>Evaluate the performance of models on a given dataset  and Select the best model</li>
  <li>Criterion: Better prediction of $Y$</li>
</ul>

<h3 id="271-mean-squared-error-mse">2.7.1. Mean squared error (MSE)</h3>
<ul>
  <li>training MSE(used for building model) is not our interest; cannot be a measure for model selection
    <ul>
      <li>e.g.)<br />
\(\\ R^2 = 1 - \frac{RSS}{TSS}\)<br />
training RSS = \(\sum(y_i - \hat{y_i})^2  \quad \text{&amp;} \quad \text{MSE} =\frac{RSS}{N}\\\)<br />
when more X variables added, $\;$ RSS &amp; MSE $\downarrow$ , $R^2 \uparrow$<br />
even X are not important variables<br />
complex model has smaller training error regardless of existence of test data</li>
    </ul>
  </li>
  <li>
    <p>Test MSE \(= \frac{1}{m}\sum_{i=1}^m(y_i^0 - \hat{f}(x_i^0))^2\)<br />
Models with low test MSE are better.<br />
$\rightarrow$ How to find optimal Flexibility?<br />
$\rightarrow$ Test MSE(error rate) is always larger than Training MSE; We estimated model function $f$ to minimize its training error<br />
$\rightarrow$ No test data: Sample re-use methods (e.g., bootstrap, cross-validation)</p>
  </li>
  <li>Classification problem: Misclassification rate</li>
</ul>

<h2 id="28-bias-variance-trade-off-편향분산-교차">2.8. Bias-Variance Trade-off 편향분산 교차</h2>
<ul>
  <li>Expected test MSE(ideal measure): $E[y_0-\hat{f}(x_0)]^2$ when $((x_0,y_0)$ is a test obs.</li>
  <li>
    <p>in population: #K training sets &amp; #K function $f_k$<br />
Estimation of expected test MSE:  \(\\ \hat{E}[y_0 - \hat{f}(x_0)]^2 = \frac{1}{K} \sum_{k=1}^K[y_0-\hat{f}_k(x_0)]^2\)</p>
  </li>
  <li>
    <p>For given $x_0$,  (when $\epsilon$ is irreducible error) \(\\ \begin{align*}
\hat{E}[y_0 - \hat{f}(x_0)]^2 &amp;= Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\epsilon) \\
                      &amp;= E [ \{ y_0 -E(\hat{f}(x_0)) \} - \{ \hat{f}(x_0) - E(\hat{f}(x_0)) \} ]^2 \\
          (1) \cdots	&amp;= E [  y_0 -E(\hat{f}(x_0)) ] ^2 \\
          (2) \cdots	&amp; \; + E [\hat{f}(x_0) - E(\hat{f}(x_0)) ] ^2 \\
          (3) \cdots	&amp; \; - 2E[ \{ y_0 -E(\hat{f}(x_0)) \} \{ \hat{f}(x_0) - E(\hat{f}(x_0)) \} ]
\end{align*}\)</p>
  </li>
  <li>
    <p>(1) \(\\ \begin{align*} 
  &amp;= E [(f(x_0) + \epsilon - E(\hat{f}(x_0)) ] ^2 \\
  &amp;= E[ f(x_0)^2 +\epsilon^2 + [E(\hat{f}(x_0)) ]^2 + 2f(x_0)\epsilon -2f(x_0)E(\hat{f}(x_0)) - 2\epsilon E(\hat{f}(x_0)) ] \\
  &amp; \quad \scriptstyle\text{when } E(\epsilon) \text{ goes to } 0 \\
  &amp;= E[E(\hat{f}(x_0)) - f(x_0)] ^2 + E(\epsilon^2)  \\
  &amp; \quad \scriptstyle{E(\hat{f}(x_0)) - f(x_0) \text{is a Bias}} \\
  &amp;= [Bias(\hat{f}(x_0))]^2 + Var(\epsilon^2)
\end{align*}\)</p>
  </li>
  <li>$(2) = Var(\hat{f}(x_0)) \leftarrow $ model variance<br />
$\scriptstyle\text{different fit’s from randomness of training sets}$</li>
  <li>$(3) = 0$</li>
</ul>

<p>$\therefore$ Expected test MSE is consisted of Reducible Error(Var+ Bias$^2$) and Irreducible Error(Var($\epsilon$))</p>

<ul>
  <li>
    <p>$Var(\hat{f}(x_0)$ : model variance</p>
  </li>
  <li>
    <p>$ [Bias(\hat{f}(x_0)]$ : Systematic model error ( caused by model assumptions; e.g. true <em>f</em>: nonlinear)</p>
  </li>
  <li>
    <p>$ Var(\epsilon)$ : Irreducible error</p>
  </li>
</ul>

<p>Model Flextibility $\uparrow$ $\Rightarrow$ model variance $\uparrow$ &amp; model bias $\downarrow$<br />
Model Flextibility $\downarrow$ $\Rightarrow$ model variance $\downarrow$ &amp; model bias $\uparrow$</p>

<p><img src="/assets/images/tradeoff_0.png" alt="image.png" /></p>

<p>$\rightarrow$ optimal model flextibility is different for <strong>each datasets</strong></p>

<h3 id="281-ex-trade-off-in-knn-reg">2.8.1. Ex) Trade-off in KNN Reg.</h3>
<ul>
  <li>given) Y = f (X) + $\epsilon$ with E($\epsilon$) = 0 and Var ($\epsilon$) = $\sigma^2$</li>
  <li>
    <p>Expected test MSE at $x_0$: \(\\
E[ (Y- \hat{f_k}(x_0) )^2 | X = x_0 ] \\
= \sigma^2 + Bias^2(\hat{f_k} (x_0)) + Var (\hat{f_k} (x_0)) \\
\rightarrow Bias(\hat{f_k} (x_0)) =  f(x_0) - E(\hat{f}(x_0))   \text{ : given "f" is KNN func.}\\ 
\quad= { f(x_0) - E[\frac1 K \sum_{i \in \mathcal N (x_0)} ^ K Y_i ] }  \\
\quad= { f(x_0)- \frac 1 K \sum E (f(x_i)+\epsilon_i)}  \\
\quad= f(x_0) - \frac 1 K \sum E (f(x_i)  \\
\rightarrow Var(\hat{f_k} (x_0)) = Var(\frac 1 K \sum_{i \in \mathcal N (x_0)} Yi )\\
\quad= \frac 1 {K^2} \sum  Var( Yi ) \\
\quad=  \frac 1 {K^2} \sum Var( f( x_i) + \epsilon_i ) \\
\quad=  \frac 1 {K^2} \sum \sigma^2 = \frac 1 {K^2} * K * \sigma^2 = \frac {\sigma^2} K\)<br />
\(\therefore\) Expected test MSE at \(x_0 = \sigma ^2 + [f(x_0) - \frac 1 K \sum_{x_i \in \mathcal N (x_0)}^k f(x_i) ]^2 + \frac {\sigma^2} K\)</p>
  </li>
  <li>
    <p>when we use large number of K :<br />
as K increases, model complexity and model variance decreases, then bias increases<br />
;which is a simpler model</p>
  </li>
  <li>
    <p>Using Misclassification rate \(= \frac 1 N \sum_{i=1}^n I(y_i \not = \hat y_i )\)<br />
(in Bayes Classifier &amp; KNN Classifier)<br />
\(min_\hat Y E( I(Y \not = \hat Y) \\
= min_\hat Y E[ E(I(Y \not = \hat Y | X) ] \\
= min_{\hat f (x)} E[ \sum_{g=1}^G I( Y= g\not= \hat f (x) ) P ( Y= g| X) ] \\
\equiv min_{\hat f (x)} \sum_{g=1}^G I ( Y=g \not= \hat f (x) ) P ( Y= g| X) \\
\Rightarrow \hat f (x) = min_g \sum_{g=1}^G I ( Y=g \not= \hat f (x) ) P ( Y= g| X) \\
\quad \equiv min_g ( 1- P ( Y= g| X) )\)</p>
  </li>
  <li>E.g)<br />
in 3 groups -&gt; Y = 1, 2, 3<br />
P(Y=1 | X) = 0.3 , P(Y=2 | X) = 0.5, P(Y=3 | X) =0.2<br />
$\hat f(x) = 1 \Rightarrow$ EPE(expected prediction error; miss classification rate) = 0 * 0.3 + 1 * 0.5 + 1 * 0.2 = 0.7<br />
$\hat f(x) = 2 \Rightarrow$ EPE = 0.5 : min value<br />
$\hat f(x) = 3 \Rightarrow$ EPE = 0.8<br />
\(\therefore min_g ( 1- P ( Y= g| X) ) \\
\quad  \equiv max_g P(Y = g | X)\)<br />
Bayes error rate at X = $x_0$; $\quad 1 - max_g P(Y=g|X=x_0)$<br />
Overall Bayes error rate; $\quad 1 - E[ max_g P(Y=g | X= x) ]$</li>
</ul>


                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
	<!--
            
                <section class="subscribe-form">
                    <h3 class="subscribe-form-title">Subscribe to Darron's Devlog</h3>
                    <p>Get the latest posts delivered right to your inbox</p>
                    <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" 
               id="searchtext" type="text" name="searchtext"  
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
                </section>
            
	-->
            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            var this_page_url = 'http://0.0.0.0:4000/stat_ch2';
                            var this_page_identifier = '/stat_ch2';
                            var this_page_title = 'Statistical Mining - Chapter 2';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            


        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/built/images/blog-cover1.png)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Darron's Devlog &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/studies/">Studies</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/stat_ch4">Statistical Mining - Chapter 4</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/stat_ch3">Statistical Mining - Chapter 3</a></li>
                                        
                                    
                                  
                                
                                  
                                    
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/studies/">
                                
                                    See all 2 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                    <article class="post-card post-template no-image">
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/stat_ch3">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Studies</span>
                            
                        
                    

                    <h2 class="post-card-title">Statistical Mining - Chapter 3</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>
</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="/">
            
            <span>Darron's Devlog</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Statistical Mining - Chapter 2</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Statistical+Mining+-+Chapter+2&amp;url=https://12kdh43.github.io/stat_ch2"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://12kdh43.github.io/stat_ch2"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="/">Darron's Devlog</a> &copy; 2021</section>
                <!-- 
				<section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                -->
				<nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                <h1 class="subscribe-overlay-title">Search Darron's Devlog</h1>
                <p class="subscribe-overlay-description">
				</p>
                <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" 
               id="searchtext" type="text" name="searchtext"  
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
            </div>
        </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');

 </script>

	
    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
