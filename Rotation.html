<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
	
	<!-- On Post front-matter YAML, set "use_math: true" to use LaTex -->
	
	  
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    TeX: {
        equationNumbers: {
        autoNumber: "AMS"
        }
    },
    tex2jax: {
    inlineMath: [ ['$', '$'], ["\\(","\\)"]  ],
    displayMath: [ ['$$', '$$'], ["\\[","\\]"]  ],
    processEscapes: true,
    }
});
MathJax.Hub.Register.MessageHook("Math Processing Error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
MathJax.Hub.Register.MessageHook("TeX Jax - parse error",function (message) {
        alert("Math Processing Error: "+message[1]);
    });
</script>

<script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
	

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Unsupervised Representation Learning by Predicting Image Rotations</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />

    <!-- syntax.css -->
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
	
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!--[if IE]>
        <style>
            p, ol, ul{
                width: 100%;
            }
            blockquote{
                width: 100%;
            }
        </style>
    <![endif]-->
    
    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="" />
    <link rel="shortcut icon" href="http://0.0.0.0:4000/assets/built/images/favicon.jpg" type="image/png" />
    <link rel="canonical" href="http://0.0.0.0:4000/Rotation" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="Darron's Devlog" />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Unsupervised Representation Learning by Predicting Image Rotations" />
    <meta property="og:description" content="Unsupervised Representation Learning by Predicting Image Rotations Gidaris et al. 2018 https://github.com/gidariss/FeatureLearningRotNet ConvNet: (+) Unparalleled capacity to learn high level semantic image features (-) Require massive amounts of manually labeled data, expensive and impractical to scale $\rightarrow$ Unsupervised Learning Unsupervised semantic feature learning: Learn image features by training ConvNets to" />
    <meta property="og:url" content="http://0.0.0.0:4000/Rotation" />
    <meta property="og:image" content="http://0.0.0.0:4000/assets/built/images/blog-cover1.png" />
    <meta property="article:publisher" content="https://www.facebook.com/" />
    <meta property="article:author" content="https://www.facebook.com/" />
    <meta property="article:published_time" content="2022-01-24T15:00:00+00:00" />
    <meta property="article:modified_time" content="2022-01-24T15:00:00+00:00" />
    <meta property="article:tag" content="papers" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Unsupervised Representation Learning by Predicting Image Rotations" />
    <meta name="twitter:description" content="Unsupervised Representation Learning by Predicting Image Rotations Gidaris et al. 2018 https://github.com/gidariss/FeatureLearningRotNet ConvNet: (+) Unparalleled capacity to learn high level semantic image features (-) Require massive amounts of manually labeled data, expensive and impractical to scale $\rightarrow$ Unsupervised Learning Unsupervised semantic feature learning: Learn image features by training ConvNets to" />
    <meta name="twitter:url" content="http://0.0.0.0:4000/" />
    <meta name="twitter:image" content="http://0.0.0.0:4000/assets/built/images/blog-cover1.png" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="Darron's Devlog" />
    <meta name="twitter:label2" content="Filed under" />
    <meta name="twitter:data2" content="papers" />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="1400" />
    <meta property="og:image:height" content="933" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "Darron's Devlog",
        "logo": "http://0.0.0.0:4000/"
    },
    "url": "http://0.0.0.0:4000/Rotation",
    "image": {
        "@type": "ImageObject",
        "url": "http://0.0.0.0:4000/assets/built/images/blog-cover1.png",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://0.0.0.0:4000/Rotation"
    },
    "description": "Unsupervised Representation Learning by Predicting Image Rotations Gidaris et al. 2018 https://github.com/gidariss/FeatureLearningRotNet ConvNet: (+) Unparalleled capacity to learn high level semantic image features (-) Require massive amounts of manually labeled data, expensive and impractical to scale $\rightarrow$ Unsupervised Learning Unsupervised semantic feature learning: Learn image features by training ConvNets to"
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Unsupervised Representation Learning by Predicting Image Rotations" href="/feed.xml" />


</head>
<body class="post-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- default -->

<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="/">Darron's Devlog</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-projects" role="menuitem"><a href="/tag/projects/">Projects</a></li>
    <li class="nav-studies" role="menuitem"><a href="/tag/studies/">Studies</a></li>
	<li class="nav-blog" role="menuitem"><a href="/tag/blog/">Blog</a></li>
    <li class="nav-archive" role="menuitem">
        <a href="/archive.html">All Posts</a>
    </li>
</ul>
        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full  tag-papers  no-image">

            <header class="post-full-header">
                <section class="post-full-meta">
                    <time class="post-full-meta-date" datetime="24 January 2022">24 January 2022</time>
                    
                        <span class="date-divider">/</span>
                        
							
                            
                               <a href='/tag/papers/'>PAPERS</a>
                            
                        
                    
                </section>
                <h1 class="post-full-title">Unsupervised Representation Learning by Predicting Image Rotations</h1>
            </header>
	<!--
            
	-->
            <section class="post-full-content">
                <div class="kg-card-markdown">
                    <h2 id="unsupervised-representation-learning-by-predicting-image-rotations">Unsupervised Representation Learning by Predicting Image Rotations</h2>
<p><em>Gidaris et al. 2018</em><br />
<a href="https://github.com/gidariss/FeatureLearningRotNet">https://github.com/gidariss/FeatureLearningRotNet</a></p>

<ul>
  <li>ConvNet:<br />
  (+) Unparalleled capacity to learn high level semantic image features<br />
  (-) Require massive amounts of manually labeled data, expensive and impractical to scale<br />
  $\rightarrow$ <em>Unsupervised Learning</em></li>
  <li>Unsupervised semantic feature learning:<br />
  Learn image features by training ConvNets to recognize the 2d rotated images as input. With apparently simple task, provides a very powerful supervisory signal for semantic feature learning(Conv). Evaluated in various unsupervised feature learning benchmarks, exceeds SotA performance.</li>
</ul>

<h3 id="featurelearningrotnet">FeatureLearningRotNet</h3>
<ul>
  <li>How To:<br />
  First define a small set of discrete geometric transformations, then each of those transformations are applied to each image on the dataset and produced transformed images are fed to ConvNet model that is trained to recognize the transformation of each image.
    <ul>
      <li>Set of geometric transformations define the classification pretext task that the ConvNet has to learn; to achieve unsupervised semantic feature learning, it is important to properly choose those geometric transformations.</li>
    </ul>
  </li>
  <li>
    <p>Purpose: to define the geometric transformations as rotations of 4 different degrees, ConvNet trained on the 4-way image classification task of recognizing one of the four Maximizing prob. $F^y(x^{y^{*}})$, probability of transformation <em>y</em> predicted by <em>F</em>, when given X is transformed by the transformation $y^{*}$.</p>
  </li>
  <li>With idea: In order a ConvNet model to be able recognize the rotation transformations, it will require to understand the concept of the objects depicted in the image	such as their location, type, and pose.</li>
</ul>

<h3 id="overview">Overview</h3>
<ol>
  <li>define a set of <em>K</em> discrete geometric transformations \(G = \{g(\cdot\vert y)\}_{y=1}^K\), where $g(.\vert y)$ applies to input X, transformed image $X^y = g(X\vert y)$</li>
  <li>ConvNet model F(.) gets as input an image $X^{y^{\ast}}$, to recognize unknown $y^{\ast}$ yields as output a probability distribution over all possible transformations	\(F(X^{y^{\ast}}\vert\theta) = \{ F^y(X^{y^{\ast}}\vert\theta) \}_{y=1}^K\), output <em>F</em> returns probs for all classes $y$.</li>
  <li>Therefore, <em>N</em> training images \(D = \{ X_i \}_{i=0}^N\), the self-supervised training objective that ConvNet must learn to solve is:<br />
 \(\mbox{min}_{\theta}\frac{1}{N}\sum_{i=1}^N \mbox{loss}(X_i,\theta)\),<br />
 where the loss function is defined as:<br />
 \(\mbox{loss}(X_i,\theta) = -\frac{1}{K}\sum_{y=1}^K \log(F^y(g(X_i|y)|\theta))\)<br />
 (negative sum of log probs <em>F</em> for all classes <em>y</em>)</li>
</ol>

<ul>
  <li>2d image rotations:<br />
  $Rot(X, \phi)$, operator that rotates image X by $\phi$ degrees<br />
  In this case 0, 90, 180, 270; K=4 for G, where $g(X|y)=Rot(X,(y-1)90)$</li>
</ul>

<h3 id="forcing-the-learning-of-semantic-features">Forcing the learning of semantic features</h3>
<p>Fact that it is essentially impossible for a ConvNet model to effectively perform the above rotation recognition task, unless it has first learnt to recognize and detect classes of objects as well as their <strong>semantic parts</strong> in images.<br />
$\rightarrow$ <strong>ATTENTION MAPS</strong><br />
<img src="/assets/images/papers/papers_rotation_0.png" alt="png" width="60%&quot;, height=&quot;60%" /></p>
<ul>
  <li>By comparing the attention maps from two models trained on supervised and unsupervised way, we observe that both models seem to focus on roughly <strong>the same image regions</strong>.</li>
</ul>

<p><img src="/assets/images/papers/papers_rotation_1.png" alt="png" width="60%&quot;, height=&quot;60%" /></p>
<ul>
  <li>Also, trained on the proposed rotation recognition task, <strong>visualized layer filters</strong> learnt appear to have a big variety of edge filters on multiple orientations and multiple frequencies, then the filters learnt by the supervised task.
    <ul>
      <li><strong>Absence of low-level visual artifacts</strong>:<br />
  An additional important advantage of using image rotations over other geometric transformations, is that they do not leave e any easily detectable low-level visual artifacts that will lead the ConvNet to learn trivial features with no practical value for the vision perception tasks.</li>
      <li><strong>Well-posedness</strong>:<br />
  Human captured images tend to depict objects in an “up-standing” position. When defining the rotation recognition task, there is usually no ambiguity of what is the rotation transformation.</li>
      <li><strong>Implementing image rotations</strong>:<br />
  Flip and transpose.</li>
    </ul>
  </li>
  <li>$*$ Activation-based Attention Maps from <em>“Paying More Attention to Attention”, Zagoruyko et al., 2017</em> - <a href="https://arxiv.org/abs/1612.03928">https://arxiv.org/abs/1612.03928</a><br />
  Activation tensor of a conv. layer: $A\in R^{C\times H\times W}$ consists of <em>C</em> feautre planes with spatial dimensions <em>H</em>x<em>W</em><br />
  Activation-based mapping function <em>F</em> w.r.t that layer: $\mathcal{F}: R^{C\times H\times W} \rightarrow R^{H\times W}$<br />
  With implicit assumption: Absolute value of a hidden neuron activation(that results when the network is evaluated on given input) can be used as an indication about the importance of that neuron w.r.t. the specific input.<br />
  By considering, therefore, the absolute values of the elements of tensor A,	we construct a spatial attention map by computing statistics of these values	across the channel dimension(<em>C</em>)
    <ul>
      <li>sum of abs: $F_{sum}(A)=\sum_{i=1}^C\vert A_i\vert$</li>
      <li>sum of abs, raised to the power of p(&gt;1): $F_{sum}^p(A) = \sum_{i=1}^C\vert A_i\vert^p$</li>
      <li>max of abs, raised to the pwoer of p(&gt;1): $F_{max}^p(A) = \mbox{max}_{i=1,C}\vert A_i\vert^p$</li>
    </ul>
  </li>
</ul>

<h3 id="transfer-learning">Transfer Learning</h3>
<p>With a model trained on proposed rotation recognition task with unlabeled data, freeze its early conv. layers and attach the layers from a supervised model, evaluate on a supervised task with a subset of labeled data.</p>

<h3 id="experimental-results">Experimental Results</h3>

<h4 id="cifar-10-experiments">CIFAR-10 Experiments</h4>
<ul>
  <li>
    <p><strong><em>RotNet</em> implementation details</strong>:<br />
  Network-In-Network (NIN) architectures (<em>Lin et al., 2013</em>)<br />
  Pretask train: <code class="language-plaintext highlighter-rouge">optimizer = SGD, batch_size = 128, momentum = 0.9, weight_decay = 5e−4, lr = 0.1, lr_decay = 0.2 (after 30, 60, 80 epochs), num_epochs = 100</code></p>
  </li>
  <li><strong>Evaluation of the learned feature hierarchies</strong>:<br />
  Using the CIFAR-10 training images, train three <em>RotNet</em> models which have 3, 4, and 5 conv. blocks respectively. Afterwards, on top of the feature maps generated by each conv. block of each <em>RotNet</em> model, add classifiers trained in a supervised way on the object recognition task of CIFAR-10; consists of 3 FC layers. The accuracy results of CIFAR-10 test set:<br />
  <img src="/assets/images/papers/papers_rotation_2.png" alt="png" width="100%&quot;, height=&quot;100%" />
    <ol>
      <li>In all cases the feature maps generated by the 2nd conv. block achieve the highest accuracy, i.e., between 88.26% and 89.06%. Then the accuracy gradually degrades, which we assume is because they start becoming more and more specific on the self-supervised task of rotation prediction.</li>
      <li>Observe that increasing the total depth of the RotNet models leads to increased object recognition performance by the feature maps generated by earlier layers. We assume that this is because increasing the depth of the model and thus the complexity of its head (i.e., top ConvNet layers) allows the features of earlier layers to be less specific to the rotation prediction task.</li>
    </ol>
  </li>
  <li><strong>Exploring the quality of the learned features w.r.t. the number of recognized rotations</strong>:<br />
  <img src="/assets/images/papers/papers_rotation_3.png" alt="png" width="100%&quot;, height=&quot;100%" />
    <ul>
      <li>Observed that 4 discrete rotations as proposed achieved better performance over other cases.</li>
    </ul>
  </li>
  <li><strong>Comparison against supervised and other unsupervised methods</strong>:<br />
  <img src="/assets/images/papers/papers_rotation_4.png" alt="png" width="100%&quot;, height=&quot;100%" /><br />
  <img src="/assets/images/papers/papers_rotation_5.png" alt="png" width="100%&quot;, height=&quot;100%" />
    <ul>
      <li>Model using the feature maps generated by the 2nd conv. block of a RotNet model with 4 conv. blocks in total.<br />
  (a) <em>RotNet + non-linear</em>: a non-linear classifier with 3 fully connected layers<br />
  (b) <em>RotNet +conv.</em>: three conv. layers + a linear prediction layer</li>
      <li>Achieved best result among the unsupervised approaches</li>
      <li>Very close to the fully supervised NIN model</li>
      <li>Observed that fine-tuning the unsupervised learned features further improves the classification performance</li>
    </ul>
  </li>
  <li><strong>Correlation between object classification task and rotation prediction task</strong>:<br />
  <img src="/assets/images/papers/papers_rotation_6.png" alt="png" width="80%&quot;, height=&quot;100%" />
    <ul>
      <li>As the ability of the RotNet features for solving the rotation prediction task improves(as the rotation prediction accuracy increases), their ability to help solving the object recognition task improves as well(the object recognition accuracy also increases).</li>
      <li>Object recognition accuracy converges fast w.r.t. the number of training epochs used for solving the pretext task of rotation prediction.</li>
    </ul>
  </li>
  <li><strong>Semi-supervised setting</strong>:<br />
  <img src="/assets/images/papers/papers_rotation_7.png" alt="png" width="80%&quot;, height=&quot;100%" /><br />
  Train a 4 block RotNet model on the rotation prediction task using the entire image dataset of CIFAR-10, then train on top of its feature maps object classifiers using only a subset of the available images and their corresponding labels. As feature maps we use those from 2nd conv. block of the RotNet model. As a classifier we use a set of convolutional layers of the same e architecture as the 3rd conv. block of a NIN model plus a linear classifier, all randomly initialized.  For training the object classifier we use for each category 20, 100, 400, 1000, or 5000 image examples. Comapred with a supervised model that is trained only on the available examples each time:
    <ul>
      <li>Observed that our unsupervised trained model exceeds in this semi-supervised setting the supervised model when the number of examples per category drops below 1000; can be useful when there are only small subset of labeled data.</li>
    </ul>
  </li>
</ul>

<h4 id="evaluation-of-self-supervised-features-trained-in-imagenet">Evaluation of self-supervised features trained in ImageNet</h4>
<ul>
  <li>
    <p>Train a <em>RotNet</em> model on the training images of the ImageNet dataset and evaluate the performance of the self-self-supervised features on the image classification tasks of ImageNet, Places, and PASCAL VOC datasets and on the object detection and object segmentation tasks of PASCAL VOC.</p>
  </li>
  <li>
    <p><strong>Implementation details</strong>:<br />
  Based on an AlexNet architecture, without local response normalization units, dropout units, or groups in the colvolutional layers, while it includes batch normalization units after each linear layer (either convolutional or fully connected).<br />
  Train with <code class="language-plaintext highlighter-rouge">SGD, batch_size=192, momentum=0.9, weight_decay=5e-4, lr=0.01, lr_decay=0.1(after 10, 20 epochs), num_epochs=30</code></p>
  </li>
  <li><strong>ImageNet classification task</strong>:<br />
  <img src="/assets/images/papers/papers_rotation_8.png" alt="png" width="100%&quot;, height=&quot;100%" />
    <ul>
      <li>Observed that <em>our approach surpasses all the other methods by a significant margin</em></li>
    </ul>
  </li>
  <li><strong>Transfer learning evaluation on PASCAL VOC</strong>:<br />
  <img src="/assets/images/papers/papers_rotation_9.png" alt="png" width="100%&quot;, height=&quot;100%" /></li>
  <li><strong>Places classification task:</strong><br />
  <img src="/assets/images/papers/papers_rotation_10.png" alt="png" width="100%&quot;, height=&quot;100%" /></li>
</ul>


                </div>
            </section>

            <!-- Email subscribe form at the bottom of the page -->
	<!--
            
                <section class="subscribe-form">
                    <h3 class="subscribe-form-title">Subscribe to Darron's Devlog</h3>
                    <p>Get the latest posts delivered right to your inbox</p>
                    <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" 
               id="searchtext" type="text" name="searchtext"  
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
                </section>
            
	-->
            <footer class="post-full-footer">
                <!-- Everything inside the #author tags pulls data from the author -->
                <!-- #author-->
                
                    
                
                <!-- /author  -->
            </footer>

            <!-- If you use Disqus comments, just uncomment this block.
            The only thing you need to change is "test-apkdzgmqhj" - which
            should be replaced with your own Disqus site-id. -->
            
                <section class="post-full-comments">
                    <div id="disqus_thread"></div>
                    <script>
                        var disqus_config = function () {
                            var this_page_url = 'http://0.0.0.0:4000/Rotation';
                            var this_page_identifier = '/Rotation';
                            var this_page_title = 'Unsupervised Representation Learning by Predicting Image Rotations';
                        };
                        (function() {
                            var d = document, s = d.createElement('script');
                            s.src = 'https://.disqus.com/embed.js';
                            s.setAttribute('data-timestamp', +new Date());
                            (d.head || d.body).appendChild(s);
                        })();
                    </script>
                </section>
            


        </article>

    </div>
</main>

<!-- Links to Previous/Next posts -->
<aside class="read-next outer">
    <div class="inner">
        <div class="read-next-feed">
            
                
                
                
                
                    <article class="read-next-card"
                        
                            style="background-image: url(/assets/built/images/blog-cover1.png)"
                        
                    >
                        <header class="read-next-card-header">
                            <small class="read-next-card-header-sitetitle">&mdash; Darron's Devlog &mdash;</small>
                            
                                <h3 class="read-next-card-header-title"><a href="/tag/papers/">Papers</a></h3>
                            
                        </header>
                        <div class="read-next-divider"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 14.5s2 3 5 3 5.5-2.463 5.5-5.5S21 6.5 18 6.5c-5 0-7 11-12 11C2.962 17.5.5 15.037.5 12S3 6.5 6 6.5s4.5 3.5 4.5 3.5"/></svg>
</div>
                        <div class="read-next-card-content">
                            <ul>
                                
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                        
                                        
                                            <li><a href="/Mask_R-CNN">Mask R-CNN</a></li>
                                        
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                    
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                                  
                                
                            </ul>
                        </div>
                        <footer class="read-next-card-footer">
                            <a href="/tag/papers/">
                                
                                    See all 1 posts  →
                                
                            </a>
                        </footer>
                    </article>
                
            

            <!-- If there's a next post, display it using the same markup included from - partials/post-card.hbs -->
            
                    <article class="post-card post-template no-image">
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/cs231n_lec14">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Cs231n</span>
                            
                        
                    

                    <h2 class="post-card-title">cs231n - Lecture 14. Visualizing and Understanding</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>What’s going on inside ConvNets? Visualizing what models have learned First layer: Visualize Filters At the first layer, we can visualize the raw weights and see gabor-like features. While the higher layers are</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
            </footer>
        </div>
    </article>

            

            <!-- If there's a previous post, display it using the same markup included from - partials/post-card.hbs -->
            
                    <article class="post-card post-template no-image">
        
        <div class="post-card-content">
            <a class="post-card-content-link" href="/cs231n_lec13">
                <header class="post-card-header">
                    
                        
                            
                                <span class="post-card-tags">Cs231n</span>
                            
                        
                    

                    <h2 class="post-card-title">cs231n - Lecture 13. Self-Supervised Learning</h2>
                </header>
                <section class="post-card-excerpt">
                    
                        <p>Self-Supervised Learning Generative vs. Self-supervised Learning Both aim to learn from data without manual label annotation Generative learning aims to model data distribution $p_{data}(x)$, e.g., generating realistic images. Self-supervised learning methods solve “pretext”</p>
                    
                </section>
            </a>
            <footer class="post-card-meta">
                
                    
                
            </footer>
        </div>
    </article>

            

        </div>
    </div>
</aside>

<!-- Floating header which appears on-scroll, included from includes/floating-header.hbs -->
<div class="floating-header">
    <div class="floating-header-logo">
        <a href="/">
            
            <span>Darron's Devlog</span>
        </a>
    </div>
    <span class="floating-header-divider">&mdash;</span>
    <div class="floating-header-title">Unsupervised Representation Learning by Predicting Image Rotations</div>
    <div class="floating-header-share">
        <div class="floating-header-share-label">Share this <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
    <path d="M7.5 15.5V4a1.5 1.5 0 1 1 3 0v4.5h2a1 1 0 0 1 1 1h2a1 1 0 0 1 1 1H18a1.5 1.5 0 0 1 1.5 1.5v3.099c0 .929-.13 1.854-.385 2.748L17.5 23.5h-9c-1.5-2-5.417-8.673-5.417-8.673a1.2 1.2 0 0 1 1.76-1.605L7.5 15.5zm6-6v2m-3-3.5v3.5m6-1v2"/>
</svg>
</div>
        <a class="floating-header-share-tw" href="https://twitter.com/share?text=Unsupervised+Representation+Learning+by+Predicting+Image+Rotations&amp;url=https://12kdh43.github.io/Rotation"
            onclick="window.open(this.href, 'share-twitter', 'width=550,height=235');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M30.063 7.313c-.813 1.125-1.75 2.125-2.875 2.938v.75c0 1.563-.188 3.125-.688 4.625a15.088 15.088 0 0 1-2.063 4.438c-.875 1.438-2 2.688-3.25 3.813a15.015 15.015 0 0 1-4.625 2.563c-1.813.688-3.75 1-5.75 1-3.25 0-6.188-.875-8.875-2.625.438.063.875.125 1.375.125 2.688 0 5.063-.875 7.188-2.5-1.25 0-2.375-.375-3.375-1.125s-1.688-1.688-2.063-2.875c.438.063.813.125 1.125.125.5 0 1-.063 1.5-.25-1.313-.25-2.438-.938-3.313-1.938a5.673 5.673 0 0 1-1.313-3.688v-.063c.813.438 1.688.688 2.625.688a5.228 5.228 0 0 1-1.875-2c-.5-.875-.688-1.813-.688-2.75 0-1.063.25-2.063.75-2.938 1.438 1.75 3.188 3.188 5.25 4.25s4.313 1.688 6.688 1.813a5.579 5.579 0 0 1 1.5-5.438c1.125-1.125 2.5-1.688 4.125-1.688s3.063.625 4.188 1.813a11.48 11.48 0 0 0 3.688-1.375c-.438 1.375-1.313 2.438-2.563 3.188 1.125-.125 2.188-.438 3.313-.875z"/></svg>

        </a>
        <a class="floating-header-share-fb" href="https://www.facebook.com/sharer/sharer.php?u=https://12kdh43.github.io/Rotation"
            onclick="window.open(this.href, 'share-facebook','width=580,height=296');return false;">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>

        </a>
    </div>
    <progress class="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</div>


<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->


        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="/">Darron's Devlog</a> &copy; 2022</section>
                <!-- 
				<section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyllt/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                -->
				<nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    
                    
                </nav>
            </div>
        </footer>

    </div>

    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                <h1 class="subscribe-overlay-title">Search Darron's Devlog</h1>
                <p class="subscribe-overlay-description">
				</p>
                <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" 
               id="searchtext" type="text" name="searchtext"  
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?query=" + url;
            }
        }
    </script>
</span>
            </div>
        </div>
    

    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');

 </script>

	
    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>

// NOTE: Scroll performance is poor in Safari
// - this appears to be due to the events firing much more slowly in Safari.
//   Dropping the scroll event and using only a raf loop results in smoother
//   scrolling but continuous processing even when not scrolling
$(document).ready(function () {
    // Start fitVids
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
    // End fitVids

    var progressBar = document.querySelector('progress');
    var header = document.querySelector('.floating-header');
    var title = document.querySelector('.post-full-title');

    var lastScrollY = window.scrollY;
    var lastWindowHeight = window.innerHeight;
    var lastDocumentHeight = $(document).height();
    var ticking = false;

    function onScroll() {
        lastScrollY = window.scrollY;
        requestTick();
    }

    function onResize() {
        lastWindowHeight = window.innerHeight;
        lastDocumentHeight = $(document).height();
        requestTick();
    }

    function requestTick() {
        if (!ticking) {
            requestAnimationFrame(update);
        }
        ticking = true;
    }

    function update() {
        var trigger = title.getBoundingClientRect().top + window.scrollY;
        var triggerOffset = title.offsetHeight + 35;
        var progressMax = lastDocumentHeight - lastWindowHeight;

        // show/hide floating header
        if (lastScrollY >= trigger + triggerOffset) {
            header.classList.add('floating-active');
        } else {
            header.classList.remove('floating-active');
        }

        progressBar.setAttribute('max', progressMax);
        progressBar.setAttribute('value', lastScrollY);

        ticking = false;
    }

    window.addEventListener('scroll', onScroll, {passive: true});
    window.addEventListener('resize', onResize, false);

    update();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
